<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Ambari安装部署Hadoop | MinMinMsn</title><meta name="author" content="Jerry Min"><meta name="copyright" content="Jerry Min"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalo">
<meta property="og:type" content="article">
<meta property="og:title" content="Ambari安装部署Hadoop">
<meta property="og:url" content="https://minminmsn.github.io/2018/12/09/2018/12/2018-12-09-ambari%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2hadoop/index/index.html">
<meta property="og:site_name" content="MinMinMsn">
<meta property="og:description" content="Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2018-12-09T00:00:00.000Z">
<meta property="article:modified_time" content="2023-05-26T07:06:30.553Z">
<meta property="article:author" content="Jerry Min">
<meta property="article:tag" content="ambari">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://minminmsn.github.io/2018/12/09/2018/12/2018-12-09-ambari%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2hadoop/index/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ambari安装部署Hadoop',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-26 15:06:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">260</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="MinMinMsn"><span class="site-name">MinMinMsn</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Ambari安装部署Hadoop</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-12-09T00:00:00.000Z" title="Created 2018-12-09 08:00:00">2018-12-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-05-26T07:06:30.553Z" title="Updated 2023-05-26 15:06:30">2023-05-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/bigdata/">bigdata</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Ambari安装部署Hadoop"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。</p>
</blockquote>
<h4 id="之所以选择Ambari部署hadoop而不是CDH，是因为CDH最新版本只支持Hadoop2-6-X，Ambari最新版本支持Hadoop2-7-3。"><a href="#之所以选择Ambari部署hadoop而不是CDH，是因为CDH最新版本只支持Hadoop2-6-X，Ambari最新版本支持Hadoop2-7-3。" class="headerlink" title="之所以选择Ambari部署hadoop而不是CDH，是因为CDH最新版本只支持Hadoop2.6.X，Ambari最新版本支持Hadoop2.7.3。"></a>之所以选择Ambari部署hadoop而不是CDH，是因为CDH最新版本只支持Hadoop2.6.X，Ambari最新版本支持Hadoop2.7.3。</h4><p>一、安装部署参考官网<a target="_blank" rel="noopener" href="http://ambari.apache.org/">http://ambari.apache.org/</a> 及简书<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/73f9670f71cf">https://www.jianshu.com/p/73f9670f71cf</a> ，主要分以下几步：</p>
<p>1、节点互信</p>
<p>2、关闭防火墙、selinux</p>
<p>3、安装ambari-server</p>
<p>4、设置ambari-server</p>
<p>5、图形界面部署hadoop各组件</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-7b83fbd7afe7850d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>二、如下是新增节点步骤： 1、注意密钥为master1节点 prod-hadoop-master-01 &#x2F;root&#x2F;.ssh&#x2F;d_rsa文件</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-cef5a91c3604aea1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>2、注册节点</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-3cee2d1ffe7f6710.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>3、安装服务也可添加后再安装</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-941b88b94fba5532.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>4、配置默认即可</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-b360e94f5a2aeaf1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>5、确认下没有变更就开始部署</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-f8c719d5effabdc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>6、安装进度完成即可，也可以登陆首页等待后续安装完成</p>
<blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-943c9e8d36bb05e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<p>三、补充Ambari没有集成组件安装： 1、解决ambari-service、ambari-agent默认安装数据目录在&#x2F;下</p>
<p>ambari-agent stop mv &#x2F;var&#x2F;lib&#x2F;ambari-agent &#x2F;data&#x2F;disk1&#x2F; ln -s &#x2F;data&#x2F;disk1&#x2F;ambari-agent &#x2F;var&#x2F;lib&#x2F;ambari-agent</p>
<p>mv &#x2F;usr&#x2F;hdp &#x2F;data&#x2F;disk1&#x2F; ln -s &#x2F;data&#x2F;disk1&#x2F;hdp&#x2F; &#x2F;usr&#x2F;hdp</p>
<p>ambari-agent start</p>
<p>2、ambari与presto整合 参考 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/0b5f52a959d5">https://www.jianshu.com/p/0b5f52a959d5</a> <a target="_blank" rel="noopener" href="https://github.com/prestodb/ambari-presto-service/releases">https://github.com/prestodb/ambari-presto-service/releases</a> <a target="_blank" rel="noopener" href="https://github.com/prestodb/ambari-presto-service/releases/download/v1.2/ambari-presto-1.2.tar.gz">https://github.com/prestodb/ambari-presto-service/releases/download/v1.2/ambari-presto-1.2.tar.gz</a></p>
<p>[root@prod-hadoop-master-01 ~]# tar zxvf ambari-presto-1.2.tar.gz -C &#x2F;var&#x2F;lib&#x2F;ambari-server&#x2F;resources&#x2F;stacks&#x2F;HDP&#x2F;2.6&#x2F;services&#x2F; ambari-presto-1.2&#x2F; ambari-presto-1.2&#x2F;configuration&#x2F; ambari-presto-1.2&#x2F;configuration&#x2F;connectors.properties.xml ambari-presto-1.2&#x2F;configuration&#x2F;jvm.config.xml ambari-presto-1.2&#x2F;configuration&#x2F;config.properties.xml ambari-presto-1.2&#x2F;configuration&#x2F;node.properties.xml ambari-presto-1.2&#x2F;HISTORY.rst ambari-presto-1.2&#x2F;themes&#x2F; ambari-presto-1.2&#x2F;themes&#x2F;theme.json ambari-presto-1.2&#x2F;Makefile ambari-presto-1.2&#x2F;setup.py ambari-presto-1.2&#x2F;MANIFEST.in ambari-presto-1.2&#x2F;PKG-INFO ambari-presto-1.2&#x2F;package&#x2F; ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F; ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;presto_cli.py ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;presto_worker.py ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;presto_coordinator.py ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;<strong>init</strong>.py ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;params.py ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;download.ini ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;common.py ambari-presto-1.2&#x2F;package&#x2F;scripts&#x2F;presto_client.py ambari-presto-1.2&#x2F;setup.cfg ambari-presto-1.2&#x2F;ambari_presto.egg-info&#x2F; ambari-presto-1.2&#x2F;ambari_presto.egg-info&#x2F;dependency_links.txt ambari-presto-1.2&#x2F;ambari_presto.egg-info&#x2F;not-zip-safe ambari-presto-1.2&#x2F;ambari_presto.egg-info&#x2F;PKG-INFO ambari-presto-1.2&#x2F;ambari_presto.egg-info&#x2F;top_level.txt ambari-presto-1.2&#x2F;ambari_presto.egg-info&#x2F;SOURCES.txt ambari-presto-1.2&#x2F;LICENSE ambari-presto-1.2&#x2F;README.md ambari-presto-1.2&#x2F;metainfo.xml ambari-presto-1.2&#x2F;requirements.txt [root@prod-hadoop-master-01 ~]# cd &#x2F;var&#x2F;lib&#x2F;ambari-server&#x2F;resources&#x2F;stacks&#x2F;HDP&#x2F;2.6&#x2F;services&#x2F; [root@prod-hadoop-master-01 services]# ls ACCUMULO ATLAS FALCON HBASE HIVE KERBEROS MAHOUT PIG RANGER_KMS SPARK SQOOP stack_advisor.pyc STORM TEZ ZEPPELIN ambari-presto-1.2 DRUID FLUME HDFS KAFKA KNOX OOZIE RANGER SLIDER SPARK2 stack_advisor.py stack_advisor.pyo SUPERSET YARN ZOOKEEPER [root@prod-hadoop-master-01 services]# mv ambari-presto-1.2&#x2F; PRESTO [root@prod-hadoop-master-01 services]# chmod -R +x PRESTO&#x2F;* [root@prod-hadoop-master-01 services]# ambari-server restart 平台上添加presto服务器，一个控制节点，两个worker节点</p>
<p>3、安装kylin组件 <a target="_blank" rel="noopener" href="https://blog.csdn.net/vivismilecs/article/details/72763665">https://blog.csdn.net/vivismilecs/article/details/72763665</a> 下载安装 tar -zxvf apache-kylin-2.3.1-hbase1x-bin.tar.gz -C &#x2F;hadoop&#x2F; cd &#x2F;hadoop&#x2F; chown -R <a target="_blank" rel="noopener" href="http://hdfshadoop/">hdfs:hadoop</a> kylin&#x2F; vim &#x2F;etc&#x2F;profile source &#x2F;etc&#x2F;profile echo $KYLIN_HOME &#x2F;hadoop&#x2F;kylin 切换用户检查环境是否正确安装 su hdfs hive（进入hive，quit;退出） hbase shell（进入hbase shell，ctrl+c结束）</p>
<p>[hdfs@prod-hadoop-data-01 kylin]$ bin&#x2F;check-env.sh  Retrieving hadoop conf dir… KYLIN_HOME is set to &#x2F;hadoop&#x2F;kylin hdfs is not in the sudoers file. This incident will be reported. Failed to create <a href="hdfs://wiki.365jiating.com/kylin/spark-history">hdfs:&#x2F;&#x2F;&#x2F;kylin&#x2F;spark-history</a>. Please make sure the user has right to access <a href="hdfs://wiki.365jiating.com/kylin/spark-history">hdfs:&#x2F;&#x2F;&#x2F;kylin&#x2F;spark-history</a></p>
<p>排错 [hdfs@prod-hadoop-data-01 kylin]$ exit [root@prod-hadoop-data-01 hadoop]# vim &#x2F;etc&#x2F;sudoers.d&#x2F;waagent</p>
<p>检测 [hdfs@prod-hadoop-data-01 kylin]$ bin&#x2F;check-env.sh  Retrieving hadoop conf dir… KYLIN_HOME is set to &#x2F;hadoop&#x2F;kylin</p>
<p>启动 [hdfs@prod-hadoop-data-01 kylin]$ bin&#x2F;kylin.sh start Retrieving hadoop conf dir… KYLIN_HOME is set to &#x2F;hadoop&#x2F;kylin Retrieving hive dependency… Retrieving hbase dependency… Retrieving hadoop conf dir… Retrieving kafka dependency… Retrieving Spark dependency… Start to check whether we need to migrate acl tables Retrieving hadoop conf dir… KYLIN_HOME is set to &#x2F;hadoop&#x2F;kylin Retrieving hive dependency… Retrieving hbase dependency… Retrieving hadoop conf dir… Retrieving kafka dependency… Retrieving Spark dependency… SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [<a target="_blank" rel="noopener" href="http://jarfile/">jar:file:&#x2F;hadoop&#x2F;apache-kylin-2.3.1-bin&#x2F;tool&#x2F;kylin-tool-2.3.1.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class</a>] SLF4J: Found binding in [<a target="_blank" rel="noopener" href="http://jarfile/">jar:file:&#x2F;data&#x2F;disk1&#x2F;hdp&#x2F;2.6.5.0-292&#x2F;hadoop&#x2F;lib&#x2F;slf4j-log4j12-1.7.10.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class</a>] SLF4J: Found binding in [<a target="_blank" rel="noopener" href="http://jarfile/">jar:file:&#x2F;hadoop&#x2F;apache-kylin-2.3.1-bin&#x2F;spark&#x2F;jars&#x2F;slf4j-log4j12-1.7.16.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class</a>] SLF4J: See <a target="_blank" rel="noopener" href="http://www.slf4j.org/codes.html#multiple_bindings">http://www.slf4j.org/codes.html#multiple_bindings</a> for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] 2018-05-24 14:23:21,974 INFO [main] common.KylinConfig:319 : Loading kylin-defaults.properties from <a target="_blank" rel="noopener" href="http://file/hadoop/apache-kylin-2.3.1-bin/tool/kylin-tool-2.3.1.jar!/kylin-defaults.properties">file:&#x2F;hadoop&#x2F;apache-kylin-2.3.1-bin&#x2F;tool&#x2F;kylin-tool-2.3.1.jar!&#x2F;kylin-defaults.properties</a> 2018-05-24 14:23:22,016 DEBUG [main] common.KylinConfig:278 : KYLIN_CONF property was not set, will seek KYLIN_HOME env variable 2018-05-24 14:23:22,019 INFO [main] common.KylinConfig:99 : Initialized a new KylinConfig from getInstanceFromEnv : 494317290 2018-05-24 14:23:22,120 INFO [main] persistence.ResourceStore:86 : Using metadata url kylin_metadata@hbase for resource store 2018-05-24 14:23:24,034 DEBUG [main] hbase.HBaseConnection:181 : Using the working dir FS for HBase: <a href="hdfs://prod-hadoop-master-01.hadoop:8020">hdfs:&#x2F;&#x2F;prod-hadoop-master-01.hadoop:8020</a> 2018-05-24 14:23:24,034 INFO [main] hbase.HBaseConnection:258 : connection is null or closed, creating a new one 2018-05-24 14:23:24,168 INFO [main] zookeeper.RecoverableZooKeeper:120 : Process identifier&#x3D;hconnection-0x7561db12 connecting to ZooKeeper ensemble&#x3D;prod-hadoop-master-01.<a href="http://hadoop:2181%2Cprod-hadoop-master-02.hadoop:2181%2Cprod-hadoop-data-01.hadoop:2181/">hadoop:2181,prod-hadoop-master-02.hadoop:2181,prod-hadoop-data-01.hadoop:2181</a> 2018-05-24 14:23:24,176 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentzookeeper.version=3.4.6-292--1/">environment:zookeeper.version&#x3D;3.4.6-292–1</a>, built on 05&#x2F;11&#x2F;2018 07:09 GMT 2018-05-24 14:23:24,176 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmenthost.name=prod-hadoop-data-01.hadoop/">environment:host.name&#x3D;prod-hadoop-data-01.hadoop</a> 2018-05-24 14:23:24,176 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.version=1.8.0_91/">environment:java.version&#x3D;1.8.0_91</a> 2018-05-24 14:23:24,177 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.vendor=oracle/">environment:java.vendor&#x3D;Oracle</a> Corporation 2018-05-24 14:23:24,177 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.home=/">environment:java.home&#x3D;&#x2F;usr&#x2F;local&#x2F;java</a> 2018-05-24 14:23:24,182 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.class.path=/">environment:java.class.path&#x3D;&#x2F;hadoop&#x2F;kylin&#x2F;tool&#x2F;kylin-tool-2.3.1.jar:1.8.1.jar:&#x2F;hadoop&#x2F;kylin&#x2F;spark&#x2F;jars&#x2F;hadoop-mapreduce-client-jobclient-2.7.3.jar:&#x2F;hadoop&#x2F;kylin&#x2F;spark&#x2F;jars&#x2F;chill-java-0.8.0.jar:jar:&#x2F;hadoop&#x2F;kylin&#x2F;spark&#x2F;jars&#x2F;xercesImpl-2.9.1.jar:&#x2F;hadoop&#x2F;kylin&#x2F;spark&#x2F;jars&#x2F;netty-3.8.0.Final.jar:&#x2F;usr&#x2F;hdp&#x2F;current&#x2F;ext&#x2F;hbase&#x2F;*</a> 2018-05-24 14:23:24,191 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.library.path=/">environment:java.library.path&#x3D;:&#x2F;usr&#x2F;hdp&#x2F;2.6.5.0-292&#x2F;hadoop&#x2F;lib&#x2F;native&#x2F;Linux-amd64-64:&#x2F;usr&#x2F;hdp&#x2F;2.6.5.0-292&#x2F;hadoop&#x2F;lib&#x2F;native&#x2F;Linux-amd64-64:&#x2F;data&#x2F;disk1&#x2F;hdp&#x2F;2.6.5.0-292&#x2F;hadoop&#x2F;lib&#x2F;native</a> 2018-05-24 14:23:24,191 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.io.tmpdir=/">environment:java.io.tmpdir&#x3D;&#x2F;tmp</a> 2018-05-24 14:23:24,191 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentjava.compiler=/">environment:java.compiler&#x3D;</a> 2018-05-24 14:23:24,193 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentos.name=linux/">environment:os.name&#x3D;Linux</a> 2018-05-24 14:23:24,193 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentos.arch=amd64/">environment:os.arch&#x3D;amd64</a> 2018-05-24 14:23:24,193 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentos.version=2.6.32-696.18.7.el6.x86_64/">environment:os.version&#x3D;2.6.32-696.18.7.el6.x86_64</a> 2018-05-24 14:23:24,193 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentuser.name=hdfs/">environment:user.name&#x3D;hdfs</a> 2018-05-24 14:23:24,194 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentuser.home=/">environment:user.home&#x3D;&#x2F;home&#x2F;hdfs</a> 2018-05-24 14:23:24,194 INFO [main] zookeeper.ZooKeeper:100 : Client <a target="_blank" rel="noopener" href="http://environmentuser.dir=/">environment:user.dir&#x3D;&#x2F;hadoop&#x2F;apache-kylin-2.3.1-bin</a> 2018-05-24 14:23:24,195 INFO [main] zookeeper.ZooKeeper:438 : Initiating client connection, connectString&#x3D;prod-hadoop-master-01.<a href="http://hadoop:2181%2Cprod-hadoop-master-02.hadoop:2181%2Cprod-hadoop-data-01.hadoop:2181/">hadoop:2181,prod-hadoop-master-02.hadoop:2181,prod-hadoop-data-01.hadoop:2181</a> sessionTimeout&#x3D;90000 watcher&#x3D;org.apache.hadoop.hbase.zookeeper.PendingWatcher@66b72664 2018-05-24 14:23:24,237 INFO [main-SendThread(prod-hadoop-data-01.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:1019 : Opening socket connection to server prod-hadoop-data-01.hadoop&#x2F;172.20.3.6:2181. Will not attempt to authenticate using SASL (unknown error) 2018-05-24 14:23:24,246 INFO [main-SendThread(prod-hadoop-data-01.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:864 : Socket connection established, initiating session, client: &#x2F;172.20.3.6:50746, server: prod-hadoop-data-01.hadoop&#x2F;172.20.3.6:2181 2018-05-24 14:23:24,256 INFO [main-SendThread(prod-hadoop-data-01.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:1279 : Session establishment complete on server prod-hadoop-data-01.hadoop&#x2F;172.20.3.6:2181, sessionid &#x3D; 0x163882326e1003b, negotiated timeout &#x3D; 60000 2018-05-24 14:23:24,892 DEBUG [main] hbase.HBaseConnection:181 : Using the working dir FS for HBase: <a href="hdfs://prod-hadoop-master-01.hadoop:8020">hdfs:&#x2F;&#x2F;prod-hadoop-master-01.hadoop:8020</a> 2018-05-24 14:23:24,944 INFO [main] imps.CuratorFrameworkImpl:224 : Starting 2018-05-24 14:23:24,947 INFO [main] zookeeper.ZooKeeper:438 : Initiating client connection, connectString&#x3D;prod-hadoop-master-01.<a href="http://hadoop:2181%2Cprod-hadoop-master-02.hadoop:2181%2Cprod-hadoop-data-01.hadoop:2181/">hadoop:2181,prod-hadoop-master-02.hadoop:2181,prod-hadoop-data-01.hadoop:2181</a> sessionTimeout&#x3D;120000 watcher&#x3D;org.apache.curator.ConnectionState@67207d8a 2018-05-24 14:23:24,950 INFO [main-SendThread(prod-hadoop-master-02.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:1019 : Opening socket connection to server prod-hadoop-master-02.hadoop&#x2F;172.20.3.5:2181. Will not attempt to authenticate using SASL (unknown error) 2018-05-24 14:23:24,951 INFO [main-SendThread(prod-hadoop-master-02.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:864 : Socket connection established, initiating session, client: &#x2F;172.20.3.6:60080, server: prod-hadoop-master-02.hadoop&#x2F;172.20.3.5:2181 2018-05-24 14:23:24,952 DEBUG [main] util.ZookeeperDistributedLock:143 : 6616@prod-hadoop-data-01 trying to lock &#x2F;kylin&#x2F;kylin_metadata&#x2F;create_htable&#x2F;kylin_metadata&#x2F;lock 2018-05-24 14:23:24,957 INFO [main-SendThread(prod-hadoop-master-02.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:1279 : Session establishment complete on server prod-hadoop-master-02.hadoop&#x2F;172.20.3.5:2181, sessionid &#x3D; 0x3638801b4480045, negotiated timeout &#x3D; 60000 2018-05-24 14:23:24,962 INFO [main-EventThread] state.ConnectionStateManager:228 : State change: CONNECTED 2018-05-24 14:23:25,031 INFO [main] util.ZookeeperDistributedLock:155 : 6616@prod-hadoop-data-01 acquired lock at &#x2F;kylin&#x2F;kylin_metadata&#x2F;create_htable&#x2F;kylin_metadata&#x2F;lock 2018-05-24 14:23:25,036 DEBUG [main] hbase.HBaseConnection:337 : Creating HTable ‘kylin_metadata’ 2018-05-24 14:23:27,822 INFO [main] client.HBaseAdmin:789 : Created kylin_metadata 2018-05-24 14:23:27,823 DEBUG [main] hbase.HBaseConnection:350 : HTable ‘kylin_metadata’ created 2018-05-24 14:23:27,824 DEBUG [main] util.ZookeeperDistributedLock:223 : 6616@prod-hadoop-data-01 trying to unlock &#x2F;kylin&#x2F;kylin_metadata&#x2F;create_htable&#x2F;kylin_metadata&#x2F;lock 2018-05-24 14:23:27,833 INFO [main] util.ZookeeperDistributedLock:234 : 6616@prod-hadoop-data-01 released lock at &#x2F;kylin&#x2F;kylin_metadata&#x2F;create_htable&#x2F;kylin_metadata&#x2F;lock 2018-05-24 14:23:28,105 DEBUG [main] hbase.HBaseConnection:181 : Using the working dir FS for HBase: <a href="hdfs://prod-hadoop-master-01.hadoop:8020">hdfs:&#x2F;&#x2F;prod-hadoop-master-01.hadoop:8020</a> 2018-05-24 14:23:28,105 INFO [main] hbase.HBaseConnection:258 : connection is null or closed, creating a new one 2018-05-24 14:23:28,106 INFO [main] zookeeper.RecoverableZooKeeper:120 : Process identifier&#x3D;hconnection-0xf339eae connecting to ZooKeeper ensemble&#x3D;prod-hadoop-master-01.<a href="http://hadoop:2181%2Cprod-hadoop-master-02.hadoop:2181%2Cprod-hadoop-data-01.hadoop:2181/">hadoop:2181,prod-hadoop-master-02.hadoop:2181,prod-hadoop-data-01.hadoop:2181</a> 2018-05-24 14:23:28,106 INFO [main] zookeeper.ZooKeeper:438 : Initiating client connection, connectString&#x3D;prod-hadoop-master-01.<a href="http://hadoop:2181%2Cprod-hadoop-master-02.hadoop:2181%2Cprod-hadoop-data-01.hadoop:2181/">hadoop:2181,prod-hadoop-master-02.hadoop:2181,prod-hadoop-data-01.hadoop:2181</a> sessionTimeout&#x3D;90000 watcher&#x3D;org.apache.hadoop.hbase.zookeeper.PendingWatcher@2822c6ff 2018-05-24 14:23:28,109 INFO [main-SendThread(prod-hadoop-data-01.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:1019 : Opening socket connection to server prod-hadoop-data-01.hadoop&#x2F;172.20.3.6:2181. Will not attempt to authenticate using SASL (unknown error) 2018-05-24 14:23:28,109 INFO [main-SendThread(prod-hadoop-data-01.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:864 : Socket connection established, initiating session, client: &#x2F;172.20.3.6:50760, server: prod-hadoop-data-01.hadoop&#x2F;172.20.3.6:2181 2018-05-24 14:23:28,115 INFO [main-SendThread(prod-hadoop-data-01.<a target="_blank" rel="noopener" href="http://hadoop:2181/">hadoop:2181</a>)] zookeeper.ClientCnxn:1279 : Session establishment complete on server prod-hadoop-data-01.hadoop&#x2F;172.20.3.6:2181, sessionid &#x3D; 0x163882326e1003c, negotiated timeout &#x3D; 60000 2018-05-24 14:23:28,138 INFO [close-hbase-conn] hbase.HBaseConnection:137 : Closing HBase connections… 2018-05-24 14:23:28,144 INFO [close-hbase-conn] client.ConnectionManager$HConnectionImplementation:1703 : Closing zookeeper sessionid&#x3D;0x163882326e1003c 2018-05-24 14:23:28,152 INFO [close-hbase-conn] zookeeper.ZooKeeper:684 : Session: 0x163882326e1003c closed 2018-05-24 14:23:28,152 INFO [main-EventThread] zookeeper.ClientCnxn:524 : EventThread shut down 2018-05-24 14:23:28,154 INFO [Thread-8] zookeeper.ZooKeeper:684 : Session: 0x3638801b4480045 closed 2018-05-24 14:23:28,154 INFO [main-EventThread] zookeeper.ClientCnxn:524 : EventThread shut down 2018-05-24 14:23:28,162 INFO [close-hbase-conn] client.ConnectionManager$HConnectionImplementation:2167 : Closing master protocol: MasterService 2018-05-24 14:23:28,163 INFO [close-hbase-conn] client.ConnectionManager$HConnectionImplementation:1703 : Closing zookeeper sessionid&#x3D;0x163882326e1003b 2018-05-24 14:23:28,168 INFO [main-EventThread] zookeeper.ClientCnxn:524 : EventThread shut down 2018-05-24 14:23:28,169 INFO [close-hbase-conn] zookeeper.ZooKeeper:684 : Session: 0x163882326e1003b closed</p>
<p>A new Kylin instance is started by hdfs. To stop it, run ‘kylin.sh stop’ Check the log at &#x2F;hadoop&#x2F;kylin&#x2F;logs&#x2F;kylin.log Web UI is at http:&#x2F;&#x2F;:7070&#x2F;kylin</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://minminmsn.github.io">Jerry Min</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://minminmsn.github.io/2018/12/09/2018/12/2018-12-09-ambari%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2hadoop/index/">https://minminmsn.github.io/2018/12/09/2018/12/2018-12-09-ambari%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2hadoop/index/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ambari/">ambari</a><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/12/12/2018/12/2018-12-12-centos7-4%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AEelasticsearch6-3-2%E9%9B%86%E7%BE%A4/index/" title="Centos7.4部署配置Elasticsearch6.3.2集群"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Centos7.4部署配置Elasticsearch6.3.2集群</div></div></a></div><div class="next-post pull-right"><a href="/2018/12/09/2018/12/2018-12-09-dns%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/index/" title="DNS主从服务器搭建"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">DNS主从服务器搭建</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Jerry Min</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">260</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/minminmsn"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">不念过往，无畏将来，若非当下，何时？</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B9%8B%E6%89%80%E4%BB%A5%E9%80%89%E6%8B%A9Ambari%E9%83%A8%E7%BD%B2hadoop%E8%80%8C%E4%B8%8D%E6%98%AFCDH%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BACDH%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC%E5%8F%AA%E6%94%AF%E6%8C%81Hadoop2-6-X%EF%BC%8CAmbari%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC%E6%94%AF%E6%8C%81Hadoop2-7-3%E3%80%82"><span class="toc-number">1.</span> <span class="toc-text">之所以选择Ambari部署hadoop而不是CDH，是因为CDH最新版本只支持Hadoop2.6.X，Ambari最新版本支持Hadoop2.7.3。</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/27/2022/12/2022-12-27-%E8%BF%90%E7%BB%B4%E8%83%BD%E5%8A%9B%E8%A6%81%E6%B1%82/index/" title="运维能力要求">运维能力要求</a><time datetime="2022-12-27T00:00:00.000Z" title="Created 2022-12-27 08:00:00">2022-12-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/11/01/2022/11/2022-11-01-%E6%B5%85%E8%B0%88%E5%9F%BA%E4%BA%8E-openstack-%E5%92%8C-k8s-%E8%BD%BB%E9%87%8F%E7%A0%94%E5%8F%91%E7%A7%81%E6%9C%89%E4%BA%91%E5%BB%BA%E8%AE%BE/index/" title="浅谈基于 OpenStack 和 k8s 轻量研发私有云建设">浅谈基于 OpenStack 和 k8s 轻量研发私有云建设</a><time datetime="2022-11-01T00:00:00.000Z" title="Created 2022-11-01 08:00:00">2022-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/17/2022/06/2022-06-17-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E9%9B%86%E9%94%A6/index/" title="数学公式集锦">数学公式集锦</a><time datetime="2022-06-17T00:00:00.000Z" title="Created 2022-06-17 08:00:00">2022-06-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/14/2022/06/2022-06-14-%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/index/" title="运维工作总结">运维工作总结</a><time datetime="2022-06-14T00:00:00.000Z" title="Created 2022-06-14 08:00:00">2022-06-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/11/2022/06/2022-06-11-%E6%98%8E%E5%84%92%E5%AD%A6%E6%A1%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index/" title="明儒学案学习笔记">明儒学案学习笔记</a><time datetime="2022-06-11T00:00:00.000Z" title="Created 2022-06-11 08:00:00">2022-06-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2023 By Jerry Min</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>