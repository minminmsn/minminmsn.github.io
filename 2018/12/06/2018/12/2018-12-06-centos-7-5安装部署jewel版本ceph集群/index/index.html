<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CentOS-7-5安装部署Jewel版本Ceph集群 | MinMinMsn</title><meta name="author" content="Jerry Min"><meta name="copyright" content="Jerry Min"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参考文档 https:&#x2F;&#x2F;www.linuxidc.com&#x2F;Linux&#x2F;2017-09&#x2F;146760.htm https:&#x2F;&#x2F;www.cnblogs.com&#x2F;luohaixian&#x2F;p&#x2F;8087591.html http:&#x2F;&#x2F;docs.ceph.com&#x2F;docs&#x2F;master&#x2F;start&#x2F;quick-start-preflight&#x2F;#rhel-centos  简介 Ceph的核心组件包括Ceph O">
<meta property="og:type" content="article">
<meta property="og:title" content="CentOS-7-5安装部署Jewel版本Ceph集群">
<meta property="og:url" content="https://minminmsn.github.io/2018/12/06/2018/12/2018-12-06-centos-7-5%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2jewel%E7%89%88%E6%9C%ACceph%E9%9B%86%E7%BE%A4/index/index.html">
<meta property="og:site_name" content="MinMinMsn">
<meta property="og:description" content="参考文档 https:&#x2F;&#x2F;www.linuxidc.com&#x2F;Linux&#x2F;2017-09&#x2F;146760.htm https:&#x2F;&#x2F;www.cnblogs.com&#x2F;luohaixian&#x2F;p&#x2F;8087591.html http:&#x2F;&#x2F;docs.ceph.com&#x2F;docs&#x2F;master&#x2F;start&#x2F;quick-start-preflight&#x2F;#rhel-centos  简介 Ceph的核心组件包括Ceph O">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2018-12-06T00:00:00.000Z">
<meta property="article:modified_time" content="2023-05-26T07:06:30.478Z">
<meta property="article:author" content="Jerry Min">
<meta property="article:tag" content="ceph">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://minminmsn.github.io/2018/12/06/2018/12/2018-12-06-centos-7-5%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2jewel%E7%89%88%E6%9C%ACceph%E9%9B%86%E7%BE%A4/index/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CentOS-7-5安装部署Jewel版本Ceph集群',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-26 15:06:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">260</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="MinMinMsn"><span class="site-name">MinMinMsn</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CentOS-7-5安装部署Jewel版本Ceph集群</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-12-06T00:00:00.000Z" title="Created 2018-12-06 08:00:00">2018-12-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-05-26T07:06:30.478Z" title="Updated 2023-05-26 15:06:30">2023-05-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/bigdata/">bigdata</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CentOS-7-5安装部署Jewel版本Ceph集群"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.linuxidc.com/Linux/2017-09/146760.htm">https://www.linuxidc.com/Linux/2017-09/146760.htm</a> <a target="_blank" rel="noopener" href="https://www.cnblogs.com/luohaixian/p/8087591.html">https://www.cnblogs.com/luohaixian/p/8087591.html</a> <a target="_blank" rel="noopener" href="http://docs.ceph.com/docs/master/start/quick-start-preflight/#rhel-centos">http://docs.ceph.com/docs/master/start/quick-start-preflight/#rhel-centos</a></p>
</blockquote>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h3><blockquote>
<p>Ceph的核心组件包括Ceph OSD、Ceph Monitor、Ceph MDS和Ceph RWG。 Ceph OSD：OSD的英文全称是Object Storage Device，它的主要功能是存储数据、复制数据、平衡数据、恢复数据等，与其它OSD间进行心跳检查等，并将一些变化情况上报给Ceph Monitor。一般情况下一块硬盘对应一个OSD，由OSD来对硬盘存储进行管理，当然一个分区也可以成为一个OSD。 Ceph Monitor：由该英文名字我们可以知道它是一个监视器，负责监视Ceph集群，维护Ceph集群的健康状态，同时维护着Ceph集群中的各种Map图，比如OSD Map、Monitor Map、PG Map和CRUSH Map，这些Map统称为Cluster Map，Cluster Map是RADOS的关键数据结构，管理集群中的所有成员、关系、属性等信息以及数据的分发，比如当用户需要存储数据到Ceph集群时，OSD需要先通过Monitor获取最新的Map图，然后根据Map图和object id等计算出数据最终存储的位置。 Ceph MDS：全称是Ceph MetaData Server，主要保存的文件系统服务的元数据，但对象存储和块存储设备是不需要使用该服务的。 Ceph RWG：RGW为Rados Gateway的缩写，ceph通过RGW为互联网云服务提供商提供对象存储服务。RGW在librados之上向应用提供访问ceph集群的RestAPI， 支持Amazon S3和openstack swift两种接口。对RGW最直接的理解就是一个协议转换层，把从上层应用符合S3或Swift协议的请求转换成rados的请求， 将数据保存在rados集群中。</p>
</blockquote>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a><strong>架构图</strong></h3><blockquote>
<p><img src="https://upload-images.jianshu.io/upload_images/7535971-a46a76f38c878dca.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
</blockquote>
<h3 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a><strong>安装部署</strong></h3><h4 id="一、基础环境"><a href="#一、基础环境" class="headerlink" title="一、基础环境"></a>一、基础环境</h4><p>0、服务分布</p>
<blockquote>
<p>mon ceph0、ceph2、cphe3 注意mon为奇数节点 osd ceph0、ceph1、ceph2、ceph3 rgw ceph1 deploy ceph0</p>
</blockquote>
<p>1、host解析</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# cat &#x2F;etc&#x2F;hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 172.20.1.138 idcv-ceph0 172.20.1.139 idcv-ceph1 172.20.1.140 idcv-ceph2 172.20.1.141 idcv-ceph3</p>
</blockquote>
<p>2、ntp时间同步</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# ntpdate 172.20.0.63</p>
</blockquote>
<p>3、ssh免密码登陆</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# ssh-keygen [root@idcv-ceph0 ~]# ssh-copy-id root@idcv-ceph1 [root@idcv-ceph0 ~]# ssh-copy-id root@idcv-ceph2 [root@idcv-ceph0 ~]# ssh-copy-id root@idcv-ceph3</p>
</blockquote>
<p>4、update系统</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# yum update</p>
</blockquote>
<p>5、关闭selinux</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# sed -i ‘s&#x2F;enforcing&#x2F;disabled&#x2F;g’ &#x2F;etc&#x2F;selinux&#x2F;config</p>
</blockquote>
<p>6、关闭iptables</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# systemctl disable firewalld</p>
</blockquote>
<p>7、reboot</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# reboot</p>
</blockquote>
<h4 id="二、安装部署deploy节点"><a href="#二、安装部署deploy节点" class="headerlink" title="二、安装部署deploy节点"></a>二、安装部署deploy节点</h4><p>1、设置国内yum源</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# cat &#x2F;etc&#x2F;yum.repos.d&#x2F;ceph.repo [Ceph] name&#x3D;Ceph packages for $basearch baseurl&#x3D;<a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/ceph/rpm-jewel/el7/$basearch">http://mirrors.aliyun.com/ceph/rpm-jewel/el7/$basearch</a> enabled&#x3D;1 gpgcheck&#x3D;1 type&#x3D;rpm-md gpgkey&#x3D;<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/ceph/keys/release.asc">https://mirrors.aliyun.com/ceph/keys/release.asc</a> priority&#x3D;1 [Ceph-noarch] name&#x3D;Ceph noarch packages baseurl&#x3D;<a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/ceph/rpm-jewel/el7/noarch">http://mirrors.aliyun.com/ceph/rpm-jewel/el7/noarch</a> enabled&#x3D;1 gpgcheck&#x3D;1 type&#x3D;rpm-md gpgkey&#x3D;<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/ceph/keys/release.asc">https://mirrors.aliyun.com/ceph/keys/release.asc</a> priority&#x3D;1 [ceph-source] name&#x3D;Ceph source packages baseurl&#x3D;<a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/ceph/rpm-jewel/el7/SRPMS">http://mirrors.aliyun.com/ceph/rpm-jewel/el7/SRPMS</a> enabled&#x3D;1 gpgcheck&#x3D;1 type&#x3D;rpm-md gpgkey&#x3D;<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/ceph/keys/release.asc">https://mirrors.aliyun.com/ceph/keys/release.asc</a> priority&#x3D;1</p>
</blockquote>
<p>2、安装ceph-deploy</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# yum install ceph-deploy [root@idcv-ceph0 ~]# ceph-deploy –version 1.5.39 [root@idcv-ceph0 ~]# ceph -v ceph version 10.2.10 (5dc1e4c05cb68dbf62ae6fce3f0700e4654fdbbe)</p>
</blockquote>
<p>3、创建部署目录并部署集群</p>
<blockquote>
<p>[root@idcv-ceph0 ~]# mkdir cluster [root@idcv-ceph0 ~]# cd cluster [root@idcv-ceph0 cluster]# ceph-deploy new idcv-ceph0 idcv-ceph1 idcv-ceph2 idcv-ceph3 [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy new idcv-ceph0 idcv-ceph1 idcv-ceph2 idcv-ceph3 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f7c5ff1bcf8&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] ssh_copykey : True [ceph_deploy.cli][INFO ] mon : [‘idcv-ceph0’, ‘idcv-ceph1’, ‘idcv-ceph2’, ‘idcv-ceph3’] [ceph_deploy.cli][INFO ] public_network : None [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] cluster_network : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] fsid : None [ceph_deploy.new][DEBUG ] Creating new cluster named ceph [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] find the location of an executable [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip link show [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ip addr show [idcv-ceph0][DEBUG ] IP addresses found: [u’172.20.1.138’] [ceph_deploy.new][DEBUG ] Resolving host idcv-ceph0 [ceph_deploy.new][DEBUG ] Monitor idcv-ceph0 at 172.20.1.138 [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [idcv-ceph1][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph1][INFO ] Running command: ssh -CT -o BatchMode&#x3D;yes idcv-ceph1 [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [idcv-ceph1][DEBUG ] find the location of an executable [idcv-ceph1][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ip link show [idcv-ceph1][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ip addr show [idcv-ceph1][DEBUG ] IP addresses found: [u’172.20.1.139’] [ceph_deploy.new][DEBUG ] Resolving host idcv-ceph1 [ceph_deploy.new][DEBUG ] Monitor idcv-ceph1 at 172.20.1.139 [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [idcv-ceph2][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph2][INFO ] Running command: ssh -CT -o BatchMode&#x3D;yes idcv-ceph2 [idcv-ceph2][DEBUG ] connection detected need for sudo [idcv-ceph2][DEBUG ] connected to host: idcv-ceph2 [idcv-ceph2][DEBUG ] detect platform information from remote host [idcv-ceph2][DEBUG ] detect machine type [idcv-ceph2][DEBUG ] find the location of an executable [idcv-ceph2][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ip link show [idcv-ceph2][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ip addr show [idcv-ceph2][DEBUG ] IP addresses found: [u’172.20.1.140’] [ceph_deploy.new][DEBUG ] Resolving host idcv-ceph2 [ceph_deploy.new][DEBUG ] Monitor idcv-ceph2 at 172.20.1.140 [ceph_deploy.new][INFO ] making sure passwordless SSH succeeds [idcv-ceph3][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph3][INFO ] Running command: ssh -CT -o BatchMode&#x3D;yes idcv-ceph3 [idcv-ceph3][DEBUG ] connection detected need for sudo [idcv-ceph3][DEBUG ] connected to host: idcv-ceph3 [idcv-ceph3][DEBUG ] detect platform information from remote host [idcv-ceph3][DEBUG ] detect machine type [idcv-ceph3][DEBUG ] find the location of an executable [idcv-ceph3][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ip link show [idcv-ceph3][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ip addr show [idcv-ceph3][DEBUG ] IP addresses found: [u’172.20.1.141’] [ceph_deploy.new][DEBUG ] Resolving host idcv-ceph3 [ceph_deploy.new][DEBUG ] Monitor idcv-ceph3 at 172.20.1.141 [ceph_deploy.new][DEBUG ] Monitor initial members are [‘idcv-ceph0’, ‘idcv-ceph1’, ‘idcv-ceph2’, ‘idcv-ceph3’] [ceph_deploy.new][DEBUG ] Monitor addrs are [‘172.20.1.138’, ‘172.20.1.139’, ‘172.20.1.140’, ‘172.20.1.141’] [ceph_deploy.new][DEBUG ] Creating a random mon key… [ceph_deploy.new][DEBUG ] Writing monitor keyring to ceph.mon.keyring… [ceph_deploy.new][DEBUG ] Writing initial config to ceph.conf…</p>
</blockquote>
<h4 id="三、安装mon服务"><a href="#三、安装mon服务" class="headerlink" title="三、安装mon服务"></a>三、安装mon服务</h4><p>1、修改cpeh.conf文件 注意mon为奇数，如果为偶数，有一个不会安装，另外设置好public_network，并稍微增大mon之间时差允许范围(默认为0.05s，现改为2s)</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# cat ceph.conf [global] fsid &#x3D; 812d3acb-eaa8-4355-9a74-64f2cd5209b3 mon_initial_members &#x3D; idcv-ceph0, idcv-ceph1, idcv-ceph2, idcv-ceph3 mon_host &#x3D; 172.20.1.138,172.20.1.139,172.20.1.140,172.20.1.141 auth_cluster_required &#x3D; cephx auth_service_required &#x3D; cephx auth_client_required &#x3D; cephx public_network &#x3D; 172.20.0.0&#x2F;20 mon_clock_drift_allowed &#x3D; 2</p>
</blockquote>
<p>2、开始部署mon服务</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph-deploy mon create-initial [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy mon create-initial [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create-initial [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fd263377368&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] keyrings : None [ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts idcv-ceph0 idcv-ceph1 idcv-ceph2 idcv-ceph3 [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph0 … [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph0][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph0][DEBUG ] get remote short hostname [idcv-ceph0][DEBUG ] deploying mon to idcv-ceph0 [idcv-ceph0][DEBUG ] get remote short hostname [idcv-ceph0][DEBUG ] remote hostname: idcv-ceph0 [idcv-ceph0][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph0][DEBUG ] create the mon path if it does not exist [idcv-ceph0][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;done [idcv-ceph0][DEBUG ] done path does not exist: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;done [idcv-ceph0][INFO ] creating keyring file: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph0.mon.keyring [idcv-ceph0][DEBUG ] create the monitor keyring file [idcv-ceph0][INFO ] Running command: ceph-mon –cluster ceph –mkfs -i idcv-ceph0 –keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph0.mon.keyring –setuser 167 –setgroup 167 [idcv-ceph0][DEBUG ] ceph-mon: renaming mon.noname-a 172.20.1.138:6789&#x2F;0 to mon.idcv-ceph0 [idcv-ceph0][DEBUG ] ceph-mon: set fsid to 812d3acb-eaa8-4355-9a74-64f2cd5209b3 [idcv-ceph0][DEBUG ] ceph-mon: created monfs at &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0 for mon.idcv-ceph0 [idcv-ceph0][INFO ] unlinking keyring file &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph0.mon.keyring [idcv-ceph0][DEBUG ] create a done file to avoid re-doing the mon deployment [idcv-ceph0][DEBUG ] create the init path if it does not exist [idcv-ceph0][INFO ] Running command: systemctl enable ceph.target [idcv-ceph0][INFO ] Running command: systemctl enable ceph-mon@idcv-ceph0 [idcv-ceph0][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mon.target.wants&#x2F;<a href="mailto:&#99;&#x65;&#112;&#104;&#x2d;&#109;&#x6f;&#110;&#x40;&#x69;&#100;&#99;&#118;&#45;&#x63;&#x65;&#112;&#104;&#x30;&#46;&#115;&#101;&#114;&#118;&#x69;&#x63;&#x65;">&#99;&#x65;&#112;&#104;&#x2d;&#109;&#x6f;&#110;&#x40;&#x69;&#100;&#99;&#118;&#45;&#x63;&#x65;&#112;&#104;&#x30;&#46;&#115;&#101;&#114;&#118;&#x69;&#x63;&#x65;</a> to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mon@.service. [idcv-ceph0][INFO ] Running command: systemctl start ceph-mon@idcv-ceph0 [idcv-ceph0][INFO ] Running command: ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph0.asok mon_status [idcv-ceph0][DEBUG ] ******************************************************************************** [idcv-ceph0][DEBUG ] status for monitor: mon.idcv-ceph0 [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “election_epoch”: 0, [idcv-ceph0][DEBUG ] “extra_probe_peers”: [ [idcv-ceph0][DEBUG ] “172.20.1.139:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “172.20.1.140:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “172.20.1.141:6789&#x2F;0” [idcv-ceph0][DEBUG ] ], [idcv-ceph0][DEBUG ] “monmap”: { [idcv-ceph0][DEBUG ] “created”: “2018-07-03 11:06:12.249491”, [idcv-ceph0][DEBUG ] “epoch”: 0, [idcv-ceph0][DEBUG ] “fsid”: “812d3acb-eaa8-4355-9a74-64f2cd5209b3”, [idcv-ceph0][DEBUG ] “modified”: “2018-07-03 11:06:12.249491”, [idcv-ceph0][DEBUG ] “mons”: [ [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “172.20.1.138:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph0][DEBUG ] “rank”: 0 [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “0.0.0.0:0&#x2F;1”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph1”, [idcv-ceph0][DEBUG ] “rank”: 1 [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “0.0.0.0:0&#x2F;2”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph0][DEBUG ] “rank”: 2 [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “0.0.0.0:0&#x2F;3”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph0][DEBUG ] “rank”: 3 [idcv-ceph0][DEBUG ] } [idcv-ceph0][DEBUG ] ] [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph0][DEBUG ] “outside_quorum”: [ [idcv-ceph0][DEBUG ] “idcv-ceph0” [idcv-ceph0][DEBUG ] ], [idcv-ceph0][DEBUG ] “quorum”: [], [idcv-ceph0][DEBUG ] “rank”: 0, [idcv-ceph0][DEBUG ] “state”: “probing”, [idcv-ceph0][DEBUG ] “sync_provider”: [] [idcv-ceph0][DEBUG ] } [idcv-ceph0][DEBUG ] ******************************************************************************** [idcv-ceph0][INFO ] monitor: mon.idcv-ceph0 is running [idcv-ceph0][INFO ] Running command: ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph0.asok mon_status [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph1 … [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [idcv-ceph1][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph1][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph1][DEBUG ] get remote short hostname [idcv-ceph1][DEBUG ] deploying mon to idcv-ceph1 [idcv-ceph1][DEBUG ] get remote short hostname [idcv-ceph1][DEBUG ] remote hostname: idcv-ceph1 [idcv-ceph1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [ceph_deploy.mon][ERROR ] RuntimeError: config file &#x2F;etc&#x2F;ceph&#x2F;ceph.conf exists with different content; use –overwrite-conf to overwrite [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph2 … [idcv-ceph2][DEBUG ] connection detected need for sudo [idcv-ceph2][DEBUG ] connected to host: idcv-ceph2 [idcv-ceph2][DEBUG ] detect platform information from remote host [idcv-ceph2][DEBUG ] detect machine type [idcv-ceph2][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph2][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph2][DEBUG ] get remote short hostname [idcv-ceph2][DEBUG ] deploying mon to idcv-ceph2 [idcv-ceph2][DEBUG ] get remote short hostname [idcv-ceph2][DEBUG ] remote hostname: idcv-ceph2 [idcv-ceph2][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph2][DEBUG ] create the mon path if it does not exist [idcv-ceph2][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph2&#x2F;done [idcv-ceph2][DEBUG ] done path does not exist: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph2&#x2F;done [idcv-ceph2][INFO ] creating keyring file: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph2.mon.keyring [idcv-ceph2][DEBUG ] create the monitor keyring file [idcv-ceph2][INFO ] Running command: sudo ceph-mon –cluster ceph –mkfs -i idcv-ceph2 –keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph2.mon.keyring –setuser 167 –setgroup 167 [idcv-ceph2][DEBUG ] ceph-mon: renaming mon.noname-c 172.20.1.140:6789&#x2F;0 to mon.idcv-ceph2 [idcv-ceph2][DEBUG ] ceph-mon: set fsid to 812d3acb-eaa8-4355-9a74-64f2cd5209b3 [idcv-ceph2][DEBUG ] ceph-mon: created monfs at &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph2 for mon.idcv-ceph2 [idcv-ceph2][INFO ] unlinking keyring file &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph2.mon.keyring [idcv-ceph2][DEBUG ] create a done file to avoid re-doing the mon deployment [idcv-ceph2][DEBUG ] create the init path if it does not exist [idcv-ceph2][INFO ] Running command: sudo systemctl enable ceph.target [idcv-ceph2][INFO ] Running command: sudo systemctl enable ceph-mon@idcv-ceph2 [idcv-ceph2][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mon.target.wants&#x2F;<a href="mailto:&#99;&#x65;&#112;&#104;&#45;&#109;&#111;&#110;&#64;&#x69;&#100;&#99;&#118;&#x2d;&#99;&#x65;&#x70;&#104;&#50;&#x2e;&#115;&#x65;&#x72;&#118;&#105;&#99;&#x65;">&#99;&#x65;&#112;&#104;&#45;&#109;&#111;&#110;&#64;&#x69;&#100;&#99;&#118;&#x2d;&#99;&#x65;&#x70;&#104;&#50;&#x2e;&#115;&#x65;&#x72;&#118;&#105;&#99;&#x65;</a> to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mon@.service. [idcv-ceph2][INFO ] Running command: sudo systemctl start ceph-mon@idcv-ceph2 [idcv-ceph2][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph2.asok mon_status [idcv-ceph2][DEBUG ] ******************************************************************************** [idcv-ceph2][DEBUG ] status for monitor: mon.idcv-ceph2 [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “election_epoch”: 0, [idcv-ceph2][DEBUG ] “extra_probe_peers”: [ [idcv-ceph2][DEBUG ] “172.20.1.138:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “172.20.1.139:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “172.20.1.141:6789&#x2F;0” [idcv-ceph2][DEBUG ] ], [idcv-ceph2][DEBUG ] “monmap”: { [idcv-ceph2][DEBUG ] “created”: “2018-07-03 11:06:15.703352”, [idcv-ceph2][DEBUG ] “epoch”: 0, [idcv-ceph2][DEBUG ] “fsid”: “812d3acb-eaa8-4355-9a74-64f2cd5209b3”, [idcv-ceph2][DEBUG ] “modified”: “2018-07-03 11:06:15.703352”, [idcv-ceph2][DEBUG ] “mons”: [ [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “172.20.1.138:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph2][DEBUG ] “rank”: 0 [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “172.20.1.140:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph2][DEBUG ] “rank”: 1 [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “0.0.0.0:0&#x2F;2”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph1”, [idcv-ceph2][DEBUG ] “rank”: 2 [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “0.0.0.0:0&#x2F;3”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph2][DEBUG ] “rank”: 3 [idcv-ceph2][DEBUG ] } [idcv-ceph2][DEBUG ] ] [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph2][DEBUG ] “outside_quorum”: [ [idcv-ceph2][DEBUG ] “idcv-ceph0”, [idcv-ceph2][DEBUG ] “idcv-ceph2” [idcv-ceph2][DEBUG ] ], [idcv-ceph2][DEBUG ] “quorum”: [], [idcv-ceph2][DEBUG ] “rank”: 1, [idcv-ceph2][DEBUG ] “state”: “probing”, [idcv-ceph2][DEBUG ] “sync_provider”: [] [idcv-ceph2][DEBUG ] } [idcv-ceph2][DEBUG ] ******************************************************************************** [idcv-ceph2][INFO ] monitor: mon.idcv-ceph2 is running [idcv-ceph2][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph2.asok mon_status [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph3 … [idcv-ceph3][DEBUG ] connection detected need for sudo [idcv-ceph3][DEBUG ] connected to host: idcv-ceph3 [idcv-ceph3][DEBUG ] detect platform information from remote host [idcv-ceph3][DEBUG ] detect machine type [idcv-ceph3][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph3][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph3][DEBUG ] get remote short hostname [idcv-ceph3][DEBUG ] deploying mon to idcv-ceph3 [idcv-ceph3][DEBUG ] get remote short hostname [idcv-ceph3][DEBUG ] remote hostname: idcv-ceph3 [idcv-ceph3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph3][DEBUG ] create the mon path if it does not exist [idcv-ceph3][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph3&#x2F;done [idcv-ceph3][DEBUG ] done path does not exist: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph3&#x2F;done [idcv-ceph3][INFO ] creating keyring file: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph3.mon.keyring [idcv-ceph3][DEBUG ] create the monitor keyring file [idcv-ceph3][INFO ] Running command: sudo ceph-mon –cluster ceph –mkfs -i idcv-ceph3 –keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph3.mon.keyring –setuser 167 –setgroup 167 [idcv-ceph3][DEBUG ] ceph-mon: renaming mon.noname-d 172.20.1.141:6789&#x2F;0 to mon.idcv-ceph3 [idcv-ceph3][DEBUG ] ceph-mon: set fsid to 812d3acb-eaa8-4355-9a74-64f2cd5209b3 [idcv-ceph3][DEBUG ] ceph-mon: created monfs at &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph3 for mon.idcv-ceph3 [idcv-ceph3][INFO ] unlinking keyring file &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;ceph-idcv-ceph3.mon.keyring [idcv-ceph3][DEBUG ] create a done file to avoid re-doing the mon deployment [idcv-ceph3][DEBUG ] create the init path if it does not exist [idcv-ceph3][INFO ] Running command: sudo systemctl enable ceph.target [idcv-ceph3][INFO ] Running command: sudo systemctl enable ceph-mon@idcv-ceph3 [idcv-ceph3][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-mon.target.wants&#x2F;<a href="mailto:&#99;&#x65;&#112;&#104;&#x2d;&#109;&#111;&#110;&#x40;&#x69;&#100;&#99;&#x76;&#x2d;&#x63;&#x65;&#112;&#104;&#x33;&#x2e;&#x73;&#101;&#x72;&#118;&#x69;&#x63;&#x65;">&#99;&#x65;&#112;&#104;&#x2d;&#109;&#111;&#110;&#x40;&#x69;&#100;&#99;&#x76;&#x2d;&#x63;&#x65;&#112;&#104;&#x33;&#x2e;&#x73;&#101;&#x72;&#118;&#x69;&#x63;&#x65;</a> to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-mon@.service. [idcv-ceph3][INFO ] Running command: sudo systemctl start ceph-mon@idcv-ceph3 [idcv-ceph3][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph3.asok mon_status [idcv-ceph3][DEBUG ] ******************************************************************************** [idcv-ceph3][DEBUG ] status for monitor: mon.idcv-ceph3 [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “election_epoch”: 1, [idcv-ceph3][DEBUG ] “extra_probe_peers”: [ [idcv-ceph3][DEBUG ] “172.20.1.138:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “172.20.1.139:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “172.20.1.140:6789&#x2F;0” [idcv-ceph3][DEBUG ] ], [idcv-ceph3][DEBUG ] “monmap”: { [idcv-ceph3][DEBUG ] “created”: “2018-07-03 11:06:18.695039”, [idcv-ceph3][DEBUG ] “epoch”: 0, [idcv-ceph3][DEBUG ] “fsid”: “812d3acb-eaa8-4355-9a74-64f2cd5209b3”, [idcv-ceph3][DEBUG ] “modified”: “2018-07-03 11:06:18.695039”, [idcv-ceph3][DEBUG ] “mons”: [ [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “172.20.1.138:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph3][DEBUG ] “rank”: 0 [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “172.20.1.140:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph3][DEBUG ] “rank”: 1 [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “172.20.1.141:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph3][DEBUG ] “rank”: 2 [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “0.0.0.0:0&#x2F;2”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph1”, [idcv-ceph3][DEBUG ] “rank”: 3 [idcv-ceph3][DEBUG ] } [idcv-ceph3][DEBUG ] ] [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph3][DEBUG ] “outside_quorum”: [], [idcv-ceph3][DEBUG ] “quorum”: [], [idcv-ceph3][DEBUG ] “rank”: 2, [idcv-ceph3][DEBUG ] “state”: “electing”, [idcv-ceph3][DEBUG ] “sync_provider”: [] [idcv-ceph3][DEBUG ] } [idcv-ceph3][DEBUG ] ******************************************************************************** [idcv-ceph3][INFO ] monitor: mon.idcv-ceph3 is running [idcv-ceph3][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph3.asok mon_status [ceph_deploy][ERROR ] GenericError: Failed to create 1 monitors</p>
</blockquote>
<p>3、注意mon节点只能是奇数，根据上面报错有一个节点没有安装成功mon服务，需要把idcv-ceph1删掉</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# cat ceph.conf [global] fsid &#x3D; 812d3acb-eaa8-4355-9a74-64f2cd5209b3 mon_initial_members &#x3D; idcv-ceph0, idcv-ceph1, idcv-ceph2, idcv-ceph3 mon_host &#x3D; 172.20.1.138,172.20.1.139,172.20.1.140,172.20.1.141 auth_cluster_required &#x3D; cephx auth_service_required &#x3D; cephx auth_client_required &#x3D; cephx public_network &#x3D; 172.20.0.0&#x2F;20 mon_clock_drift_allowed &#x3D; 2 [root@idcv-ceph0 cluster]# ceph mon remove idcv-ceph1 removing mon.idcv-ceph1 at 0.0.0.0:0&#x2F;1, there will be 3 monitors [root@idcv-ceph0 cluster]# ceph -s cluster 812d3acb-eaa8-4355-9a74-64f2cd5209b3 health HEALTH_ERR 64 pgs are stuck inactive for more than 300 seconds 64 pgs stuck inactive 64 pgs stuck unclean no osds monmap e2: 3 mons at {idcv-ceph0&#x3D;172.20.1.138:6789&#x2F;0,idcv-ceph2&#x3D;172.20.1.140:6789&#x2F;0,idcv-ceph3&#x3D;172.20.1.141:6789&#x2F;0} election epoch 8, quorum 0,1,2 idcv-ceph0,idcv-ceph2,idcv-ceph3 osdmap e1: 0 osds: 0 up, 0 in flags sortbitwise,require_jewel_osds pgmap v2: 64 pgs, 1 pools, 0 bytes data, 0 objects 0 kB used, 0 kB &#x2F; 0 kB avail 64 creating</p>
</blockquote>
<p>4、也可以修改ceph.conf文件，再覆盖部署一次</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# cat ceph.conf [global] fsid &#x3D; 812d3acb-eaa8-4355-9a74-64f2cd5209b3 mon_initial_members &#x3D; idcv-ceph0, idcv-ceph2, idcv-ceph3 mon_host &#x3D; 172.20.1.138,172.20.1.140,172.20.1.141 auth_cluster_required &#x3D; cephx auth_service_required &#x3D; cephx auth_client_required &#x3D; cephx public_network &#x3D; 172.20.0.0&#x2F;20 mon_clock_drift_allowed &#x3D; 2 [root@idcv-ceph0 cluster]# ceph-deploy –overwrite-conf mon create-initial [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy –overwrite-conf mon create-initial [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] subcommand : create-initial [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fce9cf7a368&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] keyrings : None [ceph_deploy.mon][DEBUG ] Deploying mon, cluster ceph hosts idcv-ceph0 idcv-ceph2 idcv-ceph3 [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph0 … [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph0][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph0][DEBUG ] get remote short hostname [idcv-ceph0][DEBUG ] deploying mon to idcv-ceph0 [idcv-ceph0][DEBUG ] get remote short hostname [idcv-ceph0][DEBUG ] remote hostname: idcv-ceph0 [idcv-ceph0][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph0][DEBUG ] create the mon path if it does not exist [idcv-ceph0][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;done [idcv-ceph0][DEBUG ] create a done file to avoid re-doing the mon deployment [idcv-ceph0][DEBUG ] create the init path if it does not exist [idcv-ceph0][INFO ] Running command: systemctl enable ceph.target [idcv-ceph0][INFO ] Running command: systemctl enable ceph-mon@idcv-ceph0 [idcv-ceph0][INFO ] Running command: systemctl start ceph-mon@idcv-ceph0 [idcv-ceph0][INFO ] Running command: ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph0.asok mon_status [idcv-ceph0][DEBUG ] ******************************************************************************** [idcv-ceph0][DEBUG ] status for monitor: mon.idcv-ceph0 [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “election_epoch”: 8, [idcv-ceph0][DEBUG ] “extra_probe_peers”: [ [idcv-ceph0][DEBUG ] “172.20.1.139:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “172.20.1.140:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “172.20.1.141:6789&#x2F;0” [idcv-ceph0][DEBUG ] ], [idcv-ceph0][DEBUG ] “monmap”: { [idcv-ceph0][DEBUG ] “created”: “2018-07-03 11:06:12.249491”, [idcv-ceph0][DEBUG ] “epoch”: 2, [idcv-ceph0][DEBUG ] “fsid”: “812d3acb-eaa8-4355-9a74-64f2cd5209b3”, [idcv-ceph0][DEBUG ] “modified”: “2018-07-03 11:21:27.254076”, [idcv-ceph0][DEBUG ] “mons”: [ [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “172.20.1.138:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph0][DEBUG ] “rank”: 0 [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “172.20.1.140:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph0][DEBUG ] “rank”: 1 [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] { [idcv-ceph0][DEBUG ] “addr”: “172.20.1.141:6789&#x2F;0”, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph0][DEBUG ] “rank”: 2 [idcv-ceph0][DEBUG ] } [idcv-ceph0][DEBUG ] ] [idcv-ceph0][DEBUG ] }, [idcv-ceph0][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph0][DEBUG ] “outside_quorum”: [], [idcv-ceph0][DEBUG ] “quorum”: [ [idcv-ceph0][DEBUG ] 0, [idcv-ceph0][DEBUG ] 1, [idcv-ceph0][DEBUG ] 2 [idcv-ceph0][DEBUG ] ], [idcv-ceph0][DEBUG ] “rank”: 0, [idcv-ceph0][DEBUG ] “state”: “leader”, [idcv-ceph0][DEBUG ] “sync_provider”: [] [idcv-ceph0][DEBUG ] } [idcv-ceph0][DEBUG ] ******************************************************************************** [idcv-ceph0][INFO ] monitor: mon.idcv-ceph0 is running [idcv-ceph0][INFO ] Running command: ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph0.asok mon_status [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph2 … [idcv-ceph2][DEBUG ] connection detected need for sudo [idcv-ceph2][DEBUG ] connected to host: idcv-ceph2 [idcv-ceph2][DEBUG ] detect platform information from remote host [idcv-ceph2][DEBUG ] detect machine type [idcv-ceph2][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph2][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph2][DEBUG ] get remote short hostname [idcv-ceph2][DEBUG ] deploying mon to idcv-ceph2 [idcv-ceph2][DEBUG ] get remote short hostname [idcv-ceph2][DEBUG ] remote hostname: idcv-ceph2 [idcv-ceph2][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph2][DEBUG ] create the mon path if it does not exist [idcv-ceph2][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph2&#x2F;done [idcv-ceph2][DEBUG ] create a done file to avoid re-doing the mon deployment [idcv-ceph2][DEBUG ] create the init path if it does not exist [idcv-ceph2][INFO ] Running command: sudo systemctl enable ceph.target [idcv-ceph2][INFO ] Running command: sudo systemctl enable ceph-mon@idcv-ceph2 [idcv-ceph2][INFO ] Running command: sudo systemctl start ceph-mon@idcv-ceph2 [idcv-ceph2][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph2.asok mon_status [idcv-ceph2][DEBUG ] ******************************************************************************** [idcv-ceph2][DEBUG ] status for monitor: mon.idcv-ceph2 [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “election_epoch”: 8, [idcv-ceph2][DEBUG ] “extra_probe_peers”: [ [idcv-ceph2][DEBUG ] “172.20.1.138:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “172.20.1.139:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “172.20.1.141:6789&#x2F;0” [idcv-ceph2][DEBUG ] ], [idcv-ceph2][DEBUG ] “monmap”: { [idcv-ceph2][DEBUG ] “created”: “2018-07-03 11:06:12.249491”, [idcv-ceph2][DEBUG ] “epoch”: 2, [idcv-ceph2][DEBUG ] “fsid”: “812d3acb-eaa8-4355-9a74-64f2cd5209b3”, [idcv-ceph2][DEBUG ] “modified”: “2018-07-03 11:21:27.254076”, [idcv-ceph2][DEBUG ] “mons”: [ [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “172.20.1.138:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph2][DEBUG ] “rank”: 0 [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “172.20.1.140:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph2][DEBUG ] “rank”: 1 [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] { [idcv-ceph2][DEBUG ] “addr”: “172.20.1.141:6789&#x2F;0”, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph2][DEBUG ] “rank”: 2 [idcv-ceph2][DEBUG ] } [idcv-ceph2][DEBUG ] ] [idcv-ceph2][DEBUG ] }, [idcv-ceph2][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph2][DEBUG ] “outside_quorum”: [], [idcv-ceph2][DEBUG ] “quorum”: [ [idcv-ceph2][DEBUG ] 0, [idcv-ceph2][DEBUG ] 1, [idcv-ceph2][DEBUG ] 2 [idcv-ceph2][DEBUG ] ], [idcv-ceph2][DEBUG ] “rank”: 1, [idcv-ceph2][DEBUG ] “state”: “peon”, [idcv-ceph2][DEBUG ] “sync_provider”: [] [idcv-ceph2][DEBUG ] } [idcv-ceph2][DEBUG ] ******************************************************************************** [idcv-ceph2][INFO ] monitor: mon.idcv-ceph2 is running [idcv-ceph2][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph2.asok mon_status [ceph_deploy.mon][DEBUG ] detecting platform for host idcv-ceph3 … [idcv-ceph3][DEBUG ] connection detected need for sudo [idcv-ceph3][DEBUG ] connected to host: idcv-ceph3 [idcv-ceph3][DEBUG ] detect platform information from remote host [idcv-ceph3][DEBUG ] detect machine type [idcv-ceph3][DEBUG ] find the location of an executable [ceph_deploy.mon][INFO ] distro info: CentOS Linux 7.5.1804 Core [idcv-ceph3][DEBUG ] determining if provided host has same hostname in remote [idcv-ceph3][DEBUG ] get remote short hostname [idcv-ceph3][DEBUG ] deploying mon to idcv-ceph3 [idcv-ceph3][DEBUG ] get remote short hostname [idcv-ceph3][DEBUG ] remote hostname: idcv-ceph3 [idcv-ceph3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph3][DEBUG ] create the mon path if it does not exist [idcv-ceph3][DEBUG ] checking for done path: &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph3&#x2F;done [idcv-ceph3][DEBUG ] create a done file to avoid re-doing the mon deployment [idcv-ceph3][DEBUG ] create the init path if it does not exist [idcv-ceph3][INFO ] Running command: sudo systemctl enable ceph.target [idcv-ceph3][INFO ] Running command: sudo systemctl enable ceph-mon@idcv-ceph3 [idcv-ceph3][INFO ] Running command: sudo systemctl start ceph-mon@idcv-ceph3 [idcv-ceph3][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph3.asok mon_status [idcv-ceph3][DEBUG ] ******************************************************************************** [idcv-ceph3][DEBUG ] status for monitor: mon.idcv-ceph3 [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “election_epoch”: 8, [idcv-ceph3][DEBUG ] “extra_probe_peers”: [ [idcv-ceph3][DEBUG ] “172.20.1.138:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “172.20.1.139:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “172.20.1.140:6789&#x2F;0” [idcv-ceph3][DEBUG ] ], [idcv-ceph3][DEBUG ] “monmap”: { [idcv-ceph3][DEBUG ] “created”: “2018-07-03 11:06:12.249491”, [idcv-ceph3][DEBUG ] “epoch”: 2, [idcv-ceph3][DEBUG ] “fsid”: “812d3acb-eaa8-4355-9a74-64f2cd5209b3”, [idcv-ceph3][DEBUG ] “modified”: “2018-07-03 11:21:27.254076”, [idcv-ceph3][DEBUG ] “mons”: [ [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “172.20.1.138:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph0”, [idcv-ceph3][DEBUG ] “rank”: 0 [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “172.20.1.140:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph2”, [idcv-ceph3][DEBUG ] “rank”: 1 [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] { [idcv-ceph3][DEBUG ] “addr”: “172.20.1.141:6789&#x2F;0”, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph3][DEBUG ] “rank”: 2 [idcv-ceph3][DEBUG ] } [idcv-ceph3][DEBUG ] ] [idcv-ceph3][DEBUG ] }, [idcv-ceph3][DEBUG ] “name”: “idcv-ceph3”, [idcv-ceph3][DEBUG ] “outside_quorum”: [], [idcv-ceph3][DEBUG ] “quorum”: [ [idcv-ceph3][DEBUG ] 0, [idcv-ceph3][DEBUG ] 1, [idcv-ceph3][DEBUG ] 2 [idcv-ceph3][DEBUG ] ], [idcv-ceph3][DEBUG ] “rank”: 2, [idcv-ceph3][DEBUG ] “state”: “peon”, [idcv-ceph3][DEBUG ] “sync_provider”: [] [idcv-ceph3][DEBUG ] } [idcv-ceph3][DEBUG ] ******************************************************************************** [idcv-ceph3][INFO ] monitor: mon.idcv-ceph3 is running [idcv-ceph3][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph3.asok mon_status [ceph_deploy.mon][INFO ] processing monitor mon.idcv-ceph0 [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] find the location of an executable [idcv-ceph0][INFO ] Running command: ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph0.asok mon_status [ceph_deploy.mon][INFO ] mon.idcv-ceph0 monitor has reached quorum! [ceph_deploy.mon][INFO ] processing monitor mon.idcv-ceph2 [idcv-ceph2][DEBUG ] connection detected need for sudo [idcv-ceph2][DEBUG ] connected to host: idcv-ceph2 [idcv-ceph2][DEBUG ] detect platform information from remote host [idcv-ceph2][DEBUG ] detect machine type [idcv-ceph2][DEBUG ] find the location of an executable [idcv-ceph2][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph2.asok mon_status [ceph_deploy.mon][INFO ] mon.idcv-ceph2 monitor has reached quorum! [ceph_deploy.mon][INFO ] processing monitor mon.idcv-ceph3 [idcv-ceph3][DEBUG ] connection detected need for sudo [idcv-ceph3][DEBUG ] connected to host: idcv-ceph3 [idcv-ceph3][DEBUG ] detect platform information from remote host [idcv-ceph3][DEBUG ] detect machine type [idcv-ceph3][DEBUG ] find the location of an executable [idcv-ceph3][INFO ] Running command: sudo ceph –cluster&#x3D;ceph –admin-daemon &#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph3.asok mon_status [ceph_deploy.mon][INFO ] mon.idcv-ceph3 monitor has reached quorum! [ceph_deploy.mon][INFO ] all initial monitors are running and have formed quorum [ceph_deploy.mon][INFO ] Running gatherkeys… [ceph_deploy.gatherkeys][INFO ] Storing keys in temp directory &#x2F;tmp&#x2F;tmpBqY1be [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] get remote short hostname [idcv-ceph0][DEBUG ] fetch remote file [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –admin-daemon&#x3D;&#x2F;var&#x2F;run&#x2F;ceph&#x2F;ceph-mon.idcv-ceph0.asok mon_status [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –name mon. –keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;keyring auth get client.admin [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –name mon. –keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;keyring auth get client.bootstrap-mds [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –name mon. –keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;keyring auth get client.bootstrap-mgr [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –name mon. –keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;keyring auth get-or-create client.bootstrap-mgr mon allow profile bootstrap-mgr [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –name mon. –keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;keyring auth get client.bootstrap-osd [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –connect-timeout&#x3D;25 –cluster&#x3D;ceph –name mon. –keyring&#x3D;&#x2F;var&#x2F;lib&#x2F;ceph&#x2F;mon&#x2F;ceph-idcv-ceph0&#x2F;keyring auth get client.bootstrap-rgw [ceph_deploy.gatherkeys][INFO ] Storing ceph.client.admin.keyring [ceph_deploy.gatherkeys][INFO ] Storing ceph.bootstrap-mds.keyring [ceph_deploy.gatherkeys][INFO ] Storing ceph.bootstrap-mgr.keyring [ceph_deploy.gatherkeys][INFO ] keyring ‘ceph.mon.keyring’ already exists [ceph_deploy.gatherkeys][INFO ] Storing ceph.bootstrap-osd.keyring [ceph_deploy.gatherkeys][INFO ] Storing ceph.bootstrap-rgw.keyring [ceph_deploy.gatherkeys][INFO ] Destroy temp directory &#x2F;tmp&#x2F;tmpBqY1be [root@idcv-ceph0 cluster]# ls ceph.bootstrap-mds.keyring ceph.bootstrap-osd.keyring ceph.client.admin.keyring ceph-deploy-ceph.lo</p>
</blockquote>
<h4 id="五、部署OSD角色"><a href="#五、部署OSD角色" class="headerlink" title="五、部署OSD角色"></a>五、部署OSD角色</h4><p>先准备后激活 ceph-deploy –overwrite-conf osd prepare idcv-ceph0:&#x2F;dev&#x2F;sdb idcv-ceph1:&#x2F;dev&#x2F;sdb idcv-ceph2:&#x2F;dev&#x2F;sdb idcv-ceph3:&#x2F;dev&#x2F;sdb –zap-disk ceph-deploy –overwrite-conf osd activate idcv-ceph0:&#x2F;dev&#x2F;sdb1 idcv-ceph1:&#x2F;dev&#x2F;sdb1 idcv-ceph2:&#x2F;dev&#x2F;sdb1 idcv-ceph3:&#x2F;dev&#x2F;sdb1</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph-deploy –overwrite-conf osd prepare idcv-ceph0:&#x2F;dev&#x2F;sdb idcv-ceph1:&#x2F;dev&#x2F;sdb idcv-ceph2:&#x2F;dev&#x2F;sdb idcv-ceph3:&#x2F;dev&#x2F;sdb –zap-disk [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy –overwrite-conf osd prepare idcv-ceph0:&#x2F;dev&#x2F;sdb idcv-ceph1:&#x2F;dev&#x2F;sdb idcv-ceph2:&#x2F;dev&#x2F;sdb idcv-ceph3:&#x2F;dev&#x2F;sdb –zap-disk [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] block_db : None [ceph_deploy.cli][INFO ] disk : [(‘idcv-ceph0’, ‘&#x2F;dev&#x2F;sdb’, None), (‘idcv-ceph1’, ‘&#x2F;dev&#x2F;sdb’, None), (‘idcv-ceph2’, ‘&#x2F;dev&#x2F;sdb’, None), (‘idcv-ceph3’, ‘&#x2F;dev&#x2F;sdb’, None)] [ceph_deploy.cli][INFO ] dmcrypt : False [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] bluestore : None [ceph_deploy.cli][INFO ] block_wal : None [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] subcommand : prepare [ceph_deploy.cli][INFO ] dmcrypt_key_dir : &#x2F;etc&#x2F;ceph&#x2F;dmcrypt-keys [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f103c7f35a8&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] fs_type : xfs [ceph_deploy.cli][INFO ] filestore : None [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] zap_disk : True [ceph_deploy.osd][DEBUG ] Preparing cluster ceph disks idcv-ceph0:&#x2F;dev&#x2F;sdb: idcv-ceph1:&#x2F;dev&#x2F;sdb: idcv-ceph2:&#x2F;dev&#x2F;sdb: idcv-ceph3:&#x2F;dev&#x2F;sdb: [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] find the location of an executable [ceph_deploy.osd][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.osd][DEBUG ] Deploying osd to idcv-ceph0 [idcv-ceph0][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [ceph_deploy.osd][DEBUG ] Preparing host idcv-ceph0 disk &#x2F;dev&#x2F;sdb journal None activate False [idcv-ceph0][DEBUG ] find the location of an executable [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v prepare –zap-disk –cluster ceph –fs-type xfs – &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;fsid [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-allows-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-wants-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-needs-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] set_type: Will colocate journal with data on &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;osd_journal_size [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mkfs_options_xfs [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mkfs_options_xfs [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mount_options_xfs [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mount_options_xfs [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] zap: Zapping partition table on &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;sbin&#x2F;sgdisk –zap-all – &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] Caution: invalid backup GPT header, but valid main header; regenerating [idcv-ceph0][WARNIN] backup header from main header. [idcv-ceph0][WARNIN] [idcv-ceph0][DEBUG ] **************************************************************************** [idcv-ceph0][DEBUG ] Caution: Found protective or hybrid MBR and corrupt GPT. Using GPT, but disk [idcv-ceph0][DEBUG ] verification and recovery are STRONGLY recommended. [idcv-ceph0][DEBUG ] **************************************************************************** [idcv-ceph0][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or [idcv-ceph0][DEBUG ] other utilities. [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;sbin&#x2F;sgdisk –clear –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph0][DEBUG ] Creating new GPT entries. [idcv-ceph0][DEBUG ] The operation has completed successfully. [idcv-ceph0][WARNIN] update_partition: Calling partprobe on zapped device &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;usr&#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] ptype_tobe_for_name: name &#x3D; journal [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] create_partition: Creating journal partition num 2 size 5120 on &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;sbin&#x2F;sgdisk –new&#x3D;2:0:+5120M –change-name&#x3D;2:ceph journal –partition-guid&#x3D;2:ca6594bd-a4b2-4be7-9aa5-69ba91ce7441 –typecode&#x3D;2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph0][DEBUG ] The operation has completed successfully. [idcv-ceph0][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;usr&#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb2 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:18&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;ca6594bd-a4b2-4be7-9aa5-69ba91ce7441 [idcv-ceph0][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;ca6594bd-a4b2-4be7-9aa5-69ba91ce7441 [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] set_data_partition: Creating osd partition on &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] ptype_tobe_for_name: name &#x3D; data [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] create_partition: Creating data partition num 1 size 0 on &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;sbin&#x2F;sgdisk –largest-new&#x3D;1 –change-name&#x3D;1:ceph data –partition-guid&#x3D;1:3b210c8e-b2ac-4266-9e59-623c031ebb89 –typecode&#x3D;1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph0][DEBUG ] The operation has completed successfully. [idcv-ceph0][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;usr&#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb1 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:17&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] populate_data_path_device: Creating xfs fs on &#x2F;dev&#x2F;sdb1 [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;sbin&#x2F;mkfs -t xfs -f -i size&#x3D;2048 – &#x2F;dev&#x2F;sdb1 [idcv-ceph0][DEBUG ] meta-data&#x3D;&#x2F;dev&#x2F;sdb1 isize&#x3D;2048 agcount&#x3D;4, agsize&#x3D;6225855 blks [idcv-ceph0][DEBUG ] &#x3D; sectsz&#x3D;512 attr&#x3D;2, projid32bit&#x3D;1 [idcv-ceph0][DEBUG ] &#x3D; crc&#x3D;1 finobt&#x3D;0, sparse&#x3D;0 [idcv-ceph0][DEBUG ] data &#x3D; bsize&#x3D;4096 blocks&#x3D;24903419, imaxpct&#x3D;25 [idcv-ceph0][DEBUG ] &#x3D; sunit&#x3D;0 swidth&#x3D;0 blks [idcv-ceph0][DEBUG ] naming &#x3D;version 2 bsize&#x3D;4096 ascii-ci&#x3D;0 ftype&#x3D;1 [idcv-ceph0][DEBUG ] log &#x3D;internal log bsize&#x3D;4096 blocks&#x3D;12159, version&#x3D;2 [idcv-ceph0][DEBUG ] &#x3D; sectsz&#x3D;512 sunit&#x3D;0 blks, lazy-count&#x3D;1 [idcv-ceph0][DEBUG ] realtime &#x3D;none extsz&#x3D;4096 blocks&#x3D;0, rtextents&#x3D;0 [idcv-ceph0][WARNIN] mount: Mounting &#x2F;dev&#x2F;sdb1 on &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq with options noatime,inode64 [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;mount -t xfs -o noatime,inode64 – &#x2F;dev&#x2F;sdb1 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] populate_data_path: Preparing osd data dir &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;ceph_fsid.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;ceph_fsid.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;fsid.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;fsid.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;magic.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;magic.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;journal_uuid.2933.tmp [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;journal_uuid.2933.tmp [idcv-ceph0][WARNIN] adjust_symlink: Creating symlink &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq&#x2F;journal -&gt; &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;ca6594bd-a4b2-4be7-9aa5-69ba91ce7441 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] unmount: Unmounting &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;bin&#x2F;umount – &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.kvs_nq [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;sbin&#x2F;sgdisk –typecode&#x3D;1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d – &#x2F;dev&#x2F;sdb [idcv-ceph0][DEBUG ] Warning: The kernel is still using the old partition table. [idcv-ceph0][DEBUG ] The new table will be used at the next reboot. [idcv-ceph0][DEBUG ] The operation has completed successfully. [idcv-ceph0][WARNIN] update_partition: Calling partprobe on prepared device &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;usr&#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm trigger –action&#x3D;add –sysname-match sdb1 [idcv-ceph0][INFO ] checking OSD status… [idcv-ceph0][DEBUG ] find the location of an executable [idcv-ceph0][INFO ] Running command: &#x2F;bin&#x2F;ceph –cluster&#x3D;ceph osd stat –format&#x3D;json [ceph_deploy.osd][DEBUG ] Host idcv-ceph0 is now ready for osd use. [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [idcv-ceph1][DEBUG ] find the location of an executable [ceph_deploy.osd][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.osd][DEBUG ] Deploying osd to idcv-ceph1 [idcv-ceph1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [ceph_deploy.osd][DEBUG ] Preparing host idcv-ceph1 disk &#x2F;dev&#x2F;sdb journal None activate False [idcv-ceph1][DEBUG ] find the location of an executable [idcv-ceph1][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v prepare –zap-disk –cluster ceph –fs-type xfs – &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;fsid [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-allows-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-wants-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-needs-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] set_type: Will colocate journal with data on &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;osd_journal_size [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mkfs_options_xfs [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mkfs_options_xfs [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mount_options_xfs [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mount_options_xfs [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] zap: Zapping partition table on &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –zap-all – &#x2F;dev&#x2F;sdb [idcv-ceph1][DEBUG ] Creating new GPT entries. [idcv-ceph1][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or [idcv-ceph1][DEBUG ] other utilities. [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –clear –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph1][DEBUG ] Creating new GPT entries. [idcv-ceph1][DEBUG ] The operation has completed successfully. [idcv-ceph1][WARNIN] update_partition: Calling partprobe on zapped device &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] ptype_tobe_for_name: name &#x3D; journal [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] create_partition: Creating journal partition num 2 size 5120 on &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –new&#x3D;2:0:+5120M –change-name&#x3D;2:ceph journal –partition-guid&#x3D;2:09dad07a-985e-4733-a228-f7b1105b7385 –typecode&#x3D;2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph1][DEBUG ] The operation has completed successfully. [idcv-ceph1][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb2 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:18&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;09dad07a-985e-4733-a228-f7b1105b7385 [idcv-ceph1][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;09dad07a-985e-4733-a228-f7b1105b7385 [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] set_data_partition: Creating osd partition on &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] ptype_tobe_for_name: name &#x3D; data [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] create_partition: Creating data partition num 1 size 0 on &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –largest-new&#x3D;1 –change-name&#x3D;1:ceph data –partition-guid&#x3D;1:2809f370-e6ad-4d29-bf6b-57fe1f2004c6 –typecode&#x3D;1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph1][DEBUG ] The operation has completed successfully. [idcv-ceph1][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb1 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:17&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] populate_data_path_device: Creating xfs fs on &#x2F;dev&#x2F;sdb1 [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;mkfs -t xfs -f -i size&#x3D;2048 – &#x2F;dev&#x2F;sdb1 [idcv-ceph1][DEBUG ] meta-data&#x3D;&#x2F;dev&#x2F;sdb1 isize&#x3D;2048 agcount&#x3D;4, agsize&#x3D;6225855 blks [idcv-ceph1][DEBUG ] &#x3D; sectsz&#x3D;512 attr&#x3D;2, projid32bit&#x3D;1 [idcv-ceph1][DEBUG ] &#x3D; crc&#x3D;1 finobt&#x3D;0, sparse&#x3D;0 [idcv-ceph1][DEBUG ] data &#x3D; bsize&#x3D;4096 blocks&#x3D;24903419, imaxpct&#x3D;25 [idcv-ceph1][DEBUG ] &#x3D; sunit&#x3D;0 swidth&#x3D;0 blks [idcv-ceph1][DEBUG ] naming &#x3D;version 2 bsize&#x3D;4096 ascii-ci&#x3D;0 ftype&#x3D;1 [idcv-ceph1][DEBUG ] log &#x3D;internal log bsize&#x3D;4096 blocks&#x3D;12159, version&#x3D;2 [idcv-ceph1][DEBUG ] &#x3D; sectsz&#x3D;512 sunit&#x3D;0 blks, lazy-count&#x3D;1 [idcv-ceph1][DEBUG ] realtime &#x3D;none extsz&#x3D;4096 blocks&#x3D;0, rtextents&#x3D;0 [idcv-ceph1][WARNIN] mount: Mounting &#x2F;dev&#x2F;sdb1 on &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC with options noatime,inode64 [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;mount -t xfs -o noatime,inode64 – &#x2F;dev&#x2F;sdb1 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] populate_data_path: Preparing osd data dir &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;ceph_fsid.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;ceph_fsid.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;fsid.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;fsid.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;magic.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;magic.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;journal_uuid.2415.tmp [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;journal_uuid.2415.tmp [idcv-ceph1][WARNIN] adjust_symlink: Creating symlink &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC&#x2F;journal -&gt; &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;09dad07a-985e-4733-a228-f7b1105b7385 [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] unmount: Unmounting &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;bin&#x2F;umount – &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.HAg1vC [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –typecode&#x3D;1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d – &#x2F;dev&#x2F;sdb [idcv-ceph1][DEBUG ] The operation has completed successfully. [idcv-ceph1][WARNIN] update_partition: Calling partprobe on prepared device &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm trigger –action&#x3D;add –sysname-match sdb1 [idcv-ceph1][INFO ] checking OSD status… [idcv-ceph1][DEBUG ] find the location of an executable [idcv-ceph1][INFO ] Running command: sudo &#x2F;bin&#x2F;ceph –cluster&#x3D;ceph osd stat –format&#x3D;json [ceph_deploy.osd][DEBUG ] Host idcv-ceph1 is now ready for osd use. [idcv-ceph2][DEBUG ] connection detected need for sudo [idcv-ceph2][DEBUG ] connected to host: idcv-ceph2 [idcv-ceph2][DEBUG ] detect platform information from remote host [idcv-ceph2][DEBUG ] detect machine type [idcv-ceph2][DEBUG ] find the location of an executable [ceph_deploy.osd][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.osd][DEBUG ] Deploying osd to idcv-ceph2 [idcv-ceph2][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [ceph_deploy.osd][DEBUG ] Preparing host idcv-ceph2 disk &#x2F;dev&#x2F;sdb journal None activate False [idcv-ceph2][DEBUG ] find the location of an executable [idcv-ceph2][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v prepare –zap-disk –cluster ceph –fs-type xfs – &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;fsid [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-allows-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-wants-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-needs-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] set_type: Will colocate journal with data on &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;osd_journal_size [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mkfs_options_xfs [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mkfs_options_xfs [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mount_options_xfs [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mount_options_xfs [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] zap: Zapping partition table on &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –zap-all – &#x2F;dev&#x2F;sdb [idcv-ceph2][DEBUG ] Creating new GPT entries. [idcv-ceph2][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or [idcv-ceph2][DEBUG ] other utilities. [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –clear –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph2][DEBUG ] Creating new GPT entries. [idcv-ceph2][DEBUG ] The operation has completed successfully. [idcv-ceph2][WARNIN] update_partition: Calling partprobe on zapped device &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] ptype_tobe_for_name: name &#x3D; journal [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] create_partition: Creating journal partition num 2 size 5120 on &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –new&#x3D;2:0:+5120M –change-name&#x3D;2:ceph journal –partition-guid&#x3D;2:857f0966-30d5-4ad1-9e0c-abff0fbbbc4e –typecode&#x3D;2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph2][DEBUG ] The operation has completed successfully. [idcv-ceph2][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb2 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:18&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;857f0966-30d5-4ad1-9e0c-abff0fbbbc4e [idcv-ceph2][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;857f0966-30d5-4ad1-9e0c-abff0fbbbc4e [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] set_data_partition: Creating osd partition on &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] ptype_tobe_for_name: name &#x3D; data [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] create_partition: Creating data partition num 1 size 0 on &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –largest-new&#x3D;1 –change-name&#x3D;1:ceph data –partition-guid&#x3D;1:dac63cc2-6876-4004-ba3b-7786be39d392 –typecode&#x3D;1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph2][DEBUG ] The operation has completed successfully. [idcv-ceph2][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb1 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:17&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] populate_data_path_device: Creating xfs fs on &#x2F;dev&#x2F;sdb1 [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;mkfs -t xfs -f -i size&#x3D;2048 – &#x2F;dev&#x2F;sdb1 [idcv-ceph2][DEBUG ] meta-data&#x3D;&#x2F;dev&#x2F;sdb1 isize&#x3D;2048 agcount&#x3D;4, agsize&#x3D;6225855 blks [idcv-ceph2][DEBUG ] &#x3D; sectsz&#x3D;512 attr&#x3D;2, projid32bit&#x3D;1 [idcv-ceph2][DEBUG ] &#x3D; crc&#x3D;1 finobt&#x3D;0, sparse&#x3D;0 [idcv-ceph2][DEBUG ] data &#x3D; bsize&#x3D;4096 blocks&#x3D;24903419, imaxpct&#x3D;25 [idcv-ceph2][DEBUG ] &#x3D; sunit&#x3D;0 swidth&#x3D;0 blks [idcv-ceph2][DEBUG ] naming &#x3D;version 2 bsize&#x3D;4096 ascii-ci&#x3D;0 ftype&#x3D;1 [idcv-ceph2][DEBUG ] log &#x3D;internal log bsize&#x3D;4096 blocks&#x3D;12159, version&#x3D;2 [idcv-ceph2][DEBUG ] &#x3D; sectsz&#x3D;512 sunit&#x3D;0 blks, lazy-count&#x3D;1 [idcv-ceph2][WARNIN] mount: Mounting &#x2F;dev&#x2F;sdb1 on &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR with options noatime,inode64 [idcv-ceph2][DEBUG ] realtime &#x3D;none extsz&#x3D;4096 blocks&#x3D;0, rtextents&#x3D;0 [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;mount -t xfs -o noatime,inode64 – &#x2F;dev&#x2F;sdb1 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] populate_data_path: Preparing osd data dir &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;ceph_fsid.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;ceph_fsid.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;fsid.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;fsid.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;magic.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;magic.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;journal_uuid.2354.tmp [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;journal_uuid.2354.tmp [idcv-ceph2][WARNIN] adjust_symlink: Creating symlink &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR&#x2F;journal -&gt; &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;857f0966-30d5-4ad1-9e0c-abff0fbbbc4e [idcv-ceph2][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] unmount: Unmounting &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;bin&#x2F;umount – &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.jhzVmR [idcv-ceph2][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –typecode&#x3D;1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d – &#x2F;dev&#x2F;sdb [idcv-ceph2][DEBUG ] Warning: The kernel is still using the old partition table. [idcv-ceph2][DEBUG ] The new table will be used at the next reboot. [idcv-ceph2][DEBUG ] The operation has completed successfully. [idcv-ceph2][WARNIN] update_partition: Calling partprobe on prepared device &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph2][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm trigger –action&#x3D;add –sysname-match sdb1 [idcv-ceph2][INFO ] checking OSD status… [idcv-ceph2][DEBUG ] find the location of an executable [idcv-ceph2][INFO ] Running command: sudo &#x2F;bin&#x2F;ceph –cluster&#x3D;ceph osd stat –format&#x3D;json [ceph_deploy.osd][DEBUG ] Host idcv-ceph2 is now ready for osd use. [idcv-ceph3][DEBUG ] connection detected need for sudo [idcv-ceph3][DEBUG ] connected to host: idcv-ceph3 [idcv-ceph3][DEBUG ] detect platform information from remote host [idcv-ceph3][DEBUG ] detect machine type [idcv-ceph3][DEBUG ] find the location of an executable [ceph_deploy.osd][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.osd][DEBUG ] Deploying osd to idcv-ceph3 [idcv-ceph3][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [ceph_deploy.osd][DEBUG ] Preparing host idcv-ceph3 disk &#x2F;dev&#x2F;sdb journal None activate False [idcv-ceph3][DEBUG ] find the location of an executable [idcv-ceph3][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v prepare –zap-disk –cluster ceph –fs-type xfs – &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;fsid [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-allows-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-wants-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –check-needs-journal -i 0 –log-file $run_dir&#x2F;$cluster-osd-check.log –cluster ceph –setuser ceph –setgroup ceph [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] set_type: Will colocate journal with data on &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;osd_journal_size [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mkfs_options_xfs [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mkfs_options_xfs [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mount_options_xfs [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mount_options_xfs [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] zap: Zapping partition table on &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –zap-all – &#x2F;dev&#x2F;sdb [idcv-ceph3][DEBUG ] Creating new GPT entries. [idcv-ceph3][DEBUG ] GPT data structures destroyed! You may now partition the disk using fdisk or [idcv-ceph3][DEBUG ] other utilities. [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –clear –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph3][DEBUG ] Creating new GPT entries. [idcv-ceph3][DEBUG ] The operation has completed successfully. [idcv-ceph3][WARNIN] update_partition: Calling partprobe on zapped device &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] ptype_tobe_for_name: name &#x3D; journal [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] create_partition: Creating journal partition num 2 size 5120 on &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –new&#x3D;2:0:+5120M –change-name&#x3D;2:ceph journal –partition-guid&#x3D;2:52677a68-3cf4-4d9a-b2d4-8c823e1cb901 –typecode&#x3D;2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph3][DEBUG ] The operation has completed successfully. [idcv-ceph3][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb2 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:18&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;52677a68-3cf4-4d9a-b2d4-8c823e1cb901 [idcv-ceph3][WARNIN] prepare_device: Journal is GPT partition &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;52677a68-3cf4-4d9a-b2d4-8c823e1cb901 [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] set_data_partition: Creating osd partition on &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] ptype_tobe_for_name: name &#x3D; data [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] create_partition: Creating data partition num 1 size 0 on &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –largest-new&#x3D;1 –change-name&#x3D;1:ceph data –partition-guid&#x3D;1:a85b0288-85ce-4887-8249-497ba880fe10 –typecode&#x3D;1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be –mbrtogpt – &#x2F;dev&#x2F;sdb [idcv-ceph3][DEBUG ] The operation has completed successfully. [idcv-ceph3][WARNIN] update_partition: Calling partprobe on created device &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb1 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:17&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] populate_data_path_device: Creating xfs fs on &#x2F;dev&#x2F;sdb1 [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;mkfs -t xfs -f -i size&#x3D;2048 – &#x2F;dev&#x2F;sdb1 [idcv-ceph3][DEBUG ] meta-data&#x3D;&#x2F;dev&#x2F;sdb1 isize&#x3D;2048 agcount&#x3D;4, agsize&#x3D;6225855 blks [idcv-ceph3][DEBUG ] &#x3D; sectsz&#x3D;512 attr&#x3D;2, projid32bit&#x3D;1 [idcv-ceph3][DEBUG ] &#x3D; crc&#x3D;1 finobt&#x3D;0, sparse&#x3D;0 [idcv-ceph3][DEBUG ] data &#x3D; bsize&#x3D;4096 blocks&#x3D;24903419, imaxpct&#x3D;25 [idcv-ceph3][DEBUG ] &#x3D; sunit&#x3D;0 swidth&#x3D;0 blks [idcv-ceph3][DEBUG ] naming &#x3D;version 2 bsize&#x3D;4096 ascii-ci&#x3D;0 ftype&#x3D;1 [idcv-ceph3][DEBUG ] log &#x3D;internal log bsize&#x3D;4096 blocks&#x3D;12159, version&#x3D;2 [idcv-ceph3][DEBUG ] &#x3D; sectsz&#x3D;512 sunit&#x3D;0 blks, lazy-count&#x3D;1 [idcv-ceph3][DEBUG ] realtime &#x3D;none extsz&#x3D;4096 blocks&#x3D;0, rtextents&#x3D;0 [idcv-ceph3][WARNIN] mount: Mounting &#x2F;dev&#x2F;sdb1 on &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj with options noatime,inode64 [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;mount -t xfs -o noatime,inode64 – &#x2F;dev&#x2F;sdb1 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] populate_data_path: Preparing osd data dir &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;ceph_fsid.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;ceph_fsid.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;fsid.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;fsid.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;magic.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;magic.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;journal_uuid.2372.tmp [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;journal_uuid.2372.tmp [idcv-ceph3][WARNIN] adjust_symlink: Creating symlink &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj&#x2F;journal -&gt; &#x2F;dev&#x2F;disk&#x2F;by-partuuid&#x2F;52677a68-3cf4-4d9a-b2d4-8c823e1cb901 [idcv-ceph3][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] unmount: Unmounting &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;bin&#x2F;umount – &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.gjITlj [idcv-ceph3][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:16&#x2F;dm&#x2F;uuid [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;sbin&#x2F;sgdisk –typecode&#x3D;1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d – &#x2F;dev&#x2F;sdb [idcv-ceph3][DEBUG ] Warning: The kernel is still using the old partition table. [idcv-ceph3][DEBUG ] The new table will be used at the next reboot. [idcv-ceph3][DEBUG ] The operation has completed successfully. [idcv-ceph3][WARNIN] update_partition: Calling partprobe on prepared device &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;flock -s &#x2F;dev&#x2F;sdb &#x2F;sbin&#x2F;partprobe &#x2F;dev&#x2F;sdb [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm settle –timeout&#x3D;600 [idcv-ceph3][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;udevadm trigger –action&#x3D;add –sysname-match sdb1 [idcv-ceph3][INFO ] checking OSD status… [idcv-ceph3][DEBUG ] find the location of an executable [idcv-ceph3][INFO ] Running command: sudo &#x2F;bin&#x2F;ceph –cluster&#x3D;ceph osd stat –format&#x3D;json [ceph_deploy.osd][DEBUG ] Host idcv-ceph3 is now ready for osd use. [root@idcv-ceph0 cluster]# ceph-deploy –overwrite-conf osd activate idcv-ceph0:&#x2F;dev&#x2F;sdb1 idcv-ceph1:&#x2F;dev&#x2F;sdb1 idcv-ceph2:&#x2F;dev&#x2F;sdb1 idcv-ceph3:&#x2F;dev&#x2F;sdb1 [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy –overwrite-conf osd activate idcv-ceph0:&#x2F;dev&#x2F;sdb1 idcv-ceph1:&#x2F;dev&#x2F;sdb1 idcv-ceph2:&#x2F;dev&#x2F;sdb1 idcv-ceph3:&#x2F;dev&#x2F;sdb1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : True [ceph_deploy.cli][INFO ] subcommand : activate [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fc94a47f5a8&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] disk : [(‘idcv-ceph0’, ‘&#x2F;dev&#x2F;sdb1’, None), (‘idcv-ceph1’, ‘&#x2F;dev&#x2F;sdb1’, None), (‘idcv-ceph2’, ‘&#x2F;dev&#x2F;sdb1’, None), (‘idcv-ceph3’, ‘&#x2F;dev&#x2F;sdb1’, None)] [ceph_deploy.osd][DEBUG ] Activating cluster ceph disks idcv-ceph0:&#x2F;dev&#x2F;sdb1: idcv-ceph1:&#x2F;dev&#x2F;sdb1: idcv-ceph2:&#x2F;dev&#x2F;sdb1: idcv-ceph3:&#x2F;dev&#x2F;sdb1: [idcv-ceph0][DEBUG ] connected to host: idcv-ceph0 [idcv-ceph0][DEBUG ] detect platform information from remote host [idcv-ceph0][DEBUG ] detect machine type [idcv-ceph0][DEBUG ] find the location of an executable [ceph_deploy.osd][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.osd][DEBUG ] activating host idcv-ceph0 disk &#x2F;dev&#x2F;sdb1 [ceph_deploy.osd][DEBUG ] will use init type: systemd [idcv-ceph0][DEBUG ] find the location of an executable [idcv-ceph0][INFO ] Running command: &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v activate –mark-init systemd –mount &#x2F;dev&#x2F;sdb1 [idcv-ceph0][WARNIN] main_activate: path &#x3D; &#x2F;dev&#x2F;sdb1 [idcv-ceph0][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb1 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:17&#x2F;dm&#x2F;uuid [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;blkid -o udev -p &#x2F;dev&#x2F;sdb1 [idcv-ceph0][WARNIN] command: Running command: &#x2F;sbin&#x2F;blkid -p -s TYPE -o value – &#x2F;dev&#x2F;sdb1 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mount_options_xfs [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mount_options_xfs [idcv-ceph0][WARNIN] mount: Mounting &#x2F;dev&#x2F;sdb1 on &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9 with options noatime,inode64 [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;mount -t xfs -o noatime,inode64 – &#x2F;dev&#x2F;sdb1 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9 [idcv-ceph0][WARNIN] activate: Cluster uuid is 812d3acb-eaa8-4355-9a74-64f2cd5209b3 [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;fsid [idcv-ceph0][WARNIN] activate: Cluster name is ceph [idcv-ceph0][WARNIN] activate: OSD uuid is 3b210c8e-b2ac-4266-9e59-623c031ebb89 [idcv-ceph0][WARNIN] activate: OSD id is 0 [idcv-ceph0][WARNIN] activate: Marking with init system systemd [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;sbin&#x2F;restorecon -R &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9&#x2F;systemd [idcv-ceph0][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;chown -R ceph:ceph &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9&#x2F;systemd [idcv-ceph0][WARNIN] activate: ceph osd.0 data dir is ready at &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9 [idcv-ceph0][WARNIN] mount_activate: ceph osd.0 already mounted in position; unmounting ours. [idcv-ceph0][WARNIN] unmount: Unmounting &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9 [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;bin&#x2F;umount – &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.X6wbv9 [idcv-ceph0][WARNIN] start_daemon: Starting ceph osd.0… [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;systemctl disable ceph-osd@0 [idcv-ceph0][WARNIN] Removed symlink &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-osd.target.wants&#x2F;<a href="mailto:&#x63;&#101;&#x70;&#x68;&#x2d;&#x6f;&#115;&#100;&#64;&#x30;&#46;&#115;&#x65;&#114;&#118;&#x69;&#x63;&#x65;">&#x63;&#101;&#x70;&#x68;&#x2d;&#x6f;&#115;&#100;&#64;&#x30;&#46;&#115;&#x65;&#114;&#118;&#x69;&#x63;&#x65;</a>. [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;systemctl disable ceph-osd@0 –runtime [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;systemctl enable ceph-osd@0 [idcv-ceph0][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-osd.target.wants&#x2F;<a href="mailto:&#x63;&#101;&#x70;&#104;&#45;&#111;&#115;&#100;&#64;&#48;&#46;&#x73;&#101;&#x72;&#x76;&#x69;&#99;&#x65;">&#x63;&#101;&#x70;&#104;&#45;&#111;&#115;&#100;&#64;&#48;&#46;&#x73;&#101;&#x72;&#x76;&#x69;&#99;&#x65;</a> to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-osd@.service. [idcv-ceph0][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;systemctl start ceph-osd@0 [idcv-ceph0][INFO ] checking OSD status… [idcv-ceph0][DEBUG ] find the location of an executable [idcv-ceph0][INFO ] Running command: &#x2F;bin&#x2F;ceph –cluster&#x3D;ceph osd stat –format&#x3D;json [idcv-ceph0][INFO ] Running command: systemctl enable ceph.target [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [idcv-ceph1][DEBUG ] find the location of an executable [ceph_deploy.osd][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.osd][DEBUG ] activating host idcv-ceph1 disk &#x2F;dev&#x2F;sdb1 [ceph_deploy.osd][DEBUG ] will use init type: systemd [idcv-ceph1][DEBUG ] find the location of an executable [idcv-ceph1][INFO ] Running command: sudo &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v activate –mark-init systemd –mount &#x2F;dev&#x2F;sdb1 [idcv-ceph1][WARNIN] main_activate: path &#x3D; &#x2F;dev&#x2F;sdb1 [idcv-ceph1][WARNIN] get_dm_uuid: get_dm_uuid &#x2F;dev&#x2F;sdb1 uuid path is &#x2F;sys&#x2F;dev&#x2F;block&#x2F;8:17&#x2F;dm&#x2F;uuid [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;blkid -o udev -p &#x2F;dev&#x2F;sdb1 [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;blkid -p -s TYPE -o value – &#x2F;dev&#x2F;sdb1 [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_mount_options_xfs [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-conf –cluster&#x3D;ceph –name&#x3D;osd. –lookup osd_fs_mount_options_xfs [idcv-ceph1][WARNIN] mount: Mounting &#x2F;dev&#x2F;sdb1 on &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.zUV3_1 with options noatime,inode64 [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;usr&#x2F;bin&#x2F;mount -t xfs -o noatime,inode64 – &#x2F;dev&#x2F;sdb1 &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.zUV3_1 [idcv-ceph1][WARNIN] command: Running command: &#x2F;sbin&#x2F;restorecon &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.zUV3_1 [idcv-ceph1][WARNIN] activate: Cluster uuid is 812d3acb-eaa8-4355-9a74-64f2cd5209b3 [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph-osd –cluster&#x3D;ceph –show-config-value&#x3D;fsid [idcv-ceph1][WARNIN] activate: Cluster name is ceph [idcv-ceph1][WARNIN] activate: OSD uuid is 2809f370-e6ad-4d29-bf6b-57fe1f2004c6 [idcv-ceph1][WARNIN] allocate_osd_id: Allocating OSD id… [idcv-ceph1][WARNIN] command: Running command: &#x2F;usr&#x2F;bin&#x2F;ceph –cluster ceph –name client.bootstrap-osd –keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;bootstrap-osd&#x2F;ceph.keyring osd create –concise 2809f370-e6ad-4d29-bf6b-57fe1f2004c6 [idcv-ceph1][WARNIN] mount_activate: Failed to activate [idcv-ceph1][WARNIN] unmount: Unmounting &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.zUV3_1 [idcv-ceph1][WARNIN] command_check_call: Running command: &#x2F;bin&#x2F;umount – &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;tmp&#x2F;mnt.zUV3_1 [idcv-ceph1][WARNIN] Traceback (most recent call last): [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;sbin&#x2F;ceph-disk”, line 9, in [idcv-ceph1][WARNIN] load_entry_point(‘ceph-disk&#x3D;&#x3D;1.0.0’, ‘console_scripts’, ‘ceph-disk’)() [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_disk&#x2F;main.py”, line 5371, in run [idcv-ceph1][WARNIN] main(sys.argv[1:]) [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_disk&#x2F;main.py”, line 5322, in main [idcv-ceph1][WARNIN] args.func(args) [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_disk&#x2F;main.py”, line 3445, in main_activate [idcv-ceph1][WARNIN] reactivate&#x3D;args.reactivate, [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_disk&#x2F;main.py”, line 3202, in mount_activate [idcv-ceph1][WARNIN] (osd_id, cluster) &#x3D; activate(path, activate_key_template, init) [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_disk&#x2F;main.py”, line 3365, in activate [idcv-ceph1][WARNIN] keyring&#x3D;keyring, [idcv-ceph1][WARNIN] File “&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ceph_disk&#x2F;main.py”, line 1013, in allocate_osd_id [idcv-ceph1][WARNIN] raise Error(‘ceph osd create failed’, e, e.output) [idcv-ceph1][WARNIN] ceph_disk.main.Error: Error: ceph osd create failed: Command ‘&#x2F;usr&#x2F;bin&#x2F;ceph’ returned non-zero exit status 1: 2018-07-03 11:47:35.463545 7f8310450700 0 librados: client.bootstrap-osd authentication error (1) Operation not permitted [idcv-ceph1][WARNIN] Error connecting to cluster: PermissionError [idcv-ceph1][WARNIN] [idcv-ceph1][ERROR ] RuntimeError: command returned non-zero exit status: 1 [ceph_deploy][ERROR ] RuntimeError: Failed to execute command: &#x2F;usr&#x2F;sbin&#x2F;ceph-disk -v activate –mark-init systemd –mount &#x2F;dev&#x2F;sdb1</p>
</blockquote>
<p>2、查看了下idcv-ceph1没有加上去</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 100G 0 disk ├─sda1 8:1 0 500M 0 part &#x2F;boot └─sda2 8:2 0 99.5G 0 part └─centos-root 253:0 0 99.5G 0 lvm &#x2F; sdb 8:16 0 100G 0 disk ├─sdb1 8:17 0 95G 0 part &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;osd&#x2F;ceph-0 └─sdb2 8:18 0 5G 0 part sr0 11:0 1 1024M 0 rom<br>[root@idcv-ceph0 cluster]# ceph -s cluster 812d3acb-eaa8-4355-9a74-64f2cd5209b3 health HEALTH_OK monmap e2: 3 mons at {idcv-ceph0&#x3D;172.20.1.138:6789&#x2F;0,idcv-ceph2&#x3D;172.20.1.140:6789&#x2F;0,idcv-ceph3&#x3D;172.20.1.141:6789&#x2F;0} election epoch 8, quorum 0,1,2 idcv-ceph0,idcv-ceph2,idcv-ceph3 osdmap e14: 3 osds: 3 up, 3 in flags sortbitwise,require_jewel_osds pgmap v27: 64 pgs, 1 pools, 0 bytes data, 0 objects 100 MB used, 284 GB &#x2F; 284 GB avail 64 active+clean [root@idcv-ceph0 cluster]#</p>
</blockquote>
<p>3、使用这个方法赋予角色OSD</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph-deploy install –no-adjust-repos –osd idcv-ceph1 [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy install –no-adjust-repos –osd idcv-ceph1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] testing : None [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f19c0ebd440&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] dev_commit : None [ceph_deploy.cli][INFO ] install_mds : False [ceph_deploy.cli][INFO ] stable : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] adjust_repos : False [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] install_mgr : False [ceph_deploy.cli][INFO ] install_all : False [ceph_deploy.cli][INFO ] repo : False [ceph_deploy.cli][INFO ] host : [‘idcv-ceph1’] [ceph_deploy.cli][INFO ] install_rgw : False [ceph_deploy.cli][INFO ] install_tests : False [ceph_deploy.cli][INFO ] repo_url : None [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] install_osd : True [ceph_deploy.cli][INFO ] version_kind : stable [ceph_deploy.cli][INFO ] install_common : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] dev : master [ceph_deploy.cli][INFO ] nogpgcheck : False [ceph_deploy.cli][INFO ] local_mirror : None [ceph_deploy.cli][INFO ] release : None [ceph_deploy.cli][INFO ] install_mon : False [ceph_deploy.cli][INFO ] gpg_url : None [ceph_deploy.install][DEBUG ] Installing stable version jewel on cluster ceph hosts idcv-ceph1 [ceph_deploy.install][DEBUG ] Detecting platform for host idcv-ceph1 … [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [ceph_deploy.install][INFO ] Distro info: CentOS Linux 7.5.1804 Core [idcv-ceph1][INFO ] installing Ceph on idcv-ceph1 [idcv-ceph1][INFO ] Running command: sudo yum clean all [idcv-ceph1][DEBUG ] Loaded plugins: fastestmirror, priorities [idcv-ceph1][DEBUG ] Cleaning repos: Ceph Ceph-noarch base ceph-source epel extras updates [idcv-ceph1][DEBUG ] Cleaning up everything [idcv-ceph1][DEBUG ] Maybe you want: rm -rf &#x2F;var&#x2F;cache&#x2F;yum, to also free up space taken by orphaned data from disabled or removed repos [idcv-ceph1][DEBUG ] Cleaning up list of fastest mirrors [idcv-ceph1][INFO ] Running command: sudo yum -y install ceph [idcv-ceph1][DEBUG ] Loaded plugins: fastestmirror, priorities [idcv-ceph1][DEBUG ] Determining fastest mirrors [idcv-ceph1][DEBUG ] * base: mirrors.tuna.tsinghua.edu.cn [idcv-ceph1][DEBUG ] * epel: mirrors.huaweicloud.com [idcv-ceph1][DEBUG ] * extras: mirror.bit.edu.cn [idcv-ceph1][DEBUG ] * updates: mirrors.huaweicloud.com [idcv-ceph1][DEBUG ] 12 packages excluded due to repository priority protections [idcv-ceph1][DEBUG ] Package 1:ceph-10.2.10-0.el7.x86_64 already installed and latest version [idcv-ceph1][DEBUG ] Nothing to do [idcv-ceph1][INFO ] Running command: sudo ceph –version [idcv-ceph1][DEBUG ] ceph version 10.2.10 (5dc1e4c05cb68dbf62ae6fce3f0700e4654fdbbe)</p>
</blockquote>
<p>4、节点cpeh1 还是安装不上osd角色，这边准备初始化ceph1重新添加</p>
<blockquote>
<p>ceph-deploy purge 节点 ceph-deploy purgedata 节点 清楚安装包和残余数据 ceph-dpeloy install –no-adjust-repos –osd ceph1 直接装包 赋予OSD存储角色之后在添加OSD 具体步骤如下： ceph-deploy purge idcv-ceph1 ceph-deploy purgedata idcv-ceph1 ceph-deploy –overwrite-conf osd prepare idcv-ceph1:&#x2F;dev&#x2F;sdb<br>ceph-deploy –overwrite-conf osd activate idcv-ceph1:&#x2F;dev&#x2F;sdb1</p>
</blockquote>
<p>5、部署成功osd查看集群状态</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph -s cluster 812d3acb-eaa8-4355-9a74-64f2cd5209b3 health HEALTH_OK monmap e2: 3 mons at {idcv-ceph0&#x3D;172.20.1.138:6789&#x2F;0,idcv-ceph2&#x3D;172.20.1.140:6789&#x2F;0,idcv-ceph3&#x3D;172.20.1.141:6789&#x2F;0} election epoch 8, quorum 0,1,2 idcv-ceph0,idcv-ceph2,idcv-ceph3 osdmap e27: 4 osds: 4 up, 4 in flags sortbitwise,require_jewel_osds pgmap v64: 104 pgs, 6 pools, 1588 bytes data, 171 objects 138 MB used, 379 GB &#x2F; 379 GB avail 104 active+clean</p>
</blockquote>
<h4 id="六、部署RGW服务"><a href="#六、部署RGW服务" class="headerlink" title="六、部署RGW服务"></a>六、部署RGW服务</h4><p>1、部署cdph1为对象网关</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph-deploy install –no-adjust-repos –rgw idcv-ceph1 [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy install –no-adjust-repos –rgw idcv-ceph1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] testing : None [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7fba6af12440&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] dev_commit : None [ceph_deploy.cli][INFO ] install_mds : False [ceph_deploy.cli][INFO ] stable : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] adjust_repos : False [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] install_mgr : False [ceph_deploy.cli][INFO ] install_all : False [ceph_deploy.cli][INFO ] repo : False [ceph_deploy.cli][INFO ] host : [‘idcv-ceph1’] [ceph_deploy.cli][INFO ] install_rgw : True [ceph_deploy.cli][INFO ] install_tests : False [ceph_deploy.cli][INFO ] repo_url : None [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] install_osd : False [ceph_deploy.cli][INFO ] version_kind : stable [ceph_deploy.cli][INFO ] install_common : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] dev : master [ceph_deploy.cli][INFO ] nogpgcheck : False [ceph_deploy.cli][INFO ] local_mirror : None [ceph_deploy.cli][INFO ] release : None [ceph_deploy.cli][INFO ] install_mon : False [ceph_deploy.cli][INFO ] gpg_url : None [ceph_deploy.install][DEBUG ] Installing stable version jewel on cluster ceph hosts idcv-ceph1 [ceph_deploy.install][DEBUG ] Detecting platform for host idcv-ceph1 … [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [ceph_deploy.install][INFO ] Distro info: CentOS Linux 7.5.1804 Core [idcv-ceph1][INFO ] installing Ceph on idcv-ceph1 [idcv-ceph1][INFO ] Running command: sudo yum clean all [idcv-ceph1][DEBUG ] Loaded plugins: fastestmirror, priorities [idcv-ceph1][DEBUG ] Cleaning repos: Ceph Ceph-noarch base ceph-source epel extras updates [idcv-ceph1][DEBUG ] Cleaning up everything [idcv-ceph1][DEBUG ] Maybe you want: rm -rf &#x2F;var&#x2F;cache&#x2F;yum, to also free up space taken by orphaned data from disabled or removed repos [idcv-ceph1][DEBUG ] Cleaning up list of fastest mirrors [idcv-ceph1][INFO ] Running command: sudo yum -y install ceph-radosgw [idcv-ceph1][DEBUG ] Loaded plugins: fastestmirror, priorities [idcv-ceph1][DEBUG ] Determining fastest mirrors [idcv-ceph1][DEBUG ] * base: mirrors.aliyun.com [idcv-ceph1][DEBUG ] * epel: mirrors.aliyun.com [idcv-ceph1][DEBUG ] * extras: mirrors.aliyun.com [idcv-ceph1][DEBUG ] * updates: mirror.bit.edu.cn [idcv-ceph1][DEBUG ] 12 packages excluded due to repository priority protections [idcv-ceph1][DEBUG ] Resolving Dependencies [idcv-ceph1][DEBUG ] –&gt; Running transaction check [idcv-ceph1][DEBUG ] —&gt; Package ceph-radosgw.x86_64 1:10.2.10-0.el7 will be installed [idcv-ceph1][DEBUG ] –&gt; Finished Dependency Resolution [idcv-ceph1][DEBUG ] [idcv-ceph1][DEBUG ] Dependencies Resolved [idcv-ceph1][DEBUG ] [idcv-ceph1][DEBUG ] &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; [idcv-ceph1][DEBUG ] Package Arch Version Repository Size [idcv-ceph1][DEBUG ] &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; [idcv-ceph1][DEBUG ] Installing: [idcv-ceph1][DEBUG ] ceph-radosgw x86_64 1:10.2.10-0.el7 Ceph 266 k [idcv-ceph1][DEBUG ] [idcv-ceph1][DEBUG ] Transaction Summary [idcv-ceph1][DEBUG ] &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; [idcv-ceph1][DEBUG ] Install 1 Package [idcv-ceph1][DEBUG ] [idcv-ceph1][DEBUG ] Total download size: 266 k [idcv-ceph1][DEBUG ] Installed size: 795 k [idcv-ceph1][DEBUG ] Downloading packages: [idcv-ceph1][DEBUG ] Running transaction check [idcv-ceph1][DEBUG ] Running transaction test [idcv-ceph1][DEBUG ] Transaction test succeeded [idcv-ceph1][DEBUG ] Running transaction [idcv-ceph1][DEBUG ] Installing : 1:ceph-radosgw-10.2.10-0.el7.x86_64 1&#x2F;1 [idcv-ceph1][DEBUG ] Verifying : 1:ceph-radosgw-10.2.10-0.el7.x86_64 1&#x2F;1 [idcv-ceph1][DEBUG ] [idcv-ceph1][DEBUG ] Installed: [idcv-ceph1][DEBUG ] ceph-radosgw.x86_64 1:10.2.10-0.el7<br>[idcv-ceph1][DEBUG ] [idcv-ceph1][DEBUG ] Complete! [idcv-ceph1][INFO ] Running command: sudo ceph –version [idcv-ceph1][DEBUG ] ceph version 10.2.10 (5dc1e4c05cb68dbf62ae6fce3f0700e4654fdbbe)</p>
</blockquote>
<p>2、设置idcv-ceph1为管理网关</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph-deploy admin idcv-ceph1 [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy admin idcv-ceph1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f5f91222fc8&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] client : [‘idcv-ceph1’] [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to idcv-ceph1 [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [idcv-ceph1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf</p>
</blockquote>
<p>3、创建生成网关实例idcv-ceph1</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# ceph-deploy rgw create idcv-ceph1 [ceph_deploy.conf][DEBUG ] found configuration file at: &#x2F;root&#x2F;.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.39): &#x2F;usr&#x2F;bin&#x2F;ceph-deploy rgw create idcv-ceph1 [ceph_deploy.cli][INFO ] ceph-deploy options: [ceph_deploy.cli][INFO ] username : None [ceph_deploy.cli][INFO ] verbose : False [ceph_deploy.cli][INFO ] rgw : [(‘idcv-ceph1’, ‘rgw.idcv-ceph1’)] [ceph_deploy.cli][INFO ] overwrite_conf : False [ceph_deploy.cli][INFO ] subcommand : create [ceph_deploy.cli][INFO ] quiet : False [ceph_deploy.cli][INFO ] cd_conf : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f6c86f85128&gt; [ceph_deploy.cli][INFO ] cluster : ceph [ceph_deploy.cli][INFO ] func : [ceph_deploy.cli][INFO ] ceph_conf : None [ceph_deploy.cli][INFO ] default_release : False [ceph_deploy.rgw][DEBUG ] Deploying rgw, cluster ceph hosts idcv-ceph1:rgw.idcv-ceph1 [idcv-ceph1][DEBUG ] connection detected need for sudo [idcv-ceph1][DEBUG ] connected to host: idcv-ceph1 [idcv-ceph1][DEBUG ] detect platform information from remote host [idcv-ceph1][DEBUG ] detect machine type [ceph_deploy.rgw][INFO ] Distro info: CentOS Linux 7.5.1804 Core [ceph_deploy.rgw][DEBUG ] remote host will use systemd [ceph_deploy.rgw][DEBUG ] deploying rgw bootstrap to idcv-ceph1 [idcv-ceph1][DEBUG ] write cluster configuration to &#x2F;etc&#x2F;ceph&#x2F;{cluster}.conf [idcv-ceph1][WARNIN] rgw keyring does not exist yet, creating one [idcv-ceph1][DEBUG ] create a keyring file [idcv-ceph1][DEBUG ] create path recursively if it doesn’t exist [idcv-ceph1][INFO ] Running command: sudo ceph –cluster ceph –name client.bootstrap-rgw –keyring &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;bootstrap-rgw&#x2F;ceph.keyring auth get-or-create client.rgw.idcv-ceph1 osd allow rwx mon allow rw -o &#x2F;var&#x2F;lib&#x2F;ceph&#x2F;radosgw&#x2F;ceph-rgw.idcv-ceph1&#x2F;keyring [idcv-ceph1][INFO ] Running command: sudo systemctl enable <a href="mailto:&#x63;&#101;&#112;&#x68;&#x2d;&#114;&#97;&#x64;&#111;&#115;&#103;&#119;&#x40;&#114;&#x67;&#x77;&#46;&#x69;&#x64;&#x63;&#x76;&#x2d;&#99;&#101;&#x70;&#x68;&#x31;">&#x63;&#101;&#112;&#x68;&#x2d;&#114;&#97;&#x64;&#111;&#115;&#103;&#119;&#x40;&#114;&#x67;&#x77;&#46;&#x69;&#x64;&#x63;&#x76;&#x2d;&#99;&#101;&#x70;&#x68;&#x31;</a> [idcv-ceph1][WARNIN] Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;ceph-radosgw.target.wants&#x2F;<a href="mailto:&#x63;&#101;&#x70;&#x68;&#45;&#x72;&#x61;&#100;&#111;&#115;&#103;&#x77;&#64;&#114;&#103;&#x77;&#x2e;&#105;&#x64;&#99;&#118;&#45;&#99;&#101;&#112;&#104;&#49;&#46;&#x73;&#x65;&#x72;&#x76;&#x69;&#x63;&#x65;">&#x63;&#101;&#x70;&#x68;&#45;&#x72;&#x61;&#100;&#111;&#115;&#103;&#x77;&#64;&#114;&#103;&#x77;&#x2e;&#105;&#x64;&#99;&#118;&#45;&#99;&#101;&#112;&#104;&#49;&#46;&#x73;&#x65;&#x72;&#x76;&#x69;&#x63;&#x65;</a> to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;ceph-radosgw@.service. [idcv-ceph1][INFO ] Running command: sudo systemctl start <a href="mailto:&#x63;&#x65;&#112;&#x68;&#45;&#114;&#97;&#100;&#x6f;&#x73;&#103;&#119;&#x40;&#x72;&#x67;&#119;&#46;&#x69;&#100;&#99;&#118;&#45;&#x63;&#x65;&#x70;&#104;&#49;">&#x63;&#x65;&#112;&#x68;&#45;&#114;&#97;&#100;&#x6f;&#x73;&#103;&#119;&#x40;&#x72;&#x67;&#119;&#46;&#x69;&#100;&#99;&#118;&#45;&#x63;&#x65;&#x70;&#104;&#49;</a> [idcv-ceph1][INFO ] Running command: sudo systemctl enable ceph.target [ceph_deploy.rgw][INFO ] The Ceph Object Gateway (RGW) is now running on host idcv-ceph1 and default port 7480</p>
</blockquote>
<p>4、测试网关服务</p>
<blockquote>
<p>[root@idcv-ceph0 cluster]# curl 172.20.1.139:7480 anonymous</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>到此所有需要相关服务已经部署完毕，如果对ceph.conf比较了解，设置正确参数，部署应该会比较顺利，下一篇将会测试osd块存储功能及rgw对象存储功能。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://minminmsn.github.io">Jerry Min</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://minminmsn.github.io/2018/12/06/2018/12/2018-12-06-centos-7-5%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2jewel%E7%89%88%E6%9C%ACceph%E9%9B%86%E7%BE%A4/index/">https://minminmsn.github.io/2018/12/06/2018/12/2018-12-06-centos-7-5%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2jewel%E7%89%88%E6%9C%ACceph%E9%9B%86%E7%BE%A4/index/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ceph/">ceph</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/12/09/2018/12/2018-12-09-%E6%8E%92%E6%9F%A5logstash2-4%E5%8D%87%E7%BA%A7%E5%88%B05-0%E7%89%88%E6%9C%AC%E5%90%8Ekafka%E4%B8%8D%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/index/" title="排查logstash2.4升级到5.0版本后kafka不兼容问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">排查logstash2.4升级到5.0版本后kafka不兼容问题</div></div></a></div><div class="next-post pull-right"><a href="/2018/12/06/2018/12/2018-12-06-ceph%E9%9B%86%E7%BE%A4%E7%94%B1jewel%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E5%88%B0luminous%E7%89%88%E6%9C%AC/index/" title="Ceph集群由Jewel版本升级到Luminous版本"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Ceph集群由Jewel版本升级到Luminous版本</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2018/12/06/2018/12/2018-12-06-ceph%E9%9B%86%E7%BE%A4%E7%94%B1jewel%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E5%88%B0luminous%E7%89%88%E6%9C%AC/index/" title="Ceph集群由Jewel版本升级到Luminous版本"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-12-06</div><div class="title">Ceph集群由Jewel版本升级到Luminous版本</div></div></a></div><div><a href="/2018/12/06/2018/12/2018-12-06-jewel%E7%89%88%E6%9C%ACceph%E9%9B%86%E7%BE%A4%E5%8A%9F%E8%83%BD%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/index/" title="Jewel版本Ceph集群功能性能测试"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-12-06</div><div class="title">Jewel版本Ceph集群功能性能测试</div></div></a></div><div><a href="/2019/01/21/2019/01/2019-01-21-kubernets1-13-1%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph-rbd%E5%9D%97%E5%AD%98%E5%82%A8/index/" title="kubernets1.13.1集群使用ceph rbd块存储"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-21</div><div class="title">kubernets1.13.1集群使用ceph rbd块存储</div></div></a></div><div><a href="/2019/01/30/2019/01/2019-01-30-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E9%9B%86%E6%88%90harbor-helm/index/" title="kubernetes1.13.1集群集成harbor-helm"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-30</div><div class="title">kubernetes1.13.1集群集成harbor-helm</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Jerry Min</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">260</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">61</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">34</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/minminmsn"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">不念过往，无畏将来，若非当下，何时？</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E6%A1%A3"><span class="toc-number">1.</span> <span class="toc-text">参考文档</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E5%9B%BE"><span class="toc-number">3.</span> <span class="toc-text">架构图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-number">4.</span> <span class="toc-text">安装部署</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83"><span class="toc-number">4.1.</span> <span class="toc-text">一、基础环境</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2deploy%E8%8A%82%E7%82%B9"><span class="toc-number">4.2.</span> <span class="toc-text">二、安装部署deploy节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%AE%89%E8%A3%85mon%E6%9C%8D%E5%8A%A1"><span class="toc-number">4.3.</span> <span class="toc-text">三、安装mon服务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E9%83%A8%E7%BD%B2OSD%E8%A7%92%E8%89%B2"><span class="toc-number">4.4.</span> <span class="toc-text">五、部署OSD角色</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E9%83%A8%E7%BD%B2RGW%E6%9C%8D%E5%8A%A1"><span class="toc-number">4.5.</span> <span class="toc-text">六、部署RGW服务</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/12/27/2022/12/2022-12-27-%E8%BF%90%E7%BB%B4%E8%83%BD%E5%8A%9B%E8%A6%81%E6%B1%82/index/" title="运维能力要求">运维能力要求</a><time datetime="2022-12-27T00:00:00.000Z" title="Created 2022-12-27 08:00:00">2022-12-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/11/01/2022/11/2022-11-01-%E6%B5%85%E8%B0%88%E5%9F%BA%E4%BA%8E-openstack-%E5%92%8C-k8s-%E8%BD%BB%E9%87%8F%E7%A0%94%E5%8F%91%E7%A7%81%E6%9C%89%E4%BA%91%E5%BB%BA%E8%AE%BE/index/" title="浅谈基于 OpenStack 和 k8s 轻量研发私有云建设">浅谈基于 OpenStack 和 k8s 轻量研发私有云建设</a><time datetime="2022-11-01T00:00:00.000Z" title="Created 2022-11-01 08:00:00">2022-11-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/17/2022/06/2022-06-17-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E9%9B%86%E9%94%A6/index/" title="数学公式集锦">数学公式集锦</a><time datetime="2022-06-17T00:00:00.000Z" title="Created 2022-06-17 08:00:00">2022-06-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/14/2022/06/2022-06-14-%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/index/" title="运维工作总结">运维工作总结</a><time datetime="2022-06-14T00:00:00.000Z" title="Created 2022-06-14 08:00:00">2022-06-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/06/11/2022/06/2022-06-11-%E6%98%8E%E5%84%92%E5%AD%A6%E6%A1%88%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index/" title="明儒学案学习笔记">明儒学案学习笔记</a><time datetime="2022-06-11T00:00:00.000Z" title="Created 2022-06-11 08:00:00">2022-06-11</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2023 By Jerry Min</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>