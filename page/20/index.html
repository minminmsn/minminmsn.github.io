<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"minminmsn.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="MinMinMsn">
<meta property="og:url" content="https://minminmsn.github.io/page/20/index.html">
<meta property="og:site_name" content="MinMinMsn">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Jerry Min">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://minminmsn.github.io/page/20/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>MinMinMsn</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">MinMinMsn</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/30/2019/01/2019-01-30-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E9%9B%86%E6%88%90harbor-helm/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/30/2019/01/2019-01-30-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E9%9B%86%E6%88%90harbor-helm/index/" class="post-title-link" itemprop="url">kubernetes1.13.1集群集成harbor-helm</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-30 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-30T08:00:00+08:00">2019-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:31" itemprop="dateModified" datetime="2023-05-26T15:06:31+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/goharbor/harbor-helm</span><br><span class="line">https://www.hi-linux.com/posts/14136.html</span><br><span class="line">https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/rbd</span><br><span class="line">https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/rbd/deploy/rbac</span><br><span class="line">https://github.com/helm/helm/issues/3130</span><br><span class="line">https://www.kancloud.cn/huyipow/kubernetes/531999</span><br><span class="line">https://www.hi-linux.com/posts/14136.html</span><br><span class="line">https://li-sen.github.io/2018/10/08/k8s%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8harbor/</span><br></pre></td></tr></table></figure>

<h3 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Kubernetes cluster 1.10+</span><br><span class="line">kubernetes集群版本1.13.1</span><br><span class="line"></span><br><span class="line">Helm 2.8.0+</span><br><span class="line"></span><br><span class="line">ingress</span><br><span class="line">用于外部访问集群内部环境</span><br><span class="line"></span><br><span class="line">rbd-provisioner</span><br><span class="line">ceph rbd 客户端，可以创建、删除ceph rbd pool、image等</span><br><span class="line"></span><br><span class="line">storageclass</span><br><span class="line">用于自动创建pv与pvc</span><br><span class="line"></span><br><span class="line">ceph rbd</span><br><span class="line">ceph集群luminous版本</span><br></pre></td></tr></table></figure>

<h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h3><h5 id="一、部署rbd-provisioner"><a href="#一、部署rbd-provisioner" class="headerlink" title="一、部署rbd-provisioner"></a>一、部署rbd-provisioner</h5><p><strong>1、下载external-storage</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 yaml]# git clone https://github.com/kubernetes-incubator/external-storage</span><br><span class="line">[root@elasticsearch01 yaml]# cd external-storage/ceph/rbd/deploy/rbac/</span><br><span class="line">[root@elasticsearch01 rbac]# ls</span><br><span class="line">clusterrolebinding.yaml  deployment.yaml          role.yaml                </span><br><span class="line">clusterrole.yaml         rolebinding.yaml         serviceaccount.yaml </span><br><span class="line">[root@elasticsearch01 rbac]# mkdir /k8s/yaml/volumes/rbd-provisioner</span><br><span class="line">[root@elasticsearch01 rbac]# cp * /k8s/yaml/volumes/rbd-provisioner/</span><br><span class="line">[root@elasticsearch01 rbac]# cd /k8s/yaml/volumes/rbd-provisioner/</span><br></pre></td></tr></table></figure>

<p><strong>2、创建rbd-provisioner角色、pod</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd-provisioner]# ls</span><br><span class="line">clusterrolebinding.yaml  deployment.yaml          role.yaml                </span><br><span class="line">clusterrole.yaml         rolebinding.yaml         serviceaccount.yaml      </span><br><span class="line">[root@elasticsearch01 rbd-provisioner]# kubectl create -f ./</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/rbd-provisioner created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/rbd-provisioner created</span><br><span class="line">deployment.extensions/rbd-provisioner created</span><br><span class="line">role.rbac.authorization.k8s.io/rbd-provisioner created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/rbd-provisioner created</span><br><span class="line">serviceaccount/rbd-provisioner created</span><br></pre></td></tr></table></figure>

<p><strong>3、验证rbd-provisioner</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd-provisioner]# kubectl get pods</span><br><span class="line">NAME                               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                            1/1     Running   600        25d</span><br><span class="line">ceph-rbd-pv-pod1                   1/1     Running   10         6d23h</span><br><span class="line">jenkins-0                          1/1     Running   0          6d1h</span><br><span class="line">rbd-provisioner-67b4857bcd-xxwx5   1/1     Running   0          9s</span><br></pre></td></tr></table></figure>

<h5 id="二、部署storageclass"><a href="#二、部署storageclass" class="headerlink" title="二、部署storageclass"></a>二、部署storageclass</h5><p><strong>1、修改storageclass配置</strong> 参考external-storage&#x2F;gluster&#x2F;glusterfs&#x2F;deploy&#x2F;storageclass.yaml样例根据自己情况修改，其中secretName在kubernetes集群使用ceph rbd块存储时已经创建过</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd-provisioner]# cat storageclass.yaml </span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd</span><br><span class="line">provisioner: ceph.com/rbd</span><br><span class="line">parameters:</span><br><span class="line">  monitors: 10.0.4.10:6789</span><br><span class="line">  pool: rbd-k8s</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretNamespace: default</span><br><span class="line">  adminSecretName: ceph-secret</span><br><span class="line">  userSecretName: ceph-secret</span><br><span class="line">  userId: admin</span><br><span class="line">  userSecretNamespace: default</span><br><span class="line">  userSecretName: ceph-secret</span><br><span class="line">  imageFormat: &quot;2&quot;</span><br><span class="line">  imageFeatures: layering</span><br></pre></td></tr></table></figure>

<p><strong>2、创建storageclass rbd</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# kubectl create -f storageclass.yaml </span><br><span class="line">storageclass.storage.k8s.io/rbd created</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 harbor-helm]# kubectl get storageclasses</span><br><span class="line">NAME   PROVISIONER    AGE</span><br><span class="line">rbd    ceph.com/rbd   2m</span><br></pre></td></tr></table></figure>

<h5 id="三、部署harbor-helm"><a href="#三、部署harbor-helm" class="headerlink" title="三、部署harbor-helm"></a>三、部署harbor-helm</h5><p><strong>1、下载harbor-helm 1.0.0版本的源码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 yaml]# git clone https://github.com/goharbor/harbor-helm.git</span><br><span class="line">[root@elasticsearch01 yaml]# cd harbor-helm/</span><br><span class="line">[root@elasticsearch01 harbor-helm]# git checkout 1.0.0</span><br><span class="line">[root@elasticsearch01 harbor-helm]# ls</span><br><span class="line">Chart.yaml  CONTRIBUTING.md  docs  LICENSE  README.md    templates  values.yaml</span><br></pre></td></tr></table></figure>

<p><strong>2、修改values.yaml配置</strong> 需要根据实际情况修改values.yaml配置文件，主要修改如下几个地方</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">admin</span><br><span class="line">登陆密码</span><br><span class="line"></span><br><span class="line">storageclass</span><br><span class="line">这里是rbd</span><br><span class="line"></span><br><span class="line">ingress</span><br><span class="line">修改自己的域名</span><br><span class="line"></span><br><span class="line">secretName</span><br><span class="line">tls的秘钥</span><br></pre></td></tr></table></figure>

<p>修改后具体如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# cat values.yaml </span><br><span class="line">expose:</span><br><span class="line">  # Set the way how to expose the service. Set the type as &quot;ingress&quot;, </span><br><span class="line">  # &quot;clusterIP&quot; or &quot;nodePort&quot; and fill the information in the corresponding </span><br><span class="line">  # section</span><br><span class="line">  type: ingress</span><br><span class="line">  tls:</span><br><span class="line">    # Enable the tls or not. Note: if the type is &quot;ingress&quot; and the tls </span><br><span class="line">    # is disabled, the port must be included in the command when pull/push</span><br><span class="line">    # images. Refer to https://github.com/goharbor/harbor/issues/5291 </span><br><span class="line">    # for the detail.</span><br><span class="line">    enabled: true</span><br><span class="line">    # Fill the name of secret if you want to use your own TLS certificate</span><br><span class="line">    # and private key. The secret must contain keys named tls.crt and </span><br><span class="line">    # tls.key that contain the certificate and private key to use for TLS</span><br><span class="line">    # The certificate and private key will be generated automatically if </span><br><span class="line">    # it is not set</span><br><span class="line">    secretName: &quot;ingress-secret&quot;</span><br><span class="line">    # By default, the Notary service will use the same cert and key as</span><br><span class="line">    # described above. Fill the name of secret if you want to use a </span><br><span class="line">    # separated one. Only needed when the type is &quot;ingress&quot;.</span><br><span class="line">    notarySecretName: &quot;&quot;</span><br><span class="line">    # The commmon name used to generate the certificate, it&#x27;s necessary</span><br><span class="line">    # when the type is &quot;clusterIP&quot; or &quot;nodePort&quot; and &quot;secretName&quot; is null</span><br><span class="line">    commonName: &quot;&quot;</span><br><span class="line">  ingress:</span><br><span class="line">    hosts:</span><br><span class="line">      core: core-harbor.minminmsn.com</span><br><span class="line">      notary: notary-harbor.minminmsn.com</span><br><span class="line">    annotations:</span><br><span class="line">      ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class="line">      nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class="line">      ingress.kubernetes.io/proxy-body-size: &quot;0&quot;</span><br><span class="line">      nginx.ingress.kubernetes.io/proxy-body-size: &quot;0&quot;</span><br><span class="line">  clusterIP:</span><br><span class="line">    # The name of ClusterIP service</span><br><span class="line">    name: harbor</span><br><span class="line">    ports:</span><br><span class="line">      # The service port Harbor listens on when serving with HTTP</span><br><span class="line">      httpPort: 80</span><br><span class="line">      # The service port Harbor listens on when serving with HTTPS</span><br><span class="line">      httpsPort: 443</span><br><span class="line">      # The service port Notary listens on. Only needed when notary.enabled </span><br><span class="line">      # is set to true</span><br><span class="line">      notaryPort: 4443</span><br><span class="line">  nodePort:</span><br><span class="line">    # The name of NodePort service</span><br><span class="line">    name: harbor</span><br><span class="line">    ports:</span><br><span class="line">      http:</span><br><span class="line">        # The service port Harbor listens on when serving with HTTP</span><br><span class="line">        port: 80</span><br><span class="line">        # The node port Harbor listens on when serving with HTTP</span><br><span class="line">        nodePort: 30002</span><br><span class="line">      https: </span><br><span class="line">        # The service port Harbor listens on when serving with HTTPS</span><br><span class="line">        port: 443</span><br><span class="line">        # The node port Harbor listens on when serving with HTTPS</span><br><span class="line">        nodePort: 30003</span><br><span class="line">      # Only needed when notary.enabled is set to true</span><br><span class="line">      notary: </span><br><span class="line">        # The service port Notary listens on</span><br><span class="line">        port: 4443</span><br><span class="line">        # The node port Notary listens on</span><br><span class="line">        nodePort: 30004</span><br><span class="line"></span><br><span class="line"># The external URL for Harbor core service. It is used to</span><br><span class="line"># 1) populate the docker/helm commands showed on portal</span><br><span class="line"># 2) populate the token service URL returned to docker/notary client</span><br><span class="line"># </span><br><span class="line"># Format: protocol://domain[:port]. Usually:</span><br><span class="line"># 1) if &quot;expose.type&quot; is &quot;ingress&quot;, the &quot;domain&quot; should be </span><br><span class="line"># the value of &quot;expose.ingress.hosts.core&quot;</span><br><span class="line"># 2) if &quot;expose.type&quot; is &quot;clusterIP&quot;, the &quot;domain&quot; should be</span><br><span class="line"># the value of &quot;expose.clusterIP.name&quot;</span><br><span class="line"># 3) if &quot;expose.type&quot; is &quot;nodePort&quot;, the &quot;domain&quot; should be</span><br><span class="line"># the IP address of k8s node </span><br><span class="line"># </span><br><span class="line"># If Harbor is deployed behind the proxy, set it as the URL of proxy</span><br><span class="line">externalURL: https://core-harbor.minminmsn.com</span><br><span class="line"></span><br><span class="line"># The persistence is enabled by default and a default StorageClass</span><br><span class="line"># is needed in the k8s cluster to provision volumes dynamicly. </span><br><span class="line"># Specify another StorageClass in the &quot;storageClass&quot; or set &quot;existingClaim&quot;</span><br><span class="line"># if you have already existing persistent volumes to use</span><br><span class="line">#</span><br><span class="line"># For storing images and charts, you can also use &quot;azure&quot;, &quot;gcs&quot;, &quot;s3&quot;, </span><br><span class="line"># &quot;swift&quot; or &quot;oss&quot;. Set it in the &quot;imageChartStorage&quot; section</span><br><span class="line">persistence:</span><br><span class="line">  enabled: true</span><br><span class="line">  # Setting it to &quot;keep&quot; to avoid removing PVCs during a helm delete </span><br><span class="line">  # operation. Leaving it empty will delete PVCs after the chart deleted</span><br><span class="line">  resourcePolicy: &quot;keep&quot;</span><br><span class="line">  persistentVolumeClaim:</span><br><span class="line">    registry:</span><br><span class="line">      # Use the existing PVC which must be created manually before bound</span><br><span class="line">      existingClaim: &quot;&quot;</span><br><span class="line">      # Specify the &quot;storageClass&quot; used to provision the volume. Or the default</span><br><span class="line">      # StorageClass will be used(the default).</span><br><span class="line">      # Set it to &quot;-&quot; to disable dynamic provisioning</span><br><span class="line">      storageClass: &quot;rbd&quot;</span><br><span class="line">      subPath: &quot;&quot;</span><br><span class="line">      accessMode: ReadWriteOnce</span><br><span class="line">      size: 50Gi</span><br><span class="line">    chartmuseum:</span><br><span class="line">      existingClaim: &quot;&quot;</span><br><span class="line">      storageClass: &quot;rbd&quot;</span><br><span class="line">      subPath: &quot;&quot;</span><br><span class="line">      accessMode: ReadWriteOnce</span><br><span class="line">      size: 5Gi</span><br><span class="line">    jobservice:</span><br><span class="line">      existingClaim: &quot;&quot;</span><br><span class="line">      storageClass: &quot;rbd&quot;</span><br><span class="line">      subPath: &quot;&quot;</span><br><span class="line">      accessMode: ReadWriteOnce</span><br><span class="line">      size: 2Gi</span><br><span class="line">    # If external database is used, the following settings for database will </span><br><span class="line">    # be ignored</span><br><span class="line">    database:</span><br><span class="line">      existingClaim: &quot;&quot;</span><br><span class="line">      storageClass: &quot;rbd&quot;</span><br><span class="line">      subPath: &quot;&quot;</span><br><span class="line">      accessMode: ReadWriteOnce</span><br><span class="line">      size: 2Gi</span><br><span class="line">    # If external Redis is used, the following settings for Redis will </span><br><span class="line">    # be ignored</span><br><span class="line">    redis:</span><br><span class="line">      existingClaim: &quot;&quot;</span><br><span class="line">      storageClass: &quot;rbd&quot;</span><br><span class="line">      subPath: &quot;&quot;</span><br><span class="line">      accessMode: ReadWriteOnce</span><br><span class="line">      size: 2Gi</span><br><span class="line">  # Define which storage backend is used for registry and chartmuseum to store</span><br><span class="line">  # images and charts. Refer to </span><br><span class="line">  # https://github.com/docker/distribution/blob/master/docs/configuration.md#storage </span><br><span class="line">  # for the detail.</span><br><span class="line">  imageChartStorage:</span><br><span class="line">    # Specify the type of storage: &quot;filesystem&quot;, &quot;azure&quot;, &quot;gcs&quot;, &quot;s3&quot;, &quot;swift&quot;, </span><br><span class="line">    # &quot;oss&quot; and fill the information needed in the corresponding section. The type</span><br><span class="line">    # must be &quot;filesystem&quot; if you want to use persistent volumes for registry</span><br><span class="line">    # and chartmuseum</span><br><span class="line">    type: filesystem</span><br><span class="line">    filesystem:</span><br><span class="line">      rootdirectory: /storage</span><br><span class="line">      #maxthreads: 100</span><br><span class="line">    azure:</span><br><span class="line">      accountname: accountname</span><br><span class="line">      accountkey: base64encodedaccountkey</span><br><span class="line">      container: containername</span><br><span class="line">      #realm: core.windows.net</span><br><span class="line">    gcs:</span><br><span class="line">      bucket: bucketname</span><br><span class="line">      # TODO: support the keyfile of gcs</span><br><span class="line">      #keyfile: /path/to/keyfile</span><br><span class="line">      #rootdirectory: /gcs/object/name/prefix</span><br><span class="line">      #chunksize: &quot;5242880&quot;</span><br><span class="line">    s3:</span><br><span class="line">      region: us-west-1</span><br><span class="line">      bucket: bucketname</span><br><span class="line">      #accesskey: awsaccesskey</span><br><span class="line">      #secretkey: awssecretkey</span><br><span class="line">      #regionendpoint: http://myobjects.local</span><br><span class="line">      #encrypt: false</span><br><span class="line">      #keyid: mykeyid</span><br><span class="line">      #secure: true</span><br><span class="line">      #v4auth: true</span><br><span class="line">      #chunksize: &quot;5242880&quot;</span><br><span class="line">      #rootdirectory: /s3/object/name/prefix</span><br><span class="line">      #storageclass: STANDARD</span><br><span class="line">    swift:</span><br><span class="line">      authurl: https://storage.myprovider.com/v3/auth</span><br><span class="line">      username: username</span><br><span class="line">      password: password</span><br><span class="line">      container: containername</span><br><span class="line">      #region: fr</span><br><span class="line">      #tenant: tenantname</span><br><span class="line">      #tenantid: tenantid</span><br><span class="line">      #domain: domainname</span><br><span class="line">      #domainid: domainid</span><br><span class="line">      #trustid: trustid</span><br><span class="line">      #insecureskipverify: false</span><br><span class="line">      #chunksize: 5M</span><br><span class="line">      #prefix:</span><br><span class="line">      #secretkey: secretkey</span><br><span class="line">      #accesskey: accesskey</span><br><span class="line">      #authversion: 3</span><br><span class="line">      #endpointtype: public</span><br><span class="line">      #tempurlcontainerkey: false</span><br><span class="line">      #tempurlmethods:</span><br><span class="line">    oss:</span><br><span class="line">      accesskeyid: accesskeyid</span><br><span class="line">      accesskeysecret: accesskeysecret</span><br><span class="line">      region: regionname</span><br><span class="line">      bucket: bucketname</span><br><span class="line">      #endpoint: endpoint</span><br><span class="line">      #internal: false</span><br><span class="line">      #encrypt: false</span><br><span class="line">      #secure: true</span><br><span class="line">      #chunksize: 10M</span><br><span class="line">      #rootdirectory: rootdirectory</span><br><span class="line"></span><br><span class="line">imagePullPolicy: IfNotPresent</span><br><span class="line"></span><br><span class="line">logLevel: debug</span><br><span class="line"># The initial password of Harbor admin. Change it from portal after launching Harbor</span><br><span class="line">harborAdminPassword: &quot;newpassword&quot;</span><br><span class="line"># The secret key used for encryption. Must be a string of 16 chars.</span><br><span class="line">secretKey: &quot;not-a-secure-key&quot;</span><br><span class="line"></span><br><span class="line"># If expose the service via &quot;ingress&quot;, the Nginx will not be used</span><br><span class="line">nginx:</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/nginx-photon</span><br><span class="line">    tag: v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  # resources:</span><br><span class="line">  #  requests:</span><br><span class="line">  #    memory: 256Mi</span><br><span class="line">  #    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">portal:</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/harbor-portal</span><br><span class="line">    tag: v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line"># resources:</span><br><span class="line">#  requests:</span><br><span class="line">#    memory: 256Mi</span><br><span class="line">#    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">core:</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/harbor-core</span><br><span class="line">    tag: v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line"># resources:</span><br><span class="line">#  requests:</span><br><span class="line">#    memory: 256Mi</span><br><span class="line">#    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">adminserver:</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/harbor-adminserver</span><br><span class="line">    tag: v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  # resources:</span><br><span class="line">  #  requests:</span><br><span class="line">  #    memory: 256Mi</span><br><span class="line">  #    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">jobservice:</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/harbor-jobservice</span><br><span class="line">    tag: v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  maxJobWorkers: 10</span><br><span class="line">  # The logger for jobs: &quot;file&quot;, &quot;database&quot; or &quot;stdout&quot;</span><br><span class="line">  jobLogger: file</span><br><span class="line"># resources:</span><br><span class="line">#   requests:</span><br><span class="line">#     memory: 256Mi</span><br><span class="line">#     cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">registry:</span><br><span class="line">  registry:</span><br><span class="line">    image:</span><br><span class="line">      repository: goharbor/registry-photon</span><br><span class="line">      tag: v2.6.2-v1.7.0</span><br><span class="line">  controller:</span><br><span class="line">    image:</span><br><span class="line">      repository: goharbor/harbor-registryctl</span><br><span class="line">      tag: v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  # resources:</span><br><span class="line">  #  requests:</span><br><span class="line">  #    memory: 256Mi</span><br><span class="line">  #    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">chartmuseum:</span><br><span class="line">  enabled: true</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/chartmuseum-photon</span><br><span class="line">    tag: v0.7.1-v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  # resources:</span><br><span class="line">  #  requests:</span><br><span class="line">  #    memory: 256Mi</span><br><span class="line">  #    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">clair:</span><br><span class="line">  enabled: true</span><br><span class="line">  image:</span><br><span class="line">    repository: goharbor/clair-photon</span><br><span class="line">    tag: v2.0.7-v1.7.0</span><br><span class="line">  replicas: 1</span><br><span class="line">  # The http(s) proxy used to update vulnerabilities database from internet</span><br><span class="line">  httpProxy:</span><br><span class="line">  httpsProxy:</span><br><span class="line">  # The interval of clair updaters, the unit is hour, set to 0 to </span><br><span class="line">  # disable the updaters</span><br><span class="line">  updatersInterval: 12</span><br><span class="line">  # resources:</span><br><span class="line">  #  requests:</span><br><span class="line">  #    memory: 256Mi</span><br><span class="line">  #    cpu: 100m</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">notary:</span><br><span class="line">  enabled: true</span><br><span class="line">  server:</span><br><span class="line">    image:</span><br><span class="line">      repository: goharbor/notary-server-photon</span><br><span class="line">      tag: v0.6.1-v1.7.0</span><br><span class="line">    replicas: 1</span><br><span class="line">  signer:</span><br><span class="line">    image:</span><br><span class="line">      repository: goharbor/notary-signer-photon</span><br><span class="line">      tag: v0.6.1-v1.7.0</span><br><span class="line">    replicas: 1</span><br><span class="line">  nodeSelector: &#123;&#125;</span><br><span class="line">  tolerations: []</span><br><span class="line">  affinity: &#123;&#125;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">database:</span><br><span class="line">  # if external database is used, set &quot;type&quot; to &quot;external&quot;</span><br><span class="line">  # and fill the connection informations in &quot;external&quot; section</span><br><span class="line">  type: internal</span><br><span class="line">  internal:</span><br><span class="line">    image:</span><br><span class="line">      repository: goharbor/harbor-db</span><br><span class="line">      tag: v1.7.0</span><br><span class="line">    # The initial superuser password for internal database</span><br><span class="line">    password: &quot;changeit&quot;</span><br><span class="line">    # resources:</span><br><span class="line">    #  requests:</span><br><span class="line">    #    memory: 256Mi</span><br><span class="line">    #    cpu: 100m</span><br><span class="line">    nodeSelector: &#123;&#125;</span><br><span class="line">    tolerations: []</span><br><span class="line">    affinity: &#123;&#125;</span><br><span class="line">  external:</span><br><span class="line">    host: &quot;192.168.0.1&quot;</span><br><span class="line">    port: &quot;5432&quot;</span><br><span class="line">    username: &quot;user&quot;</span><br><span class="line">    password: &quot;password&quot;</span><br><span class="line">    coreDatabase: &quot;registry&quot;</span><br><span class="line">    clairDatabase: &quot;clair&quot;</span><br><span class="line">    notaryServerDatabase: &quot;notary_server&quot;</span><br><span class="line">    notarySignerDatabase: &quot;notary_signer&quot;</span><br><span class="line">    sslmode: &quot;disable&quot;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br><span class="line"></span><br><span class="line">redis:</span><br><span class="line">  # if external Redis is used, set &quot;type&quot; to &quot;external&quot;</span><br><span class="line">  # and fill the connection informations in &quot;external&quot; section</span><br><span class="line">  type: internal</span><br><span class="line">  internal:</span><br><span class="line">    image:</span><br><span class="line">      repository: goharbor/redis-photon</span><br><span class="line">      tag: v1.7.0</span><br><span class="line">    # resources:</span><br><span class="line">    #  requests:</span><br><span class="line">    #    memory: 256Mi</span><br><span class="line">    #    cpu: 100m</span><br><span class="line">    nodeSelector: &#123;&#125;</span><br><span class="line">    tolerations: []</span><br><span class="line">    affinity: &#123;&#125;</span><br><span class="line">  external:</span><br><span class="line">    host: &quot;10.2.8.44&quot;</span><br><span class="line">    port: &quot;6379&quot;</span><br><span class="line">    # The &quot;coreDatabaseIndex&quot; must be &quot;0&quot; as the library Harbor</span><br><span class="line">    # used doesn&#x27;t support configuring it</span><br><span class="line">    coreDatabaseIndex: &quot;0&quot;</span><br><span class="line">    jobserviceDatabaseIndex: &quot;1&quot;</span><br><span class="line">    registryDatabaseIndex: &quot;2&quot;</span><br><span class="line">    chartmuseumDatabaseIndex: &quot;3&quot;</span><br><span class="line">    password: &quot;&quot;</span><br><span class="line">  ## Additional deployment annotations</span><br><span class="line">  podAnnotations: &#123;&#125;</span><br></pre></td></tr></table></figure>

<p><strong>4、helm 初始化安装harbor</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# helm install . --name min</span><br><span class="line">NAME:   min</span><br><span class="line">LAST DEPLOYED: Mon Jan 28 17:01:09 2019</span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/PersistentVolumeClaim</span><br><span class="line">NAME                    STATUS   VOLUME  CAPACITY  ACCESS MODES  STORAGECLASS  AGE</span><br><span class="line">min-harbor-chartmuseum  Pending  1s</span><br><span class="line">min-harbor-jobservice   Pending  1s</span><br><span class="line">min-harbor-registry     Pending  1s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME                      TYPE       CLUSTER-IP      EXTERNAL-IP  PORT(S)            AGE</span><br><span class="line">min-harbor-adminserver    ClusterIP  10.254.7.52     &lt;none&gt;       80/TCP             1s</span><br><span class="line">min-harbor-chartmuseum    ClusterIP  10.254.80.86    &lt;none&gt;       80/TCP             1s</span><br><span class="line">min-harbor-clair          ClusterIP  10.254.221.71   &lt;none&gt;       6060/TCP           0s</span><br><span class="line">min-harbor-core           ClusterIP  10.254.114.190  &lt;none&gt;       80/TCP             0s</span><br><span class="line">min-harbor-database       ClusterIP  10.254.146.141  &lt;none&gt;       5432/TCP           0s</span><br><span class="line">min-harbor-jobservice     ClusterIP  10.254.21.20    &lt;none&gt;       80/TCP             0s</span><br><span class="line">min-harbor-notary-server  ClusterIP  10.254.255.218  &lt;none&gt;       4443/TCP           0s</span><br><span class="line">min-harbor-notary-signer  ClusterIP  10.254.203.88   &lt;none&gt;       7899/TCP           0s</span><br><span class="line">min-harbor-portal         ClusterIP  10.254.73.42    &lt;none&gt;       80/TCP             0s</span><br><span class="line">min-harbor-redis          ClusterIP  10.254.134.216  &lt;none&gt;       6379/TCP           0s</span><br><span class="line">min-harbor-registry       ClusterIP  10.254.69.96    &lt;none&gt;       5000/TCP,8080/TCP  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Deployment</span><br><span class="line">NAME                      DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE</span><br><span class="line">min-harbor-adminserver    1        1        1           0          0s</span><br><span class="line">min-harbor-chartmuseum    1        1        1           0          0s</span><br><span class="line">min-harbor-clair          1        1        1           0          0s</span><br><span class="line">min-harbor-core           1        0        0           0          0s</span><br><span class="line">min-harbor-jobservice     1        0        0           0          0s</span><br><span class="line">min-harbor-notary-server  1        0        0           0          0s</span><br><span class="line">min-harbor-notary-signer  1        0        0           0          0s</span><br><span class="line">min-harbor-portal         1        0        0           0          0s</span><br><span class="line">min-harbor-registry       1        0        0           0          0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/StatefulSet</span><br><span class="line">NAME                 DESIRED  CURRENT  AGE</span><br><span class="line">min-harbor-database  1        1        0s</span><br><span class="line">min-harbor-redis     1        1        0s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Ingress</span><br><span class="line">NAME                HOSTS                                                    ADDRESS  PORTS  AGE</span><br><span class="line">min-harbor-ingress  core-harbor.minminmsn.com,notary-harbor.minminmsn.com  80, 443  0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                       READY  STATUS             RESTARTS  AGE</span><br><span class="line">min-harbor-adminserver-54877f95bd-45vq2    0/1    ContainerCreating  0         0s</span><br><span class="line">min-harbor-chartmuseum-7d59b659df-jkt9f    0/1    Pending            0         0s</span><br><span class="line">min-harbor-clair-69f89c644-hg6qp           0/1    ContainerCreating  0         0s</span><br><span class="line">min-harbor-core-5cdff64cc8-9vw2w           0/1    ContainerCreating  0         0s</span><br><span class="line">min-harbor-jobservice-bbdf5bbcd-qsz9h      0/1    Pending            0         0s</span><br><span class="line">min-harbor-notary-server-dcbccf89b-9gpsp   0/1    Pending            0         0s</span><br><span class="line">min-harbor-notary-signer-5d45d46d64-d4sjg  0/1    ContainerCreating  0         0s</span><br><span class="line">min-harbor-database-0                      0/1    Pending            0         0s</span><br><span class="line">min-harbor-redis-0                         0/1    Pending            0         0s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Secret</span><br><span class="line">NAME                    TYPE               DATA  AGE</span><br><span class="line">min-harbor-adminserver  Opaque             4     1s</span><br><span class="line">min-harbor-chartmuseum  Opaque             1     1s</span><br><span class="line">min-harbor-core         Opaque             4     1s</span><br><span class="line">min-harbor-database     Opaque             1     1s</span><br><span class="line">min-harbor-ingress      kubernetes.io/tls  3     1s</span><br><span class="line">min-harbor-jobservice   Opaque             1     1s</span><br><span class="line">min-harbor-registry     Opaque             1     1s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                      DATA  AGE</span><br><span class="line">min-harbor-adminserver    39    1s</span><br><span class="line">min-harbor-chartmuseum    24    1s</span><br><span class="line">min-harbor-clair          1     1s</span><br><span class="line">min-harbor-core           1     1s</span><br><span class="line">min-harbor-jobservice     1     1s</span><br><span class="line">min-harbor-notary-server  5     1s</span><br><span class="line">min-harbor-registry       2     1s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">Please wait for several minutes for Harbor deployment to complete.</span><br><span class="line">Then you should be able to visit the Harbor portal at https://core-harbor.minminmsn.com. </span><br><span class="line">For more details, please visit https://github.com/goharbor/harbor.</span><br></pre></td></tr></table></figure>

<p><strong>5、验证pv与pvc</strong> 主要是pv与pvc如果没有自动创建存储的条件需要提前手动创建好pv几pvc，然后value.yaml文件里选择existingClaim，填写各自pvc的名字即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# kubectl get pv</span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                         STORAGECLASS   REASON   AGE</span><br><span class="line">ceph-rbd-pv                                20Gi       RWO            Recycle          Bound    default/ceph-rbd-pv-claim                                             7d1h</span><br><span class="line">jenkins-home-pv                            40Gi       RWO            Recycle          Bound    default/jenkins-home-pvc                                              6d2h</span><br><span class="line">pvc-84079273-22de-11e9-a09d-52540089b2b6   5Gi        RWO            Delete           Bound    default/min-harbor-chartmuseum                rbd                     43s</span><br><span class="line">pvc-84085284-22de-11e9-a09d-52540089b2b6   2Gi        RWO            Delete           Bound    default/min-harbor-jobservice                 rbd                     56s</span><br><span class="line">pvc-840a9404-22de-11e9-a09d-52540089b2b6   50Gi       RWO            Delete           Bound    default/min-harbor-registry                   rbd                     56s</span><br><span class="line">pvc-844d2f2d-22de-11e9-a09d-52540089b2b6   2Gi        RWO            Delete           Bound    default/database-data-min-harbor-database-0   rbd                     43s</span><br><span class="line">pvc-8455d703-22de-11e9-a09d-52540089b2b6   2Gi        RWO            Delete           Bound    default/data-min-harbor-redis-0               rbd                     43s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 harbor-helm]# kubectl get pvc</span><br><span class="line">NAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">ceph-rbd-pv-claim                     Bound    ceph-rbd-pv                                20Gi       RWO                           7d1h</span><br><span class="line">data-min-harbor-redis-0               Bound    pvc-8455d703-22de-11e9-a09d-52540089b2b6   2Gi        RWO            rbd            46s</span><br><span class="line">database-data-min-harbor-database-0   Bound    pvc-844d2f2d-22de-11e9-a09d-52540089b2b6   2Gi        RWO            rbd            46s</span><br><span class="line">jenkins-home-pvc                      Bound    jenkins-home-pv                            40Gi       RWO                           6d2h</span><br><span class="line">min-harbor-chartmuseum                Bound    pvc-84079273-22de-11e9-a09d-52540089b2b6   5Gi        RWO            rbd            46s</span><br><span class="line">min-harbor-jobservice                 Bound    pvc-84085284-22de-11e9-a09d-52540089b2b6   2Gi        RWO            rbd            46s</span><br><span class="line">min-harbor-registry                   Bound    pvc-840a9404-22de-11e9-a09d-52540089b2b6   50Gi       RWO            rbd            46s</span><br></pre></td></tr></table></figure>

<p><strong>6、验证ceph rbd</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# rbd list rbd-k8s</span><br><span class="line">cephimage1</span><br><span class="line">cephimage2</span><br><span class="line">cephimage3</span><br><span class="line">kubernetes-dynamic-pvc-8420311c-22de-11e9-b7ec-02420afe4907</span><br><span class="line">kubernetes-dynamic-pvc-84203268-22de-11e9-b7ec-02420afe4907</span><br><span class="line">kubernetes-dynamic-pvc-8bfd862e-22de-11e9-b7ec-02420afe4907</span><br><span class="line">kubernetes-dynamic-pvc-8bfe7a4f-22de-11e9-b7ec-02420afe4907</span><br><span class="line">kubernetes-dynamic-pvc-8bfe9445-22de-11e9-b7ec-02420afe4907</span><br></pre></td></tr></table></figure>

<p><strong>7、验证pods</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# kubectl get pods</span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox                                     1/1     Running   600        25d</span><br><span class="line">ceph-rbd-pv-pod1                            1/1     Running   10         6d23h</span><br><span class="line">jenkins-0                                   1/1     Running   0          6d2h</span><br><span class="line">min-harbor-adminserver-685ccf67d7-k6z4p     1/1     Running   1          5m10s</span><br><span class="line">min-harbor-chartmuseum-7d59b659df-nglbx     1/1     Running   0          5m10s</span><br><span class="line">min-harbor-clair-69f89c644-62428            1/1     Running   1          5m10s</span><br><span class="line">min-harbor-core-5cdd9c7bc9-z2lnd            1/1     Running   1          5m10s</span><br><span class="line">min-harbor-database-0                       1/1     Running   0          5m10s</span><br><span class="line">min-harbor-jobservice-9889c95b9-s656x       1/1     Running   0          5m10s</span><br><span class="line">min-harbor-notary-server-588bc8bf45-t7mkz   1/1     Running   0          5m10s</span><br><span class="line">min-harbor-notary-signer-6d967d4c-jhvfs     1/1     Running   0          5m10s</span><br><span class="line">min-harbor-portal-798ff99d56-vxnnx          1/1     Running   0          5m9s</span><br><span class="line">min-harbor-redis-0                          1/1     Running   0          5m10s</span><br><span class="line">min-harbor-registry-54b5cd848d-4nr95        2/2     Running   0          5m9s</span><br><span class="line">rbd-provisioner-67b4857bcd-xxwx5            1/1     Running   0          42m</span><br></pre></td></tr></table></figure>

<p><strong>期间遇到各种报错可以重置helm环境</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# helm install . --name min</span><br><span class="line">helm delete --purge min</span><br><span class="line">These resources were kept due to the resource policy:</span><br><span class="line">[PersistentVolumeClaim] min-harbor-chartmuseum</span><br><span class="line">[PersistentVolumeClaim] min-harbor-jobservice</span><br><span class="line">[PersistentVolumeClaim] min-harbor-registry</span><br><span class="line"></span><br><span class="line">release &quot;min&quot; deleted</span><br></pre></td></tr></table></figure>

<h3 id="四、访问harobr"><a href="#四、访问harobr" class="headerlink" title="四、访问harobr"></a>四、访问harobr</h3><p><strong>1、获取harbor ingress 服务</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 harbor-helm]# kubectl get ingress</span><br><span class="line">NAME                 HOSTS                                                     ADDRESS   PORTS     AGE</span><br><span class="line">jenkins              jenkins.minminmsn.com                                              80, 443   6d2h</span><br><span class="line">min-harbor-ingress   core-harbor.minminmsn.com,notary-harbor.minminmsn.com             80, 443   6m43s</span><br></pre></td></tr></table></figure>

<p><strong>2、docker login登陆验证</strong> 注意这里docker login默认是走https协议，需要ingress的node节点443对外开放，之前部署的ingress没有启动hostNetwork为true，这里需要启动，可以通过kubectl edit deployment&#x2F;nginx-ingress-controller -n ingress-nginx修改，然后docker login就没问题了 登陆测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch02 ~]# docker login core-harbor.minminmsn.com</span><br><span class="line">Username: admin</span><br><span class="line">Password: </span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上传下载测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch02 ~]# docker tag registry.cn-beijing.aliyuncs.com/minminmsn/kubernetes-dashboard:v1.10.1 core-harbor.minminmsn.com/public/kubernetes-dashboard:v1.10.1</span><br><span class="line">[root@elasticsearch02 ~]# docker push core-harbor.minminmsn.com/public/kubernetes-dashboard:v1.10.1</span><br><span class="line">The push refers to repository [core-harbor.minminmsn.com/public/kubernetes-dashboard]</span><br><span class="line">fbdfe08b001c: Pushed </span><br><span class="line">v1.10.1: digest: sha256:54cc02a35d33a5ff9f8aa1a1b43f375728bcd85034cb311bdaf5c14f48340733 size: 529</span><br><span class="line"></span><br><span class="line">[root@elasticsearch03 ~]# docker pull core-harbor.minminmsn.com/public/kubernetes-dashboard:v1.10.1</span><br><span class="line">v1.10.1: Pulling from public/kubernetes-dashboard</span><br><span class="line">Digest: sha256:54cc02a35d33a5ff9f8aa1a1b43f375728bcd85034cb311bdaf5c14f48340733</span><br><span class="line">Status: Downloaded newer image for core-harbor.minminmsn.com/public/kubernetes-dashboard:v1.10.1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>3、配置解析浏览器访问</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://core-harbor.minminmsn.com/">https://core-harbor.minminmsn.com</a> <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/30/5c50fed828261.png"><img src="/images/5c50fed828261.png"></a> <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/30/5c50ff0dacd5f.png"><img src="/images/5c50ff0dacd5f.png"></a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/27/2019/01/2019-01-27-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7helm/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/27/2019/01/2019-01-27-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7helm/index/" class="post-title-link" itemprop="url">kubernetes1.13.1集群安装包管理工具helm</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-27 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-27T08:00:00+08:00">2019-01-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:31" itemprop="dateModified" datetime="2023-05-26T15:06:31+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/goharbor/harbor-helm</span><br><span class="line">https://docs.helm.sh/using_helm/#installing-helm</span><br><span class="line">https://github.com/goharbor/harbor/blob/master/docs/kubernetes_deployment.md</span><br><span class="line">https://github.com/goharbor/harbor-helm/blob/master/docs/High%20Availability.md</span><br><span class="line">https://li-sen.github.io/2018/10/08/k8s%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8harbor/</span><br><span class="line">https://www.cnblogs.com/ericnie/p/8463127.html</span><br><span class="line">https://www.bountysource.com/issues/60265705-error-looks-like-https-kubernetes-charts-storage-googleapis-com-is-not-a-valid-chart-repository-or-cannot-be-reached-pipline-error-exit-status-1</span><br></pre></td></tr></table></figure>

<h3 id="一、安装helm客户端"><a href="#一、安装helm客户端" class="headerlink" title="一、安装helm客户端"></a>一、安装helm客户端</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ~] wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.3-linux-amd64.tar.gz</span><br><span class="line">[root@elasticsearch01 ~] tar zxvf helm-v2.12.3-linux-amd64.tar.gz </span><br><span class="line">[root@elasticsearch01 ~] cd linux-amd64/</span><br><span class="line">[root@elasticsearch01 linux-amd64]mv helm tiller /usr/local/bin/</span><br><span class="line">[root@elasticsearch01 linux-amd64]# helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:&quot;v2.12.3&quot;, GitCommit:&quot;eecf22f77df5f65c823aacd2dbd30ae6c65f186e&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br><span class="line">Error: could not find tiller</span><br></pre></td></tr></table></figure>

<h3 id="二、安装tiller"><a href="#二、安装tiller" class="headerlink" title="二、安装tiller"></a>二、安装tiller</h3><p>依赖关系 socat 需要在各个节点上安装socat yum install socat</p>
<p><strong>1、创建rbac角色</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# cat helm-rbac.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: tiller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: tiller</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: tiller</span><br><span class="line">    namespace: kube-system</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 helm]# kubectl create -f helm-rbac.yaml </span><br><span class="line">serviceaccount/tiller created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/tiller created</span><br></pre></td></tr></table></figure>

<p><strong>2、初始化安装tiller</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# helm init</span><br><span class="line">Creating /root/.helm </span><br><span class="line">Creating /root/.helm/repository </span><br><span class="line">Creating /root/.helm/repository/cache </span><br><span class="line">Creating /root/.helm/repository/local </span><br><span class="line">Creating /root/.helm/plugins </span><br><span class="line">Creating /root/.helm/starters </span><br><span class="line">Creating /root/.helm/cache/archive </span><br><span class="line">Creating /root/.helm/repository/repositories.yaml </span><br><span class="line">Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com </span><br><span class="line">Error: Looks like &quot;https://kubernetes-charts.storage.googleapis.com&quot; is not a valid chart repository or cannot be reached: Get https://kubernetes-charts.storage.googleapis.com/index.yaml: read tcp 10.2.8.44:49020-&gt;216.58.220.208:443: read: connection reset by peer</span><br></pre></td></tr></table></figure>

<p>报错一 更换国内源</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line">&quot;stable&quot; has been added to your repositories</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 helm]# helm init</span><br><span class="line">$HELM_HOME has been configured at /root/.helm.</span><br><span class="line">Warning: Tiller is already installed in the cluster.</span><br><span class="line">(Use --client-only to suppress this message, or --upgrade to upgrade Tiller to the current version.)</span><br><span class="line">Happy Helming!</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 helm]# helm repo update</span><br><span class="line">Hang tight while we grab the latest from your chart repositories...</span><br><span class="line">...Skip local chart repository</span><br><span class="line">...Successfully got an update from the &quot;stable&quot; chart repository</span><br><span class="line">Update Complete. ⎈ Happy Helming!⎈ </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# kubectl get pods -n kube-system</span><br><span class="line">NAME                                   READY   STATUS             RESTARTS   AGE</span><br><span class="line">coredns-7748f7f6df-2c7ws               1/1     Running            0          21d</span><br><span class="line">coredns-7748f7f6df-chhwx               1/1     Running            0          21d</span><br><span class="line">kubernetes-dashboard-cb55bd5bd-p644x   1/1     Running            0          15d</span><br><span class="line">kubernetes-dashboard-cb55bd5bd-vlmdh   1/1     Running            0          22d</span><br><span class="line">metrics-server-788c48df64-cfnnx        1/1     Running            0          13d</span><br><span class="line">metrics-server-788c48df64-v75gr        1/1     Running            0          13d</span><br><span class="line">tiller-deploy-69ffbf64bc-rxcj8         0/1     ImagePullBackOff   0          6m13s</span><br><span class="line">[root@elasticsearch01 helm]# </span><br></pre></td></tr></table></figure>

<p>报错二 更换国内docker镜像（gcr.io&#x2F;kubernetes-helm&#x2F;tiller:v2.12.3），或者下载镜像后重新打标签</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# kubectl describe pod/tiller-deploy-69ffbf64bc-rxcj8  -n kube-system</span><br><span class="line">Name:               tiller-deploy-69ffbf64bc-rxcj8</span><br><span class="line">Namespace:          kube-system</span><br><span class="line">Priority:           0</span><br><span class="line">PriorityClassName:  &lt;none&gt;</span><br><span class="line">Node:               10.2.8.34/10.2.8.34</span><br><span class="line">Start Time:         Fri, 25 Jan 2019 09:46:25 +0800</span><br><span class="line">Labels:             app=helm</span><br><span class="line">                    name=tiller</span><br><span class="line">                    pod-template-hash=69ffbf64bc</span><br><span class="line">Annotations:        &lt;none&gt;</span><br><span class="line">Status:             Pending</span><br><span class="line">IP:                 10.254.73.7</span><br><span class="line">Controlled By:      ReplicaSet/tiller-deploy-69ffbf64bc</span><br><span class="line">Containers:</span><br><span class="line">  tiller:</span><br><span class="line">    Container ID:   </span><br><span class="line">    Image:          gcr.io/kubernetes-helm/tiller:v2.12.3</span><br><span class="line">    Image ID:       </span><br><span class="line">    Ports:          44134/TCP, 44135/TCP</span><br><span class="line">    Host Ports:     0/TCP, 0/TCP</span><br><span class="line">    State:          Waiting</span><br><span class="line">      Reason:       ImagePullBackOff</span><br><span class="line">    Ready:          False</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Liveness:       http-get http://:44135/liveness delay=1s timeout=1s period=10s #success=1 #failure=3</span><br><span class="line">    Readiness:      http-get http://:44135/readiness delay=1s timeout=1s period=10s #success=1 #failure=3</span><br><span class="line">    Environment:</span><br><span class="line">      TILLER_NAMESPACE:    kube-system</span><br><span class="line">      TILLER_HISTORY_MAX:  0</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-f8hz7 (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True </span><br><span class="line">  Ready             False </span><br><span class="line">  ContainersReady   False </span><br><span class="line">  PodScheduled      True </span><br><span class="line">Volumes:</span><br><span class="line">  default-token-f8hz7:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default-token-f8hz7</span><br><span class="line">    Optional:    false</span><br><span class="line">QoS Class:       BestEffort</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason     Age                   From                Message</span><br><span class="line">  ---- ------ ---- ---- -------</span><br><span class="line">  Normal   Scheduled  10m                   default-scheduler   Successfully assigned kube-system/tiller-deploy-69ffbf64bc-rxcj8 to 10.2.8.34</span><br><span class="line">  Normal   Pulling    8m36s (x4 over 10m)   kubelet, 10.2.8.34  pulling image &quot;gcr.io/kubernetes-helm/tiller:v2.12.3&quot;</span><br><span class="line">  Warning  Failed     8m21s (x4 over 10m)   kubelet, 10.2.8.34  Failed to pull image &quot;gcr.io/kubernetes-helm/tiller:v2.12.3&quot;: rpc error: code = Unknown desc = Error response from daemon: Get https://gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)</span><br><span class="line">  Warning  Failed     8m21s (x4 over 10m)   kubelet, 10.2.8.34  Error: ErrImagePull</span><br><span class="line">  Normal   BackOff    5m51s (x15 over 10m)  kubelet, 10.2.8.34  Back-off pulling image &quot;gcr.io/kubernetes-helm/tiller:v2.12.3&quot;</span><br><span class="line">  Warning  Failed     49s (x36 over 10m)    kubelet, 10.2.8.34  Error: ImagePullBackOff</span><br></pre></td></tr></table></figure>

<p>可以通过阿里云容器服务节后github构建海外镜像到国内</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch02 ~]# docker pull registry.cn-beijing.aliyuncs.com/minminmsn/tiller:v2.12.3</span><br><span class="line">v2.12.3: Pulling from minminmsn/tiller</span><br><span class="line">407ea412d82c: Pull complete </span><br><span class="line">b384553aa9a9: Pull complete </span><br><span class="line">9015cc67398b: Pull complete </span><br><span class="line">b4d55549c9ed: Pull complete </span><br><span class="line">Digest: sha256:bbc6dbfc37b82de97da58ce9a99b17db8f474b3deb51130c36f463849c69bd3b</span><br><span class="line">Status: Downloaded newer image for registry.cn-beijing.aliyuncs.com/minminmsn/tiller:v2.12.3</span><br><span class="line">[root@elasticsearch02 ~]# docker tag registry.cn-beijing.aliyuncs.com/minminmsn/tiller:v2.12.3 gcr.io/kubernetes-helm/tiller:v2.12.3</span><br><span class="line">[root@elasticsearch02 ~]# docker images |grep tiller</span><br><span class="line">gcr.io/kubernetes-helm/tiller                                     v2.12.3             336eb7f809d0        5 minutes ago       81.4MB</span><br><span class="line">registry.cn-beijing.aliyuncs.com/minminmsn/tiller                 v2.12.3             336eb7f809d0        5 minutes ago       81.4MB</span><br></pre></td></tr></table></figure>

<p>等一会儿查看tiller pod正常运行了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# kubectl get pods -n kube-system</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-7748f7f6df-2c7ws               1/1     Running   0          21d</span><br><span class="line">coredns-7748f7f6df-chhwx               1/1     Running   0          21d</span><br><span class="line">kubernetes-dashboard-cb55bd5bd-p644x   1/1     Running   0          15d</span><br><span class="line">kubernetes-dashboard-cb55bd5bd-vlmdh   1/1     Running   0          22d</span><br><span class="line">metrics-server-788c48df64-cfnnx        1/1     Running   0          13d</span><br><span class="line">metrics-server-788c48df64-v75gr        1/1     Running   0          13d</span><br><span class="line">tiller-deploy-69ffbf64bc-rxcj8         1/1     Running   0          28m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 helm]# kubectl log pod/tiller-deploy-69ffbf64bc-rxcj8  -n kube-system</span><br><span class="line">log is DEPRECATED and will be removed in a future version. Use logs instead.</span><br><span class="line">[main] 2019/01/25 02:13:01 Starting Tiller v2.12.3 (tls=false)</span><br><span class="line">[main] 2019/01/25 02:13:01 GRPC listening on :44134</span><br><span class="line">[main] 2019/01/25 02:13:01 Probes listening on :44135</span><br><span class="line">[main] 2019/01/25 02:13:01 Storage driver is ConfigMap</span><br><span class="line">[main] 2019/01/25 02:13:01 Max history per release is 0</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 helm]# helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:&quot;v2.12.3&quot;, GitCommit:&quot;eecf22f77df5f65c823aacd2dbd30ae6c65f186e&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:&quot;v2.12.3&quot;, GitCommit:&quot;eecf22f77df5f65c823aacd2dbd30ae6c65f186e&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br></pre></td></tr></table></figure>

<p>其他错误</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# helm list</span><br><span class="line">Error: configmaps is forbidden: User &quot;system:serviceaccount:kube-system:default&quot; cannot list resource &quot;configmaps&quot; in API group &quot;&quot; in the namespace &quot;kube-system&quot;</span><br></pre></td></tr></table></figure>

<p>处理方式参考<a target="_blank" rel="noopener" href="https://github.com/helm/helm/issues/3130">https://github.com/helm/helm/issues/3130</a> 原因分析，rbac权限问题，其实之前已经创建过，只是没有生效，需要重启tiller使其生效</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 helm]# helm init --upgrade --service-account tiller</span><br><span class="line">$HELM_HOME has been configured at /root/.helm.</span><br><span class="line"></span><br><span class="line">Tiller (the Helm server-side component) has been upgraded to the current version.</span><br><span class="line">Happy Helming!</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 helm]# kubectl get pods -n kube-system</span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns-7748f7f6df-2c7ws               1/1     Running   0          24d</span><br><span class="line">coredns-7748f7f6df-chhwx               1/1     Running   0          24d</span><br><span class="line">kubernetes-dashboard-cb55bd5bd-p644x   1/1     Running   0          18d</span><br><span class="line">kubernetes-dashboard-cb55bd5bd-vlmdh   1/1     Running   0          25d</span><br><span class="line">metrics-server-788c48df64-cfnnx        1/1     Running   0          16d</span><br><span class="line">metrics-server-788c48df64-v75gr        1/1     Running   0          16d</span><br><span class="line">tiller-deploy-dbb85cb99-9mhk8          1/1     Running   0          32s</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/24/2019/01/2019-01-24-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph-rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/24/2019/01/2019-01-24-kubernetes1-13-1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph-rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins/index/" class="post-title-link" itemprop="url">kubernetes1.13.1集群结合ceph rbd部署最新版本jenkins</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-24 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-24T08:00:00+08:00">2019-01-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:31" itemprop="dateModified" datetime="2023-05-26T15:06:31+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://blog.csdn.net/aixiaoyang168/article/details/79767649</span><br><span class="line">https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/kubernetes</span><br><span class="line">https://www.cnblogs.com/cocowool/p/kubernetes_statefulset.html</span><br><span class="line">https://www.cnblogs.com/cocowool/p/kubernetes_storage.html</span><br></pre></td></tr></table></figure>

<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h3><p><strong>jenkins-kubernetes-plugin</strong> Jenkins plugin to run dynamic agents in a Kubernetes cluster. Based on the Scaling Docker with Kubernetes article, automates the scaling of Jenkins agents running in Kubernetes. The plugin creates a Kubernetes Pod for each agent started, defined by the Docker image to run, and stops it after each build. Agents are launched using JNLP, so it is expected that the image connects automatically to the Jenkins master. For that some environment variables are automatically injected: + JENKINS_URL: Jenkins web interface url + JENKINS_SECRET: the secret key for authentication + JENKINS_AGENT_NAME: the name of the Jenkins agent + JENKINS_NAME: the name of the Jenkins agent (Deprecated. Only here for backwards compatibility)</p>
<h3 id="基本环境"><a href="#基本环境" class="headerlink" title="基本环境"></a><strong>基本环境</strong></h3><p>k81集群1.13.1版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ~]# kubectl get nodes</span><br><span class="line">NAME        STATUS   ROLES    AGE   VERSION</span><br><span class="line">10.2.8.34   Ready    &lt;none&gt;   25d   v1.13.1</span><br><span class="line">10.2.8.65   Ready    &lt;none&gt;   25d   v1.13.1</span><br></pre></td></tr></table></figure>

<p>ceph集群 luminous版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# ceph -s</span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph01,ceph02,ceph03</span><br><span class="line">    mgr: ceph03(active), standbys: ceph02, ceph01</span><br><span class="line">    osd: 24 osds: 24 up, 24 in</span><br><span class="line">    rgw: 3 daemons active</span><br></pre></td></tr></table></figure>

<h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a><strong>操作步骤</strong></h3><h4 id="一、使用ceph-rbd创建pv、pvc"><a href="#一、使用ceph-rbd创建pv、pvc" class="headerlink" title="一、使用ceph rbd创建pv、pvc"></a><strong>一、使用ceph rbd创建pv、pvc</strong></h4><p>官网使用的是自带创建pv与pvc这里使用的是手动创建 <strong>1、创建pv</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 jenkins]# cat jenkins-pv.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins-home-pv</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 40Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  rbd:</span><br><span class="line">    monitors:</span><br><span class="line">      - &#x27;10.0.4.10:6789&#x27;</span><br><span class="line">      - &#x27;10.0.4.13:6789&#x27;</span><br><span class="line">      - &#x27;10.0.4.15:6789&#x27;</span><br><span class="line">    pool: rbd-k8s</span><br><span class="line">    image: cephimage3</span><br><span class="line">    user: admin</span><br><span class="line">    secretRef:</span><br><span class="line">      name: ceph-secret</span><br><span class="line">    fsType: ext4</span><br><span class="line">    readOnly: false</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl create -f jenkins-pv.yaml </span><br><span class="line">persistentvolume/jenkins-home-pv created</span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl get pv</span><br><span class="line">NAME              CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                       STORAGECLASS   REASON   AGE</span><br><span class="line">ceph-rbd-pv       20Gi       RWO            Recycle          Bound       default/ceph-rbd-pv-claim                           22h</span><br><span class="line">jenkins-home-pv   40Gi       RWO            Recycle          Available                                                       4s</span><br></pre></td></tr></table></figure>

<p><strong>2、创建pvc</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 jenkins]# cat jenkins-pvc.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins-home-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 20Gi</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl create -f jenkins-pvc.yaml </span><br><span class="line">persistentvolumeclaim/jenkins-home-pvc created</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl get pvc</span><br><span class="line">NAME                STATUS   VOLUME            CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">ceph-rbd-pv-claim   Bound    ceph-rbd-pv       20Gi       RWO                           22h</span><br><span class="line">jenkins-home-pvc    Bound    jenkins-home-pv   40Gi       RWO                           3s</span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl get pv</span><br><span class="line">NAME              CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                       STORAGECLASS   REASON   AGE</span><br><span class="line">ceph-rbd-pv       20Gi       RWO            Recycle          Bound    default/ceph-rbd-pv-claim                           22h</span><br><span class="line">jenkins-home-pv   40Gi       RWO            Recycle          Bound    default/jenkins-home-pvc                            77s</span><br></pre></td></tr></table></figure>

<h4 id="二、跟进实际情况修改jenkins-yml文件"><a href="#二、跟进实际情况修改jenkins-yml文件" class="headerlink" title="二、跟进实际情况修改jenkins.yml文件"></a><strong>二、跟进实际情况修改jenkins.yml文件</strong></h4><p>主要修改的配置从上到下分别是： <strong>1、拉取镜像策略</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">imagePullPolicy: IfNotPresent</span><br></pre></td></tr></table></figure>

<p><strong>2、自动存储storage class改成voulumes的pvc方式实现</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">volumes:</span><br><span class="line">- name: jenkins-home</span><br><span class="line">  persistentVolumeClaim:</span><br><span class="line">    claimName: jenkins-home-pvc</span><br></pre></td></tr></table></figure>

<p><strong>3、ingress的host改成实际的</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">host: jenkins.minminmsn.com</span><br></pre></td></tr></table></figure>

<p><strong>4、ingres的tls证书改成实际的</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tls:</span><br><span class="line">- hosts:</span><br><span class="line">  - jenkins.minminmsn.com</span><br><span class="line">  secretName: ingress-secret</span><br></pre></td></tr></table></figure>

<p><strong>5、具体如下</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 jenkins]# cat jenkins.yml </span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1beta1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">  labels:</span><br><span class="line">    name: jenkins</span><br><span class="line">spec:</span><br><span class="line">  serviceName: jenkins</span><br><span class="line">  replicas: 1</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: jenkins</span><br><span class="line">      labels:</span><br><span class="line">        name: jenkins</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 10</span><br><span class="line">      serviceAccountName: jenkins</span><br><span class="line">      containers:</span><br><span class="line">        - name: jenkins</span><br><span class="line">          image: jenkins/jenkins:lts-alpine</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 8080</span><br><span class="line">            - containerPort: 50000</span><br><span class="line">          resources:</span><br><span class="line">            limits:</span><br><span class="line">              cpu: 1</span><br><span class="line">              memory: 1Gi</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 0.5</span><br><span class="line">              memory: 500Mi</span><br><span class="line">          env:</span><br><span class="line">            - name: LIMITS_MEMORY</span><br><span class="line">              valueFrom:</span><br><span class="line">                resourceFieldRef:</span><br><span class="line">                  resource: limits.memory</span><br><span class="line">                  divisor: 1Mi</span><br><span class="line">            - name: JAVA_OPTS</span><br><span class="line">              # value: -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1 -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85</span><br><span class="line">              value: -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: jenkins-home</span><br><span class="line">              mountPath: /var/jenkins_home</span><br><span class="line">              readOnly: false</span><br><span class="line">          livenessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /login</span><br><span class="line">              port: 8080</span><br><span class="line">            initialDelaySeconds: 60</span><br><span class="line">            timeoutSeconds: 5</span><br><span class="line">            failureThreshold: 12 # ~2 minutes</span><br><span class="line">          readinessProbe:</span><br><span class="line">            httpGet:</span><br><span class="line">              path: /login</span><br><span class="line">              port: 8080</span><br><span class="line">            initialDelaySeconds: 60</span><br><span class="line">            timeoutSeconds: 5</span><br><span class="line">            failureThreshold: 12 # ~2 minutes</span><br><span class="line">      securityContext:</span><br><span class="line">        fsGroup: 1000</span><br><span class="line">      volumes:</span><br><span class="line">      - name: jenkins-home</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: jenkins-home-pvc</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">spec:</span><br><span class="line">  # type: LoadBalancer</span><br><span class="line">  selector:</span><br><span class="line">    name: jenkins</span><br><span class="line">  # ensure the client ip is propagated to avoid the invalid crumb issue when using LoadBalancer (k8s &gt;=1.7)</span><br><span class="line">  #externalTrafficPolicy: Local</span><br><span class="line">  ports:</span><br><span class="line">    -</span><br><span class="line">      name: http</span><br><span class="line">      port: 80</span><br><span class="line">      targetPort: 8080</span><br><span class="line">      protocol: TCP</span><br><span class="line">    -</span><br><span class="line">      name: agent</span><br><span class="line">      port: 50000</span><br><span class="line">      protocol: TCP</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class="line">    kubernetes.io/tls-acme: &quot;true&quot;</span><br><span class="line">    # &quot;413 Request Entity Too Large&quot; uploading plugins, increase client_max_body_size</span><br><span class="line">    nginx.ingress.kubernetes.io/proxy-body-size: 50m</span><br><span class="line">    nginx.ingress.kubernetes.io/proxy-request-buffering: &quot;off&quot;</span><br><span class="line">    # For nginx-ingress controller &lt; 0.9.0.beta-18</span><br><span class="line">    ingress.kubernetes.io/ssl-redirect: &quot;true&quot;</span><br><span class="line">    # &quot;413 Request Entity Too Large&quot; uploading plugins, increase client_max_body_size</span><br><span class="line">    ingress.kubernetes.io/proxy-body-size: 50m</span><br><span class="line">    ingress.kubernetes.io/proxy-request-buffering: &quot;off&quot;</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: jenkins</span><br><span class="line">          servicePort: 80</span><br><span class="line">    host: jenkins.minminmsn.com</span><br><span class="line">  tls:</span><br><span class="line">  - hosts:</span><br><span class="line">    - jenkins.minminmsn.com</span><br><span class="line">    secretName: ingress-secret</span><br></pre></td></tr></table></figure>

<h4 id="三、创建状态集、svc、pod、ingress"><a href="#三、创建状态集、svc、pod、ingress" class="headerlink" title="三、创建状态集、svc、pod、ingress"></a><strong>三、创建状态集、svc、pod、ingress</strong></h4><p><strong>1、创建rbac认证角色</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 jenkins]# kubectl create -f service-account.yml </span><br><span class="line">serviceaccount/jenkins created</span><br><span class="line">role.rbac.authorization.k8s.io/jenkins created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/jenkins created</span><br></pre></td></tr></table></figure>

<p><strong>2、创建jenkins服务等</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 jenkins]# kubectl create -f jenkins.yml </span><br><span class="line">statefulset.apps/jenkins created</span><br><span class="line">service/jenkins created</span><br><span class="line">ingress.extensions/jenkins created        4s</span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl get pods</span><br><span class="line">NAME               READY   STATUS              RESTARTS   AGE</span><br><span class="line">busybox            1/1     Running             454        18d</span><br><span class="line">ceph-rbd-pv-pod1   1/1     Running             1          21h</span><br><span class="line">jenkins-0          0/1     ContainerCreating   0          7s</span><br><span class="line">[root@elasticsearch01 jenkins]# kubectl get pods</span><br><span class="line">NAME               READY   STATUS    RESTARTS   AGE</span><br><span class="line">busybox            1/1     Running   454        18d</span><br><span class="line">ceph-rbd-pv-pod1   1/1     Running   1          21h</span><br><span class="line">jenkins-0          1/1     Running   0          4m52s</span><br></pre></td></tr></table></figure>

<h4 id="四、通过ingress访问"><a href="#四、通过ingress访问" class="headerlink" title="四、通过ingress访问"></a><strong>四、通过ingress访问</strong></h4><p>获取ingress-nginx对外端口，<a target="_blank" rel="noopener" href="https://jenkins.minminmsn.com:47215/%E8%AE%BF%E9%97%AE%E5%8D%B3%E5%8F%AF%EF%BC%8C%E9%9C%80%E8%A6%81%E9%85%8D%E7%BD%AEdns%E8%A7%A3%E6%9E%90%E5%88%B0pod%E6%89%80%E5%9C%A8node%E7%9A%84ip">https://jenkins.minminmsn.com:47215/访问即可，需要配置dns解析到pod所在node的ip</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 jenkins]# kubectl get svc -n ingress-nginx|grep ingress-nginx</span><br><span class="line">ingress-nginx       LoadBalancer   10.254.125.151   &lt;pending&gt;     80:33003/TCP,443:47215/TCP   14d</span><br></pre></td></tr></table></figure>

<h4 id="五、初始化jenkins"><a href="#五、初始化jenkins" class="headerlink" title="五、初始化jenkins"></a><strong>五、初始化jenkins</strong></h4><p><strong>1、查找密码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch02 ~]# df -h|grep rbd</span><br><span class="line">/dev/rbd0                  493G  163G  306G  35% /data</span><br><span class="line">/dev/rbd1                   20G   45M   20G   1% /var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/rbd-k8s-image-cephimage2</span><br><span class="line">/dev/rbd2                   40G  138M   40G   1% /var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/rbd-k8s-image-cephimage3</span><br><span class="line">[root@elasticsearch02 ~]# cd //var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/rbd-k8s-image-cephimage3</span><br><span class="line">[root@elasticsearch02 rbd-k8s-image-cephimage3]# ls</span><br><span class="line">config.xml                     init.groovy.d                        jobs              nodes                     secrets      war</span><br><span class="line">copy_reference_file.log        jenkins.CLI.xml                      logs              plugins                   updates</span><br><span class="line">hudson.model.UpdateCenter.xml  jenkins.install.UpgradeWizard.state  lost+found        secret.key                userContent</span><br><span class="line">identity.key.enc               jenkins.telemetry.Correlator.xml     nodeMonitors.xml  secret.key.not-so-secret  users</span><br><span class="line">[root@elasticsearch02 rbd-k8s-image-cephimage3]# cat secrets/initialAdminPassword </span><br><span class="line">92c145b796cc48b0af8b5ef0f7afce28</span><br></pre></td></tr></table></figure>

<blockquote>
<p><img src="/images/k8s1.png"></p>
</blockquote>
<p><strong>2、选择安装插件</strong></p>
<blockquote>
<p><img src="/images/k8s2.png"> <img src="/images/k8s3.png"></p>
</blockquote>
<p><strong>3、创建初始管理账号</strong></p>
<blockquote>
<p><img src="/images/k8s4.png"></p>
</blockquote>
<p><strong>4、设置jenkins url默认<a target="_blank" rel="noopener" href="https://jenkins.minminmsn.com:47215/">https://jenkins.minminmsn.com:47215/</a></strong></p>
<blockquote>
<p><img src="/images/k8s5.png"></p>
</blockquote>
<p><strong>5、开始使用jenkins</strong></p>
<blockquote>
<p><img src="/images/k8s6.png"></p>
</blockquote>
<p><strong>6、jenkins控制台界面，主要配置都在系统管理中</strong></p>
<blockquote>
<p><img src="/images/k8s7.png"></p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><blockquote>
<p>使用ceph rbd 这种只能读写一次的设备不能用在线上，线上应该使用分布式存储例如nfs，cephfs，glusterfs等，这里只是测试jenkins结合ceph，pv，pvc完成有状态pod的测试</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/21/2019/01/2019-01-21-kubernets1-13-1%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph-rbd%E5%9D%97%E5%AD%98%E5%82%A8/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/21/2019/01/2019-01-21-kubernets1-13-1%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph-rbd%E5%9D%97%E5%AD%98%E5%82%A8/index/" class="post-title-link" itemprop="url">kubernets1.13.1集群使用ceph rbd块存储</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-21 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-21T08:00:00+08:00">2019-01-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:31" itemprop="dateModified" datetime="2023-05-26T15:06:31+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/kubernetes/examples/tree/master/staging/volumes/rbd</span><br><span class="line">http://docs.ceph.com/docs/mimic/rados/operations/pools/</span><br><span class="line">https://blog.csdn.net/aixiaoyang168/article/details/78999851 </span><br><span class="line">https://www.cnblogs.com/keithtt/p/6410302.html</span><br><span class="line">https://kubernetes.io/docs/concepts/storage/volumes/</span><br><span class="line">https://kubernetes.io/docs/concepts/storage/persistent-volumes/</span><br><span class="line">https://blog.csdn.net/wenwenxiong/article/details/78406136</span><br><span class="line">http://www.mamicode.com/info-detail-1701743.html</span><br></pre></td></tr></table></figure>

<h3 id="文档目录"><a href="#文档目录" class="headerlink" title="文档目录"></a><strong>文档目录</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes/kubernetes1.13.1%2Betcd3.3.10%2Bflanneld0.10%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.md">kubernetes1.13.1+etcd3.3.10+flanneld0.10集群部署</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes-dashboard-amd64/Kubernetes1.13.1%E9%83%A8%E7%BD%B2Kuberneted-dashboard%20v1.10.1.md">kubernetes1.13.1部署kuberneted-dashboard v1.10.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/coredns/kubernetes1.13.1%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2coredns.md">kubernetes1.13.1部署coredns</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/ingress-nginx/kubernetes1.13.1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard.md">kubernetes1.13.1部署ingress-nginx并配置https转发dashboard</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/kubernetes1.13.1%E9%83%A8%E7%BD%B2metrics-server0.3.1.md">kubernetes1.13.1部署metrics-server0.3.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/volumes/rbd/k8s%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph%20rbd%E5%9D%97%E5%AD%98%E5%82%A8.md">kubernetes1.13.1集群使用ceph rbd存储块</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/jenkins/k8s1.13.1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph%20rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins.md">kubernetes1.13.1集群结合ceph rbd部署最新版本jenkins</a></li>
</ul>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h3><p>ceph支持对象存储，文件系统及块存储，是三合一存储类型，kubernetes的样例中有cephfs与rbd两种使用方式的介绍，cephfs需要node节点安装ceph才能支持，rbd需要node节点安装ceph-common才支持。 使用上的区别如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Volume Plugin   ReadWriteOnce   ReadOnlyMany    ReadWriteMany</span><br><span class="line">CephFS              ✓               ✓               ✓</span><br><span class="line">RBD                 ✓               ✓               -</span><br></pre></td></tr></table></figure>

<h3 id="基本环境"><a href="#基本环境" class="headerlink" title="基本环境"></a><strong>基本环境</strong></h3><p>k81集群1.13.1版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ~]# kubectl get nodes</span><br><span class="line">NAME        STATUS   ROLES    AGE   VERSION</span><br><span class="line">10.2.8.34   Ready    &lt;none&gt;   24d   v1.13.1</span><br><span class="line">10.2.8.65   Ready    &lt;none&gt;   24d   v1.13.1</span><br></pre></td></tr></table></figure>

<p>ceph集群 luminous版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# ceph -s</span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph01,ceph02,ceph03</span><br><span class="line">    mgr: ceph03(active), standbys: ceph02, ceph01</span><br><span class="line">    osd: 24 osds: 24 up, 24 in</span><br><span class="line">    rgw: 3 daemons active</span><br></pre></td></tr></table></figure>

<h3 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a><strong>操作步骤</strong></h3><h4 id="一、ceph集群创建ceph池及镜像"><a href="#一、ceph集群创建ceph池及镜像" class="headerlink" title="一、ceph集群创建ceph池及镜像"></a><strong>一、ceph集群创建ceph池及镜像</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# ceph osd pool create rbd-k8s 1024 1024 </span><br><span class="line">For better initial performance on pools expected to store a large number of objects, consider supplying the expected_num_objects parameter when creating the pool.</span><br><span class="line"></span><br><span class="line">[root@ceph01 ~]# ceph osd lspools </span><br><span class="line">1 rbd-es,2 .rgw.root,3 default.rgw.control,4 default.rgw.meta,5 default.rgw.log,6 default.rgw.buckets.index,7 default.rgw.buckets.data,8 default.rgw.buckets.non-ec,9 rbd-k8s,</span><br><span class="line"></span><br><span class="line">[root@ceph01 ~]# rbd create rbd-k8s/cephimage1 --size 10240</span><br><span class="line">[root@ceph01 ~]# rbd create rbd-k8s/cephimage2 --size 20480</span><br><span class="line">[root@ceph01 ~]# rbd create rbd-k8s/cephimage3 --size 40960</span><br><span class="line">[root@ceph01 ~]# rbd list rbd-k8s</span><br><span class="line">cephimage1</span><br><span class="line">cephimage2</span><br><span class="line">cephimage3</span><br></pre></td></tr></table></figure>

<h4 id="二、k8s集群使用ceph-rbd块存储"><a href="#二、k8s集群使用ceph-rbd块存储" class="headerlink" title="二、k8s集群使用ceph rbd块存储"></a><strong>二、k8s集群使用ceph rbd块存储</strong></h4><p><strong>1、下载样例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ~]# git clone https://github.com/kubernetes/examples.git</span><br><span class="line">Cloning into &#x27;examples&#x27;...</span><br><span class="line">remote: Enumerating objects: 11475, done.</span><br><span class="line">remote: Total 11475 (delta 0), reused 0 (delta 0), pack-reused 11475</span><br><span class="line">Receiving objects: 100% (11475/11475), 16.94 MiB | 6.00 MiB/s, done.</span><br><span class="line">Resolving deltas: 100% (6122/6122), done.</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 ~]# cd examples/staging/volumes/rbd</span><br><span class="line">[root@elasticsearch01 rbd]# ls</span><br><span class="line">rbd-with-secret.yaml  rbd.yaml  README.md  secret</span><br><span class="line">[root@elasticsearch01 rbd]# cp -a ./rbd /k8s/yaml/volumes/</span><br></pre></td></tr></table></figure>

<p><strong>2、k8s集群节点安装ceph客户端</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ceph]# yum  install ceph-common</span><br></pre></td></tr></table></figure>

<p><strong>3、修改rbd-with-secret.yaml配置文件</strong> 修改后配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# cat rbd-with-secret.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd2</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - image: kubernetes/pause</span><br><span class="line">      name: rbd-rw</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: rbdpd</span><br><span class="line">        mountPath: /mnt/rbd</span><br><span class="line">  volumes:</span><br><span class="line">    - name: rbdpd</span><br><span class="line">      rbd:</span><br><span class="line">        monitors:</span><br><span class="line">        - &#x27;10.0.4.10:6789&#x27;</span><br><span class="line">        - &#x27;10.0.4.13:6789&#x27;</span><br><span class="line">        - &#x27;10.0.4.15:6789&#x27;</span><br><span class="line">        pool: rbd-k8s</span><br><span class="line">        image: cephimage1</span><br><span class="line">        fsType: ext4</span><br><span class="line">        readOnly: true</span><br><span class="line">        user: admin</span><br><span class="line">        secretRef:</span><br><span class="line">          name: ceph-secret</span><br></pre></td></tr></table></figure>

<p>如下参数根据实际情况修改： monitors：这是 Ceph集群的monitor 监视器，Ceph 集群可以配置多个 monitor，本配置3个mon pool：这是Ceph集群中存储数据进行归类区分使用，这里用的pool为rbd-ceph image：这是Ceph 块设备中的磁盘映像文件，这里用的是cephimage1 fsType：文件系统类型，默认使用 ext4 即可 readOnly：是否为只读，这里测试使用只读即可 user：这是Ceph Client访问Ceph存储集群所使用的用户名，这里我们使用admin 即可 keyring：这是Ceph集群认证需要的密钥环，搭建Ceph存储集群时生成的ceph.client.admin.keyring imageformat：这是磁盘映像文件格式，可以使用 2，或者老一些的1，内核版本比较低的使用1 imagefeatures： 这是磁盘映像文件的特征，需要uname -r查看集群系统内核所支持的特性，这里Ceontos7.4内核版本为3.10.0-693.el7.x86_64只支持layering</p>
<p><strong>4、使用ceph认证秘钥</strong> 在集群中使用secret更方便易于扩展且安全</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# cat /etc/ceph/ceph.client.admin.keyring </span><br><span class="line">[client.admin]</span><br><span class="line">    key = AQBHVp9bPirBCRAAUt6Mjw5PUjiy/RDHyHZrUw==</span><br><span class="line"></span><br><span class="line">[root@ceph01 ~]# grep key /etc/ceph/ceph.client.admin.keyring |awk &#x27;&#123;printf &quot;%s&quot;, $NF&#125;&#x27;|base64</span><br><span class="line">QVFCSFZwOWJQaXJCQ1JBQVV0Nk1qdzVQVWppeS9SREh5SFpyVXc9PQ==</span><br></pre></td></tr></table></figure>

<p><strong>5、创建ceph-secret</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# cat secret/ceph-secret.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-secret</span><br><span class="line">type: &quot;kubernetes.io/rbd&quot;</span><br><span class="line">data:</span><br><span class="line">  key: QVFCSFZwOWJQaXJCQ1JBQVV0Nk1qdzVQVWppeS9SREh5SFpyVXc9PQ==</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl create -f secret/ceph-secret.yaml </span><br><span class="line">secret/ceph-secret created</span><br></pre></td></tr></table></figure>

<p><strong>6、创建pod测试rbd</strong> 按照官网的案例直接创建即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# kubectl create -frbd-with-secret.yaml </span><br></pre></td></tr></table></figure>

<p>但是生产环境中不直接使用volumes，他会随着pods的创建儿创建，删除而删除，数据得不到保存，如果需要数据不丢失，需要借助pv和pvc实现</p>
<p><strong>7、创建ceph-pv</strong> 注意rbd是读写一次，只读多次，目前还不支持读写多次，我们日常使用rbd映射磁盘时也是一个image只挂载一个客户端上；cephfs可以支持读写多次</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# cat rbd-pv.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-rbd-pv</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 20Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  rbd:</span><br><span class="line">    monitors:</span><br><span class="line">      - &#x27;10.0.4.10:6789&#x27;</span><br><span class="line">      - &#x27;10.0.4.13:6789&#x27;</span><br><span class="line">      - &#x27;10.0.4.15:6789&#x27;</span><br><span class="line">    pool: rbd-k8s</span><br><span class="line">    image: cephimage2</span><br><span class="line">    user: admin</span><br><span class="line">    secretRef:</span><br><span class="line">      name: ceph-secret</span><br><span class="line">    fsType: ext4</span><br><span class="line">    readOnly: false</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl create -f rbd-pv.yaml </span><br><span class="line">persistentvolume/ceph-rbd-pv created</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl get pv</span><br><span class="line">NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE</span><br><span class="line">ceph-rbd-pv   20Gi       RWO            Recycle          Available  </span><br></pre></td></tr></table></figure>

<p><strong>8、创建ceph-pvc</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# cat rbd-pv-claim.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-rbd-pv-claim</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 10Gi</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl create -f rbd-pv-claim.yaml </span><br><span class="line">persistentvolumeclaim/ceph-rbd-pv-claim created</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl get pvc</span><br><span class="line">NAME                STATUS   VOLUME        CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">ceph-rbd-pv-claim   Bound    ceph-rbd-pv   20Gi       RWO                           6s</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl get pv</span><br><span class="line">NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                       STORAGECLASS   REASON   AGE</span><br><span class="line">ceph-rbd-pv   20Gi       RWO            Recycle          Bound    default/ceph-rbd-pv-claim                           5m28s</span><br></pre></td></tr></table></figure>

<p><strong>9、创建pod通过pv、pvc方式测试rbd</strong> 由于需要格式化挂载rbd，rbd空间比较大10G，需要时间比较久，大概需要几分钟</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# cat rbd-pv-pod.yaml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-rbd-pv-pod1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: ceph-rbd-pv-busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    command: [&quot;sleep&quot;, &quot;60000&quot;]</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: ceph-rbd-vol1</span><br><span class="line">      mountPath: /mnt/ceph-rbd-pvc/busybox</span><br><span class="line">      readOnly: false</span><br><span class="line">  volumes:</span><br><span class="line">  - name: ceph-rbd-vol1</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: ceph-rbd-pv-claim</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl create -f rbd-pv-pod.yaml </span><br><span class="line">pod/ceph-rbd-pv-pod1 created</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl get pods</span><br><span class="line">NAME               READY   STATUS              RESTARTS   AGE</span><br><span class="line">busybox            1/1     Running             432        18d</span><br><span class="line">ceph-rbd-pv-pod1   0/1     ContainerCreating   0          19s</span><br></pre></td></tr></table></figure>

<p>报错如下 MountVolume.WaitForAttach failed for volume “ceph-rbd-pv” : rbd: map failed exit status 6, rbd output: rbd: sysfs write failed RBD image feature set mismatch. Try disabling features unsupported by the kernel with “rbd feature disable”. In some cases useful info is found in syslog - try “dmesg | tail”. rbd: map failed: (6) No such device or address 解决方法 禁用一些特性，这些特性在centos7.4内核上不支持，所以生产环境中k8s及相关ceph最好使用内核版本高的系统做为底层操作系统 rbd feature disable rbd-k8s&#x2F;cephimage2 exclusive-lock object-map fast-diff deep-flatten</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# rbd feature disable rbd-k8s/cephimage2 exclusive-lock object-map fast-diff deep-flatten</span><br></pre></td></tr></table></figure>

<h4 id="三、验证效果"><a href="#三、验证效果" class="headerlink" title="三、验证效果"></a><strong>三、验证效果</strong></h4><p><strong>1、k8s集群端验证</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 rbd]# kubectl get pods -o wide</span><br><span class="line">NAME               READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES</span><br><span class="line">busybox            1/1     Running   432        18d     10.254.35.3   10.2.8.65   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">ceph-rbd-pv-pod1   1/1     Running   0          3m39s   10.254.35.8   10.2.8.65   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">[root@elasticsearch02 ceph]# df -h |grep rbd</span><br><span class="line">/dev/rbd0                  493G  162G  306G  35% /data</span><br><span class="line">/dev/rbd1                   20G   45M   20G   1% /var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/rbd-k8s-image-cephimage2</span><br><span class="line">[root@elasticsearch02 ceph]# cd /var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/rbd-k8s-image-cephimage2</span><br><span class="line">[root@elasticsearch02 rbd-k8s-image-cephimage2]# ls</span><br><span class="line">lost+found</span><br><span class="line"></span><br><span class="line">[root@elasticsearch01 rbd]# kubectl exec -ti ceph-rbd-pv-pod1 sh</span><br><span class="line">/ # df -h</span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">overlay                  49.1G      7.4G     39.1G  16% /</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /dev</span><br><span class="line">tmpfs                     7.8G         0      7.8G   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1                49.1G      7.4G     39.1G  16% /dev/termination-log</span><br><span class="line">/dev/vda1                49.1G      7.4G     39.1G  16% /etc/resolv.conf</span><br><span class="line">/dev/vda1                49.1G      7.4G     39.1G  16% /etc/hostname</span><br><span class="line">/dev/vda1                49.1G      7.4G     39.1G  16% /etc/hosts</span><br><span class="line">shm                      64.0M         0     64.0M   0% /dev/shm</span><br><span class="line">/dev/rbd1                19.6G     44.0M     19.5G   0% /mnt/ceph-rbd-pvc/busybox</span><br><span class="line">tmpfs                     7.8G     12.0K      7.8G   0% /var/run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                     7.8G         0      7.8G   0% /proc/acpi</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/kcore</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/keys</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/timer_list</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/timer_stats</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /proc/sched_debug</span><br><span class="line">tmpfs                     7.8G         0      7.8G   0% /proc/scsi</span><br><span class="line">tmpfs                     7.8G         0      7.8G   0% /sys/firmware</span><br><span class="line">/ # cd /mnt/ceph-rbd-pvc/busybox/</span><br><span class="line">/mnt/ceph-rbd-pvc/busybox # ls</span><br><span class="line">lost+found</span><br><span class="line">/mnt/ceph-rbd-pvc/busybox # touch ceph-rbd-pods</span><br><span class="line">/mnt/ceph-rbd-pvc/busybox # ls</span><br><span class="line">ceph-rbd-pods  lost+found</span><br><span class="line">/mnt/ceph-rbd-pvc/busybox # echo busbox&gt;ceph-rbd-pods </span><br><span class="line">/mnt/ceph-rbd-pvc/busybox # cat ceph-rbd-pods </span><br><span class="line">busbox</span><br><span class="line"></span><br><span class="line">[root@elasticsearch02 ceph]# cd /var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/rbd-k8s-image-cephimage2</span><br><span class="line">[root@elasticsearch02 rbd-k8s-image-cephimage2]# ls</span><br><span class="line">ceph-rbd-pods  lost+found</span><br></pre></td></tr></table></figure>

<p><strong>2、ceph集群端验证</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph01 ~]# ceph df</span><br><span class="line">GLOBAL:</span><br><span class="line">    SIZE        AVAIL       RAW USED     %RAW USED </span><br><span class="line">    65.9TiB     58.3TiB      7.53TiB         11.43 </span><br><span class="line">POOLS:</span><br><span class="line">    NAME                           ID     USED        %USED     MAX AVAIL     OBJECTS </span><br><span class="line">    rbd-es                         1      1.38TiB      7.08       18.1TiB      362911 </span><br><span class="line">    .rgw.root                      2      1.14KiB         0       18.1TiB           4 </span><br><span class="line">    default.rgw.control            3           0B         0       18.1TiB           8 </span><br><span class="line">    default.rgw.meta               4      46.9KiB         0        104GiB         157 </span><br><span class="line">    default.rgw.log                5           0B         0       18.1TiB         345 </span><br><span class="line">    default.rgw.buckets.index      6           0B         0        104GiB        2012 </span><br><span class="line">    default.rgw.buckets.data       7      1.01TiB      5.30       18.1TiB     2090721 </span><br><span class="line">    default.rgw.buckets.non-ec     8           0B         0       18.1TiB           0 </span><br><span class="line">    rbd-k8s                        9       137MiB         0       18.1TiB          67 </span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/18/2019/01/2019-01-18-centos7-5%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%A8%B3%E5%AE%9A%E7%89%88jenkins%E5%B9%B6%E9%85%8D%E7%BD%AEldap%E8%AE%A4%E8%AF%81/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/18/2019/01/2019-01-18-centos7-5%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%A8%B3%E5%AE%9A%E7%89%88jenkins%E5%B9%B6%E9%85%8D%E7%BD%AEldap%E8%AE%A4%E8%AF%81/index/" class="post-title-link" itemprop="url">Centos7.5部署最新稳定版jenkins并配置ldap认证</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-18 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-18T08:00:00+08:00">2019-01-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:31" itemprop="dateModified" datetime="2023-05-26T15:06:31+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+on+Red+Hat+distributions</span><br><span class="line">https://wiki.jenkins.io/display/JENKINS/LDAP+Plugin</span><br></pre></td></tr></table></figure>

<h3 id="一、部署jenkins"><a href="#一、部署jenkins" class="headerlink" title="一、部署jenkins"></a><strong>一、部署jenkins</strong></h3><p><strong>1、设置jenkins家目录环境</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_8_24_centos ~]# yum -y install java</span><br><span class="line">[root@VM_8_24_centos builds]# java -version</span><br><span class="line">java version &quot;1.8.0_171&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_171-b11)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode)</span><br></pre></td></tr></table></figure>

<p><strong>2、安装jenkins</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_8_24_centos ~]# wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo</span><br><span class="line">[root@VM_8_24_centos ~]# rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.key</span><br><span class="line">[root@VM_8_24_centos ~]# yum -y install jenkins</span><br><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package jenkins.noarch 0:2.150.2-1.1 will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  jenkins.noarch 0:2.150.2-1.1                                                                                                       </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure>

<p><strong>3、修改jenkins家目录位置</strong> 默认是&#x2F;var&#x2F;lib&#x2F;jenkins，修改后启动服务，如果之前启动过，这边重启服务会重新安装插件等到新目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_8_24_centos ~]# mkdir /data1/jenkins/</span><br><span class="line">[root@VM_8_24_centos ~]# chown jenkins:jenkins /data1/jenkins/</span><br><span class="line">[root@VM_8_24_centos ~]# source /etc/profile</span><br><span class="line">[root@VM_8_24_centos ~]# echo $JENKINS_HOME</span><br><span class="line">/data1/jenkins</span><br><span class="line">[root@VM_8_24_centos ~]# grep JENKINS_HOME /etc/sysconfig/jenkins </span><br><span class="line">JENKINS_HOME=&quot;/data1/jenkins&quot;</span><br><span class="line"># permissions of $JENKINS_HOME and /var/log/jenkins.</span><br><span class="line"># $JENKINS_HOME location. Do not enable this, &quot;true&quot;, unless</span><br></pre></td></tr></table></figure>

<p><strong>4、启动jenkins服务</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@VM_8_24_centos ~]# systemctl start jenkins</span><br><span class="line">[root@VM_8_24_centos ~]# systemctl status jenkins</span><br><span class="line">● jenkins.service - LSB: Jenkins Automation Server</span><br><span class="line">   Loaded: loaded (/etc/rc.d/init.d/jenkins; bad; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Thu 2019-01-17 10:54:27 CST; 6s ago</span><br><span class="line">     Docs: man:systemd-sysv-generator(8)</span><br><span class="line">  Process: 14935 ExecStart=/etc/rc.d/init.d/jenkins start (code=exited, status=0/SUCCESS)</span><br><span class="line">   Memory: 391.4M</span><br><span class="line">   CGroup: /system.slice/jenkins.service</span><br><span class="line">           └─14960 /usr/bin/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /...</span><br><span class="line">[root@VM_8_24_centos ~]# cat /data1/jenkins/secrets/initialAdminPassword</span><br><span class="line">96a4e031a951464690c093c918410793</span><br><span class="line">[root@VM_8_24_centos ~]# ls /data1/jenkins/</span><br><span class="line">config.xml                     jenkins.install.UpgradeWizard.state  nodeMonitors.xml  secret.key.not-so-secret  users</span><br><span class="line">hudson.model.UpdateCenter.xml  jenkins.telemetry.Correlator.xml     nodes             secrets</span><br><span class="line">identity.key.enc               jobs                                 plugins           updates</span><br><span class="line">jenkins.CLI.xml                logs                                 secret.key        userContent</span><br></pre></td></tr></table></figure>

<h3 id="二、初始化jenkins环境"><a href="#二、初始化jenkins环境" class="headerlink" title="二、初始化jenkins环境"></a><strong>二、初始化jenkins环境</strong></h3><p><strong>1、浏览器打开ip:8080端口输入密码</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412e451a5b2.png"><img src="/images/5c412e451a5b2.png"></a></p>
</blockquote>
<p><strong>2、选择安装插件</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412e52f1168.png"><img src="/images/5c412e52f1168.png"></a> <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412e61e86b0.png"><img src="/images/5c412e61e86b0.png"></a></p>
</blockquote>
<p><strong>3、创建初始管理账号</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412e6ab2ebe.png"><img src="/images/5c412e6ab2ebe.png"></a></p>
</blockquote>
<p><strong>4、设置jenkins url默认<a target="_blank" rel="noopener" href="http://ip:8080/">http://ip:8080</a></strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412e7fb97bf.png"><img src="/images/5c412e7fb97bf.png"></a></p>
</blockquote>
<p><strong>5、开始使用jenkins</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412e8968e1f.png"><img src="/images/5c412e8968e1f.png"></a></p>
</blockquote>
<p><strong>6、jenkins控制台界面，主要配置都在系统管理中</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412ef129292.png"><img src="/images/5c412ef129292.png"></a></p>
</blockquote>
<h3 id="三、配置ldap"><a href="#三、配置ldap" class="headerlink" title="三、配置ldap"></a><strong>三、配置ldap</strong></h3><p><strong>1、系统配置-全局安全配置-Security Realm-选择LDAP-Advanced Service Configtion</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412f0dc4a47.png"><img src="/images/5c412f0dc4a47.png"></a></p>
</blockquote>
<p><strong>2、Security Realm-Authorization-Add user or group设置权限</strong></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/18/5c412f2972ee1.png"><img src="/images/5c412f2972ee1.png"></a></p>
</blockquote>
<p><strong>3、域账号登陆</strong></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/15/2019/01/2019-01-15-%E5%AD%A6%E4%B9%A0%E9%98%B3%E6%98%8E%E5%BF%83%E5%AD%A6%E4%B9%A6%E7%B1%8D%E6%8E%A8%E8%8D%90/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/15/2019/01/2019-01-15-%E5%AD%A6%E4%B9%A0%E9%98%B3%E6%98%8E%E5%BF%83%E5%AD%A6%E4%B9%A6%E7%B1%8D%E6%8E%A8%E8%8D%90/index/" class="post-title-link" itemprop="url">学习阳明心学书籍推荐</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-15 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-15T08:00:00+08:00">2019-01-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:30" itemprop="dateModified" datetime="2023-05-26T15:06:30+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/wisdom/" itemprop="url" rel="index"><span itemprop="name">wisdom</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/wisdom/mind/" itemprop="url" rel="index"><span itemprop="name">mind</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="王阳明简介"><a href="#王阳明简介" class="headerlink" title="王阳明简介"></a><strong>王阳明简介</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">王守仁（1472年10月31日－1529年1月9日），汉族，幼名云，字伯安，别号阳明，浙江绍兴府余姚县（今属宁波余姚）人。因曾筑室于会稽山阳明洞，自号阳明子，学者称之为阳明先生，亦称王阳明。明代著名的思想家、文学家、哲学家和军事家，陆王心学之集大成者，精通儒家、道家、佛家。 </span><br><span class="line">王守仁（心学集大成者）与孔子（儒学创始人）、孟子（儒学集大成者）、朱熹（理学集大成者）并称为孔、孟、朱、王。</span><br><span class="line">王守仁的学说思想王学（阳明学），是明代影响最大的哲学思想。其学术思想传至中国、日本、朝鲜半岛以及东南亚，立德、立言于一身，成就冠绝有明一代。弟子极众，世称姚江学派。其文章博大昌达，行墨间有俊爽之气。有《王文成公全书》。</span><br></pre></td></tr></table></figure>

<h3 id="王阳明评价"><a href="#王阳明评价" class="headerlink" title="王阳明评价"></a><strong>王阳明评价</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">阳明先生创良知之说，为暗室一炬。</span><br><span class="line">    ——明末清初著名文人·张岱</span><br><span class="line">震霆启寐，烈耀破迷，自孔孟以来，未有若此深切著明者也。</span><br><span class="line">    ——明末清初著名学者·黄宗羲</span><br><span class="line">王文成公为明第一流人物，立德、立功、立言，皆居绝顶。</span><br><span class="line">    ——清代著名文人、学者·王士祯</span><br><span class="line">他在近代学术界中，极具伟大，军事上、政治上，多有很大的勋业。</span><br><span class="line">    ——近现代著名学者·梁启超</span><br><span class="line">我邦阳明学之特色，在其有活动的事业家，乃至维新诸豪杰震天动地之伟业，殆无一不由于王学所赐予。</span><br><span class="line">    ——日本天皇的老师、日本近代著名哲学家·高濑武次郎</span><br></pre></td></tr></table></figure>

<h3 id="学习推荐阳明的理由"><a href="#学习推荐阳明的理由" class="headerlink" title="学习推荐阳明的理由"></a><strong>学习推荐阳明的理由</strong></h3><ul>
<li><strong>阳明五溺，千辛万苦中得来值得借鉴</strong></li>
</ul>
<blockquote>
<ul>
<li>阳明的一生很有借鉴意义，他早年天赋异禀，但是也走了弯路耽误了几十年时间：初溺于任侠之习，再溺于骑射之习，三溺于辞章之习，四溺于神仙之习，五溺于佛氏之习。正德丙寅，始归正于圣贤之学。</li>
<li>其中经历千辛万苦可想而知，更给人借鉴的是阳明认知到二氏之学的不足，在他看来儒学的本体是“良知”，追求的是天地万物的绝对虚无，其中不含半点私欲。而道教和佛教虽然也都坚持虚无，但他们追求的是长生不老和脱离生死苦海，说到底追求的还是自己的私欲，所以他们并没有得到真正的虚无。</li>
</ul>
</blockquote>
<ul>
<li><strong>仁者不忧，能在浮躁中给你心安</strong></li>
</ul>
<blockquote>
<ul>
<li>如今日韩都在学习他国人不学习真是太可惜了，国人都认为中国没有哲学，相反阳明的东方哲学可以看着对根的培养，西方的哲学只是对枝枝叶叶的探求，东方的是本，西方的是末！东方哲学重情感，西方哲学重理性，在这个浮躁的社会，我们更需要的是对“培根之学”的认知，给自己以心安！</li>
</ul>
</blockquote>
<ul>
<li><strong>六度分隔，让你直接与大师们沟通</strong></li>
</ul>
<blockquote>
<ul>
<li>看了许多关于王阳明的书，总结了下主要分成三类：传习录、全集、传集。估计大部分人对传集比较了解，像什么知行合一王阳明啊都写成小说了，还有些名家比如梁启超、叶圣陶虽然也很有天赋，但人家毕竟涉猎广泛，没有把精力专注在阳明学上，另外也有些名家没有读到所以想推荐也推荐不了。</li>
<li>读哪些没有深切体认的书读了再多也没用，就好像看热闹一样，正如禅宗讲究的觉后再修才是真修，所以要读就得读经典。所谓经典就好像有的书人家用几月几年写成，有的书却花费了几十年或者一辈子才完成，但是一旦完成就能流传几千年，能给后人提供源源不断的营养，不得不令人萧然起敬！书中又直接或间接的接触到很多大师们，最终汇总成圣学之道，花多少时间沉浸其中也是值得的！</li>
</ul>
</blockquote>
<ul>
<li><strong>知行合一，关键还得致良知</strong></li>
</ul>
<blockquote>
<ul>
<li>说得再多再好也没有用，得马上去做，阳明有弟子问他怎样才能提升，阳明给他讲了很多，还是觉得不够又问具体方法步骤，阳明说“致良知”三字已经道尽，你却不知！确实如果能在日常的生活中，深切体认“致良知”，就算走上正道了，至于以后你能成长到多高就看你用功多少了。不需要再去探求千千万万的法门了，别人的法门可能是你入魔的捷径，你所要做的就是找到一个适合你的方法，认真去做！</li>
</ul>
</blockquote>
<h3 id="推荐书籍"><a href="#推荐书籍" class="headerlink" title="推荐书籍"></a><strong>推荐书籍</strong></h3><ul>
<li><strong>传习录（两本）</strong></li>
</ul>
<p><strong>传习录注疏</strong></p>
<blockquote>
<p>简明的《传习录》注本，学修阳明心学的好途径 [明] 王阳明 著，邓艾民 注 <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/15/5c3d6c814a390.jpg"><img src="/images/5c3d6c814a390.jpg"></a></p>
</blockquote>
<p><strong>王阳明《传习录》详注集评</strong></p>
<blockquote>
<p>全面详尽威望的《传习录》版本，集中日三十余种注评版本之精华。 与冯友兰齐名之中国哲学宗师陈荣捷数十年心血力作 大陆尘封多年修订再版，清华大学国学院院长陈来作序力荐 陈荣捷 著 <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/15/5c3d6b3f91455.jpg"><img src="/images/5c3d6b3f91455.jpg"></a></p>
</blockquote>
<ul>
<li><p><strong>全集一本</strong> <strong>理学丛书：王文成公全书（套装共4册</strong></p>
<blockquote>
<p>中华书局出版。王阳明全部著作结集 [明] 王守仁 著，王晓昕，赵平略 校 <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/15/5c3d6b5319de7.jpg"><img src="/images/5c3d6b5319de7.jpg"></a>
  </p>
</blockquote>
</li>
<li><p><strong>传集三本</strong> <strong>王阳明（新修订）</strong></p>
<blockquote>
<p>[加] 秦家懿著 著 <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/15/5c3d6b645530d.jpg"><img src="/images/5c3d6b645530d.jpg"></a></p>
</blockquote>
</li>
</ul>
<p><strong>王阳明：一切心法（套装全2册）</strong></p>
<blockquote>
<p>[熊逸] 著 <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/15/5c3d6b77a602c.jpg"><img src="/images/5c3d6b77a602c.jpg"></a></p>
</blockquote>
<p><strong>王阳明大传：知行合一的心学智慧（全新修订版）</strong></p>
<blockquote>
<p>冈田武彦 著，杨田，冯莹莹，袁斌，孙逢明 译 畅销四年，新版修订，新增阳明遗迹珍贵图片和阳明先生大事年表，杜维明、樊登、董平等学者名人力荐 国际儒学泰斗、阳明学大师冈田武彦二十五年心血力作 全面丰富的阳明传记，经典严谨的心学读本 <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/15/5c3d6b8e60bfa.jpg"><img src="/images/5c3d6b8e60bfa.jpg"></a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/12/2019/01/2019-01-12-%E4%BD%BF%E7%94%A8prometheus%E9%87%87%E9%9B%86ingress-nginx%E6%95%B0%E6%8D%AEgrafan%E5%B1%95%E7%A4%BA%E6%95%88%E6%9E%9C/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/12/2019/01/2019-01-12-%E4%BD%BF%E7%94%A8prometheus%E9%87%87%E9%9B%86ingress-nginx%E6%95%B0%E6%8D%AEgrafan%E5%B1%95%E7%A4%BA%E6%95%88%E6%9E%9C/index/" class="post-title-link" itemprop="url">使用prometheus采集ingress-nginx数据grafan展示效果</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-12 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-12T08:00:00+08:00">2019-01-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:30" itemprop="dateModified" datetime="2023-05-26T15:06:30+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://akomljen.com/get-kubernetes-cluster-metrics-with-prometheus-in-5-minutes/</span><br><span class="line">https://github.com/kubernetes/ingress-nginx/tree/f56e839134fd4a1d020c3e95d4fe89496225041c/deploy/grafana/dashboards</span><br><span class="line">https://github.com/kubernetes/ingress-nginx/tree/f56e839134fd4a1d020c3e95d4fe89496225041c/deploy/monitoring</span><br></pre></td></tr></table></figure>

<h3 id="文档目录"><a href="#文档目录" class="headerlink" title="文档目录"></a><strong>文档目录</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes/kubernetes1.13.1%2Betcd3.3.10%2Bflanneld0.10%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.md">kubernetes1.13.1+etcd3.3.10+flanneld0.10集群部署</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes-dashboard-amd64/Kubernetes1.13.1%E9%83%A8%E7%BD%B2Kuberneted-dashboard%20v1.10.1.md">kubernetes1.13.1部署kuberneted-dashboard v1.10.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/coredns/kubernetes1.13.1%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2coredns.md">kubernetes1.13.1部署coredns</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/ingress-nginx/kubernetes1.13.1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard.md">kubernetes1.13.1部署ingress-nginx并配置https转发dashboard</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/kubernetes1.13.1%E9%83%A8%E7%BD%B2metrics-server0.3.1.md">kubernetes1.13.1部署metrics-server0.3.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/volumes/rbd/k8s%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph%20rbd%E5%9D%97%E5%AD%98%E5%82%A8.md">kubernetes1.13.1集群使用ceph rbd存储块</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/jenkins/k8s1.13.1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph%20rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins.md">kubernetes1.13.1集群结合ceph rbd部署最新版本jenkins</a></li>
</ul>
<h3 id="部署monitoring"><a href="#部署monitoring" class="headerlink" title="部署monitoring"></a><strong>部署monitoring</strong></h3><p>在ingress-nginx官网deploy&#x2F;monitoring目录下载相关yaml文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 monitoring]# pwd</span><br><span class="line">/k8s/yaml/ingress-nginx/monitoring</span><br><span class="line">[root@elasticsearch01 monitoring]# ls</span><br><span class="line">configuration.yaml  grafana.yaml  prometheus.yaml</span><br></pre></td></tr></table></figure>

<p>使用kubectl部署prometheus和grafana容器pod</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 monitoring]# kubectl create -f ./</span><br><span class="line">configmap/prometheus-configuration created</span><br><span class="line">deployment.extensions/grafana created</span><br><span class="line">service/grafana created</span><br><span class="line">role.rbac.authorization.k8s.io/prometheus-server created</span><br><span class="line">serviceaccount/prometheus-server created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/prometheus-server created</span><br><span class="line">deployment.apps/prometheus-server created</span><br><span class="line">service/prometheus-server created</span><br></pre></td></tr></table></figure>

<p>查看对外暴露端口，服务以NoderPort方式对外提供服务 prometheus访问地址为：<a target="_blank" rel="noopener" href="http://10.2.8.65:37941/">http://10.2.8.65:37941</a> grafana访问地址为：<a target="_blank" rel="noopener" href="http://10.2.8.34:32358/">http://10.2.8.34:32358</a> 以上服务也可以部署ingress服务，通过域名访问</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 monitoring]# kubectl get pods,svc -n ingress-nginx -o wide|egrep &quot;grafana|prome&quot;</span><br><span class="line">pod/grafana-69549786b6-69sqm                    1/1     Running   0          14m     10.254.73.6   10.2.8.34   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod/prometheus-server-8658d8cdbb-8kf2g          1/1     Running   0          14m     10.254.35.7   10.2.8.65   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">service/grafana             NodePort       10.254.108.105   &lt;none&gt;        3000:32358/TCP               14m     app.kubernetes.io/name=grafana,app.kubernetes.io/part-of=ingress-nginx</span><br><span class="line">service/prometheus-server   NodePort       10.254.155.29    &lt;none&gt;        9090:37941/TCP               14m     app.kubernetes.io/name=prometheus,app.kubernetes.io/part-of=ingress-nginx</span><br></pre></td></tr></table></figure>

<h3 id="配置grafana"><a href="#配置grafana" class="headerlink" title="配置grafana"></a><strong>配置grafana</strong></h3><p>在ingress-nginx官网deploy&#x2F;grafana&#x2F;dashboards目录下载相关nginx.json文件</p>
<p>配置prometheus数据源</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/12/5c39e516d5f36.png"><img src="/images/5c39e516d5f36.png"></a> 导入dashboard <a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/12/5c39e526c4276.png"><img src="/images/5c39e526c4276.png"></a></p>
</blockquote>
<p>最终展示效果如下</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/12/5c39e53bbbc39.png"><img src="/images/5c39e53bbbc39.png"></a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/09/2019/01/2019-01-09-kubernetes1-13-1%E9%83%A8%E7%BD%B2metrics-server0-3-1/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/09/2019/01/2019-01-09-kubernetes1-13-1%E9%83%A8%E7%BD%B2metrics-server0-3-1/index/" class="post-title-link" itemprop="url">kubernetes1.13.1部署metrics-server0.3.1</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-09 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-09T08:00:00+08:00">2019-01-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:30" itemprop="dateModified" datetime="2023-05-26T15:06:30+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://kubernetes.io/docs/tasks/debug-application-cluster/core-metrics-pipeline/#metrics-server</span><br><span class="line">https://github.com/kubernetes-incubator/metrics-server/tree/master/deploy/1.8%2B</span><br><span class="line">https://www.cnblogs.com/cuishuai/p/9857120.html</span><br><span class="line">https://juejin.im/post/5b6592ace51d4515b01c11ed</span><br></pre></td></tr></table></figure>

<h3 id="文档目录"><a href="#文档目录" class="headerlink" title="文档目录"></a><strong>文档目录</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes/kubernetes1.13.1%2Betcd3.3.10%2Bflanneld0.10%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.md">kubernetes1.13.1+etcd3.3.10+flanneld0.10集群部署</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes-dashboard-amd64/Kubernetes1.13.1%E9%83%A8%E7%BD%B2Kuberneted-dashboard%20v1.10.1.md">kubernetes1.13.1部署kuberneted-dashboard v1.10.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/coredns/kubernetes1.13.1%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2coredns.md">kubernetes1.13.1部署coredns</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/ingress-nginx/kubernetes1.13.1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard.md">kubernetes1.13.1部署ingress-nginx并配置https转发dashboard</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/kubernetes1.13.1%E9%83%A8%E7%BD%B2metrics-server0.3.1.md">kubernetes1.13.1部署metrics-server0.3.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/volumes/rbd/k8s%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph%20rbd%E5%9D%97%E5%AD%98%E5%82%A8.md">kubernetes1.13.1集群使用ceph rbd存储块</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/jenkins/k8s1.13.1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph%20rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins.md">kubernetes1.13.1集群结合ceph rbd部署最新版本jenkins</a></li>
</ul>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h3><p><strong>Metrics Server</strong> heapster 已经被废弃了，后续版本中会使用 metrics-server代替 Metrics Server is a cluster-wide aggregator of resource usage data. Starting from Kubernetes 1.8 it’s deployed by default in clusters created by kube-up.sh script as a Deployment object. If you use a different Kubernetes setup mechanism you can deploy it using the provided deployment yamls. It’s supported in Kubernetes 1.7+ (see details below). Metric server collects metrics from the Summary API, exposed by Kubelet on each node. Metrics Server registered in the main API server through Kubernetes aggregator, which was introduced in Kubernetes 1.7. Learn more about the metrics server in the design doc.</p>
<h3 id="官网部署方法"><a href="#官网部署方法" class="headerlink" title="官网部署方法"></a><strong>官网部署方法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/kubernetes-incubator/metrics-server</span><br><span class="line">cd metrics-server</span><br><span class="line">kubectl create -f deploy/1.8+/</span><br><span class="line">kubectl -n kube-system get pods -l k8s-app=metrics-server</span><br></pre></td></tr></table></figure>

<h3 id="实际部署步骤"><a href="#实际部署步骤" class="headerlink" title="实际部署步骤"></a><strong>实际部署步骤</strong></h3><p><strong>下载部署文件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 metrics-server]# ls </span><br><span class="line">aggregated-metrics-reader.yaml  auth-reader.yaml         metrics-server-deployment.yaml  resource-reader.yaml</span><br><span class="line">auth-delegator.yaml             metrics-apiservice.yaml  metrics-server-service.yaml</span><br></pre></td></tr></table></figure>

<p><strong>构建images</strong> 可以在github上编写Dockerfile，再通过阿里云构建，构建后地址为registry.cn-beijing.aliyuncs.com&#x2F;minminmsn&#x2F;metrics-server:v0.3.1 Dockerfile文件地址：<a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/Dockerfile">https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/Dockerfile</a></p>
<p><strong>修改deployment镜像地址</strong> k8s.gcr.io&#x2F;metrics-server:v0.3.1改成registry.cn-beijing.aliyuncs.com&#x2F;minminmsn&#x2F;metrics-server:v0.3.1 [root@elasticsearch01 metrics-server]# vim metrics-server-deployment.yaml</p>
<p><strong>部署metrices-server</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 metrics-server]# kubectl create -f /k8s/yaml/metrics-server/</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created</span><br><span class="line">apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created</span><br><span class="line">serviceaccount/metrics-server created</span><br><span class="line">deployment.extensions/metrics-server created</span><br><span class="line">service/metrics-server created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:metrics-server created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created</span><br></pre></td></tr></table></figure>

<p><strong>报错</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I0109 05:55:43.708300       1 serving.go:273] Generated self-signed cert (apiserver.local.config/certificates/apiserver.crt, apiserver.local.config/certificates/apiserver.key)</span><br><span class="line">Error: cluster doesn&#x27;t provide requestheader-client-ca-file</span><br></pre></td></tr></table></figure>

<p><strong>排查</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/kubernetes-incubator/metrics-server/issues/22</span><br><span class="line">https://github.com/kubernetes-incubator/bootkube/issues/994</span><br><span class="line">https://github.com/pires/kubernetes-vagrant-coreos-cluster/pull/319</span><br><span class="line">https://blog.csdn.net/liukuan73/article/details/81352637</span><br><span class="line">https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/</span><br></pre></td></tr></table></figure>

<p><strong>解决方法</strong> 开启聚合层，Enable apiserver flags，修改kube-apiserver配置，重启服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 cfg]# tail /k8s/kubernetes/cfg/kube-apiserver</span><br><span class="line">--etcd-cafile=/k8s/etcd/ssl/ca.pem \</span><br><span class="line">--etcd-certfile=/k8s/etcd/ssl/server.pem \</span><br><span class="line">--etcd-keyfile=/k8s/etcd/ssl/server-key.pem \</span><br><span class="line">--requestheader-client-ca-file=/k8s/kubernetes/ssl/ca.pem \</span><br><span class="line">--requestheader-allowed-names=aggregator \</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra- \</span><br><span class="line">--requestheader-group-headers=X-Remote-Group \</span><br><span class="line">--requestheader-username-headers=X-Remote-User \</span><br><span class="line">--proxy-client-cert-file=/k8s/kubernetes/ssl/kube-proxy.pem \</span><br><span class="line">--proxy-client-key-file=/k8s/kubernetes/ssl/kube-proxy-key.pem&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 cfg]# systemctl restart kube-apiserver.service </span><br><span class="line">[root@elasticsearch01 cfg]# systemctl status kube-apiserver.service </span><br><span class="line">● kube-apiserver.service - Kubernetes API Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kube-apiserver.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Wed 2019-01-09 14:56:59 CST; 8s ago</span><br><span class="line">     Docs: https://github.com/kubernetes/kubernetes</span><br><span class="line"> Main PID: 7465 (kube-apiserver)</span><br><span class="line">   CGroup: /system.slice/kube-apiserver.service</span><br><span class="line">           └─7465 /k8s/kubernetes/bin/kube-apiserver --logtostderr=true --v=4 --etcd-servers=https://10.2.8.44:2379,https://10.2.8...</span><br></pre></td></tr></table></figure>

<h3 id="创建metrics-ingress便于外部访问"><a href="#创建metrics-ingress便于外部访问" class="headerlink" title="创建metrics-ingress便于外部访问"></a><strong>创建metrics-ingress便于外部访问</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ~]# cat /k8s/yaml/metrics-server/metrics-server-ingress.yaml </span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-ingress</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/ingress.class: nginx</span><br><span class="line">    nginx.ingress.kubernetes.io/secure-backends: &quot;true&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  tls:</span><br><span class="line">  - hosts:</span><br><span class="line">    - metrics.minminmsn.com</span><br><span class="line">    secretName: ingress-secret</span><br><span class="line">  rules:</span><br><span class="line">    - host: metrics.minminmsn.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">        - path: /</span><br><span class="line">          backend:</span><br><span class="line">            serviceName: metrics-server</span><br><span class="line">            servicePort: 443</span><br><span class="line">[root@elasticsearch01 metrics-server]# kubectl create -f metrics-server-ingress.yaml </span><br><span class="line">ingress.extensions/metrics-ingress created</span><br></pre></td></tr></table></figure>

<h3 id="验证效果"><a href="#验证效果" class="headerlink" title="验证效果"></a><strong>验证效果</strong></h3><p><a target="_blank" rel="noopener" href="https://metrics.minminmsn.com:47215/metrics">https://metrics.minminmsn.com:47215/metrics</a></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/09/5c35d849d34cc.png"><img src="/images/5c35d849d34cc.png"></a></p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/06/2019/01/2019-01-06-kubernetes1-13-1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/06/2019/01/2019-01-06-kubernetes1-13-1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard/index/" class="post-title-link" itemprop="url">kubernetes1.13.1部署ingress-nginx并配置https转发dashboard</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-06 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-06T08:00:00+08:00">2019-01-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:30" itemprop="dateModified" datetime="2023-05-26T15:06:30+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/kubernetes/ingress-nginx</span><br><span class="line">https://www.jianshu.com/p/e30b06906b77</span><br><span class="line">https://github.com/kubernetes/ingress-nginx/issues/2474</span><br><span class="line">https://www.cnblogs.com/zhangeamon/p/7007076.html</span><br><span class="line">https://github.com/kubernetes/kubernetes/issues/45324</span><br><span class="line">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/</span><br><span class="line">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#securitycontextdeny</span><br><span class="line">https://jimmysong.io/kubernetes-handbook/concepts/admission-controller.html</span><br><span class="line">https://github.com/kubernetes/ingress-nginx/issues/3608</span><br><span class="line">https://blog.csdn.net/ygqygq2/article/details/82791101</span><br></pre></td></tr></table></figure>

<h3 id="文档目录"><a href="#文档目录" class="headerlink" title="文档目录"></a><strong>文档目录</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes/kubernetes1.13.1%2Betcd3.3.10%2Bflanneld0.10%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.md">kubernetes1.13.1+etcd3.3.10+flanneld0.10集群部署</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes-dashboard-amd64/Kubernetes1.13.1%E9%83%A8%E7%BD%B2Kuberneted-dashboard%20v1.10.1.md">kubernetes1.13.1部署kuberneted-dashboard v1.10.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/coredns/kubernetes1.13.1%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2coredns.md">kubernetes1.13.1部署coredns</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/ingress-nginx/kubernetes1.13.1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard.md">kubernetes1.13.1部署ingress-nginx并配置https转发dashboard</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/kubernetes1.13.1%E9%83%A8%E7%BD%B2metrics-server0.3.1.md">kubernetes1.13.1部署metrics-server0.3.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/volumes/rbd/k8s%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph%20rbd%E5%9D%97%E5%AD%98%E5%82%A8.md">kubernetes1.13.1集群使用ceph rbd存储块</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/jenkins/k8s1.13.1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph%20rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins.md">kubernetes1.13.1集群结合ceph rbd部署最新版本jenkins</a></li>
</ul>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h3><p><strong>Ingress</strong> An API object that manages external access to the services in a cluster, typically HTTP. Ingress can provide load balancing, SSL termination and name-based virtual hosting.</p>
<p><strong>Terminology</strong> - Node: A single virtual or physical machine in a Kubernetes cluster. - Cluster: A group of nodes firewalled from the internet, that are the primary compute resources managed by Kubernetes. - Edge router: A router that enforces the firewall policy for your cluster. This could be a gateway managed by a cloud provider or a physical piece of hardware. - Cluster network: A set of links, logical or physical, that facilitate communication within a cluster according to the Kubernetes networking model. - Service: A Kubernetes Service that identifies a set of pods using label selectors. Unless mentioned otherwise, Services are assumed to have virtual IPs only routable within the cluster network.</p>
<p><strong>What is Ingress?</strong> Ingress, added in Kubernetes v1.1, exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the ingress resource.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> internet</span><br><span class="line">     |</span><br><span class="line">[ Ingress ]</span><br><span class="line">--|-----|--</span><br><span class="line">[ Services ]</span><br></pre></td></tr></table></figure>

<p>An ingress can be configured to give services externally-reachable URLs, load balance traffic, terminate SSL, and offer name based virtual hosting. An ingress controller is responsible for fulfilling the ingress, usually with a loadbalancer, though it may also configure your edge router or additional frontends to help handle the traffic. An ingress does not expose arbitrary ports or protocols. Exposing services other than HTTP and HTTPS to the internet typically uses a service of type Service.Type&#x3D;NodePort or Service.Type&#x3D;LoadBalancer.</p>
<p><strong>Prerequisites</strong> FEATURE STATE: Kubernetes v1.1 beta Before you start using an ingress, there are a few things you should understand. The ingress is a beta resource. You will need an ingress controller to satisfy an ingress, simply creating the resource will have no effect. GCE&#x2F;Google Kubernetes Engine deploys an ingress controller on the master. Review the beta limitations of this controller if you are using GCE&#x2F;GKE. In environments other than GCE&#x2F;Google Kubernetes Engine, you may need to deploy an ingress controller. There are a number of ingress controller you may choose from.</p>
<p><strong>Ingress controllers</strong> In order for the ingress resource to work, the cluster must have an ingress controller running. This is unlike other types of controllers, which run as part of the kube-controller-manager binary, and are typically started automatically with a cluster. Choose the ingress controller implementation that best fits your cluster. Kubernetes as a project currently supports and maintains GCE and nginx controllers. Additional controllers include: Contour is an Envoy based ingress controller provided and supported by Heptio. F5 Networks provides support and maintenance for the F5 BIG-IP Controller for Kubernetes. HAProxy based ingress controller jcmoraisjr&#x2F;haproxy-ingress which is mentioned on the blog post HAProxy Ingress Controller for Kubernetes. HAProxy Technologies offers support and maintenance for HAProxy Enterprise and the ingress controller jcmoraisjr&#x2F;haproxy-ingress. Istio based ingress controller Control Ingress Traffic. Kong offers community or commercial support and maintenance for the Kong Ingress Controllerfor Kubernetes. NGINX, Inc. offers support and maintenance for the NGINX Ingress Controller for Kubernetes. Traefik is a fully featured ingress controller (Let’s Encrypt, secrets, http2, websocket), and it also comes with commercial support by Containous. You may deploy any number of ingress controllers within a cluster. When you create an ingress, you should annotate each ingress with the appropriate ingress-class to indicate which ingress controller should be used if more than one exists within your cluster. If you do not define a class, your cloud provider may use a default ingress provider.</p>
<h3 id="官网部署方法"><a href="#官网部署方法" class="headerlink" title="官网部署方法"></a><strong>官网部署方法</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/kubernetes/ingress-nginx/blob/master/docs/deploy/index.md</span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml</span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/provider/cloud-generic.yaml</span><br></pre></td></tr></table></figure>

<h3 id="部署ingress-controller"><a href="#部署ingress-controller" class="headerlink" title="部署ingress-controller"></a><strong>部署ingress-controller</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ingree-nginx]# kubectl create -f mandatory.yaml </span><br><span class="line">namespace/ingress-nginx created</span><br><span class="line">configmap/nginx-configuration created</span><br><span class="line">configmap/tcp-services created</span><br><span class="line">configmap/udp-services created</span><br><span class="line">serviceaccount/nginx-ingress-serviceaccount created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/nginx-ingress-clusterrole created</span><br><span class="line">role.rbac.authorization.k8s.io/nginx-ingress-role created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/nginx-ingress-role-nisa-binding created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/nginx-ingress-clusterrole-nisa-binding created</span><br><span class="line">deployment.extensions/nginx-ingress-controller created</span><br></pre></td></tr></table></figure>

<p><strong>报错</strong> Error creating: pods “nginx-ingress-controller-565dfd6dff-g977n” is forbidden: SecurityContext.RunAsUser is forbidden</p>
<p><strong>排错</strong> 需要对准入控制器进行修改，然后重启apiserver –enable-admission-plugins&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \ SecurityContextDeny 不enable就行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ingree-nginx]# vim /k8s/kubernetes/cfg/kube-apiserver </span><br><span class="line">[root@elasticsearch01 ingree-nginx]# systemctl restart kube-apiserver.service </span><br><span class="line">[root@elasticsearch01 ingree-nginx]# systemctl status kube-apiserver.service </span><br><span class="line">● kube-apiserver.service - Kubernetes API Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kube-apiserver.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Mon 2019-01-07 11:30:07 CST; 7s ago</span><br><span class="line">     Docs: https://github.com/kubernetes/kubernetes</span><br><span class="line"> Main PID: 12796 (kube-apiserver)</span><br><span class="line">   CGroup: /system.slice/kube-apiserver.service</span><br><span class="line">           └─12796 /k8s/kubernetes/bin/kube-apiserver --logtostderr=true --v=4 --etcd-servers=https://10.2.8.44:2379,https://10.2....</span><br></pre></td></tr></table></figure>

<p><strong>检查状态</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ingree-nginx]# kubectl get pods -n ingress-nginx</span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-ingress-controller-565dfd6dff-vj52t   1/1     Running   0          2m36s</span><br></pre></td></tr></table></figure>

<h3 id="部署svc"><a href="#部署svc" class="headerlink" title="部署svc"></a><strong>部署svc</strong></h3><p>[root@elasticsearch01 ingree-nginx]# kubectl create -f cloud-generic.yaml service&#x2F;ingress-nginx created [root@elasticsearch01 ingree-nginx]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx LoadBalancer 10.254.156.80 80:40133&#x2F;TCP,443:36517&#x2F;TCP 12s</p>
<h3 id="测试功能"><a href="#测试功能" class="headerlink" title="测试功能"></a><strong>测试功能</strong></h3><p>之前dashboard是通过nodeport暴露，现在使用ingress方式，注意ingress后端是https，需要添加如下配置 <strong>宣告annotations</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/ingress.class: nginx</span><br><span class="line">    nginx.ingress.kubernetes.io/secure-backends: &quot;true&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;</span><br></pre></td></tr></table></figure>

<p><strong>生成ingress-secret证书</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ingress-nginx]# kubectl -n kube-system  create secret tls ingress-secret --key /certs/dashboard.key --cert /certs/dashboard.crt </span><br><span class="line">secret/ingress-secret created</span><br></pre></td></tr></table></figure>

<p><strong>创建ingress服务</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ~]# cat /k8s/yaml/ingress-nginx/k8s.yaml </span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: dashboard-ingress</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/ingress.class: nginx</span><br><span class="line">    nginx.ingress.kubernetes.io/secure-backends: &quot;true&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  tls:</span><br><span class="line">  - hosts:</span><br><span class="line">    - dashboard.minminmsn.com</span><br><span class="line">    secretName: ingress-secret</span><br><span class="line">  rules:</span><br><span class="line">    - host: dashboard.minminmsn.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">        - path: /</span><br><span class="line">          backend:</span><br><span class="line">            serviceName: kubernetes-dashboard</span><br><span class="line">            servicePort: 443</span><br><span class="line">[root@elasticsearch01 ingree-nginx]# kubectl create -f k8s.yaml </span><br><span class="line">ingress.extensions/dashboard-ingress created</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 ingree-nginx]# kubectl get ingress -n kube-system</span><br><span class="line">NAME                HOSTS                      ADDRESS   PORTS   AGE</span><br><span class="line">dashboard-ingress   dashboard.minminmsn.com             80      2m51s</span><br><span class="line">[root@elasticsearch01 ingree-nginx]# kubectl describe ingress dashboard-ingress -n kube-system</span><br><span class="line">Name:             dashboard-ingress</span><br><span class="line">Namespace:        kube-system</span><br><span class="line">Address:          </span><br><span class="line">Default backend:  default-http-backend:80 (&lt;none&gt;)</span><br><span class="line">Rules:</span><br><span class="line">  Host                      Path  Backends</span><br><span class="line">  ---- ---- --------</span><br><span class="line">  dashboard.minminmsn.com  </span><br><span class="line">                               kubernetes-dashboard:443 (10.254.73.2:8443)</span><br><span class="line">Annotations:</span><br><span class="line">  ingress.kubernetes.io/ssl-passthrough:  true</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason  Age   From                      Message</span><br><span class="line">  ---- ------ ---- ---- -------</span><br><span class="line">  Normal  CREATE  3m3s  nginx-ingress-controller  Ingress ingress-nginx/dashboard-ingress</span><br><span class="line">  Normal  CREATE  3m3s  nginx-ingress-controller  Ingress ingress-nginx/dashboard-ingress</span><br></pre></td></tr></table></figure>

<p><strong>网页浏览</strong> 集群内部访问直接<a target="_blank" rel="noopener" href="https://dashboard.minminmsn.com/">https://dashboard.minminmsn.com</a> 即可；集群外部访问需要获取对外端口47215,另外需要设置dns解析,访问时同样需要输入token [root@elasticsearch01 ~]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx LoadBalancer 10.254.125.151 80:33003&#x2F;TCP,443:47215&#x2F;TCP 16m</p>
<p>访问效果如下</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://i.loli.net/2019/01/08/5c340781762c2.png"><img src="/images/5c340781762c2.png"></a></p>
</blockquote>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a><strong>补充</strong></h3><p><strong>准入控制器</strong> To see which admission plugins are enabled: kube-apiserver -h | grep enable-admission-plugins In 1.13, they are: NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeClaimResize,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,Priority</p>
<p>LimitRanger：此准入控制器将确保所有资源请求不会超过 namespace 的 LimitRange。 SecurityContextDeny：此准入控制器将拒绝任何试图设置某些升级的SecurityContext字段的pod 。 ServiceAccount：此准入控制器实现serviceAccounts的自动化。 ResourceQuota：此准入控制器将观察传入请求并确保它不违反命名空间的ResourceQuota对象中列举的任何约束。 NodeRestriction：该准入控制器限制了 kubelet 可以修改的Node和Pod对象。 NamespaceExists：此许可控制器检查除 Namespace 其自身之外的命名空间资源上的所有请求。如果请求引用的命名空间不存在，则拒绝该请求。 NamespaceLifecycle：此准入控制器强制执行正在终止的命令空间中不能创建新对象，并确保Namespace拒绝不存在的请求。此准入控制器还防止缺失三个系统保留的命名空间default、kube-system、kube-public。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://minminmsn.github.io/2019/01/03/2019/01/2019-01-03-kubenetes1-13-1-%E9%83%A8%E7%BD%B2coredns/index/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jerry Min">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MinMinMsn">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/01/03/2019/01/2019-01-03-kubenetes1-13-1-%E9%83%A8%E7%BD%B2coredns/index/" class="post-title-link" itemprop="url">kubenetes1.13.1 部署coredns</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-03 08:00:00" itemprop="dateCreated datePublished" datetime="2019-01-03T08:00:00+08:00">2019-01-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-05-26 15:06:30" itemprop="dateModified" datetime="2023-05-26T15:06:30+08:00">2023-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/middleware/" itemprop="url" rel="index"><span itemprop="name">middleware</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a><strong>参考文档</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">https://www.cnblogs.com/aguncn/p/7217884.html</span><br><span class="line">https://github.com/coredns/deployment/issues/111</span><br><span class="line">https://blog.csdn.net/ccy19910925/article/details/80762025</span><br><span class="line">https://github.com/coredns/deployment/tree/master/kubernetes</span><br><span class="line">https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#coredns</span><br></pre></td></tr></table></figure>

<h3 id="文档目录"><a href="#文档目录" class="headerlink" title="文档目录"></a><strong>文档目录</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes/kubernetes1.13.1%2Betcd3.3.10%2Bflanneld0.10%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.md">kubernetes1.13.1+etcd3.3.10+flanneld0.10集群部署</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/kubernetes-dashboard-amd64/Kubernetes1.13.1%E9%83%A8%E7%BD%B2Kuberneted-dashboard%20v1.10.1.md">kubernetes1.13.1部署kuberneted-dashboard v1.10.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/coredns/kubernetes1.13.1%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2coredns.md">kubernetes1.13.1部署coredns</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/ingress-nginx/kubernetes1.13.1%E9%83%A8%E7%BD%B2ingress-nginx%E5%B9%B6%E9%85%8D%E7%BD%AEhttps%E8%BD%AC%E5%8F%91dashboard.md">kubernetes1.13.1部署ingress-nginx并配置https转发dashboard</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/metrics-server/kubernetes1.13.1%E9%83%A8%E7%BD%B2metrics-server0.3.1.md">kubernetes1.13.1部署metrics-server0.3.1</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/volumes/rbd/k8s%E9%9B%86%E7%BE%A4%E4%BD%BF%E7%94%A8ceph%20rbd%E5%9D%97%E5%AD%98%E5%82%A8.md">kubernetes1.13.1集群使用ceph rbd存储块</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/minminmsn/k8s1.13/blob/master/jenkins/k8s1.13.1%E9%9B%86%E7%BE%A4%E7%BB%93%E5%90%88ceph%20rbd%E9%83%A8%E7%BD%B2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%ACjenkins.md">kubernetes1.13.1集群结合ceph rbd部署最新版本jenkins</a></li>
</ul>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h3><p><strong>About CoreDNS</strong> CoreDNS is a flexible, extensible DNS server that can serve as the Kubernetes cluster DNS. Like Kubernetes, the CoreDNS project is hosted by the CNCF. You can use CoreDNS instead of kube-dns in your cluster by replacing kube-dns in an existing deployment, or by using tools like kubeadm that will deploy and upgrade the cluster for you.</p>
<h3 id="一、修改部署文件环境变量"><a href="#一、修改部署文件环境变量" class="headerlink" title="一、修改部署文件环境变量"></a><strong>一、修改部署文件环境变量</strong></h3><p>在官网下载<a target="_blank" rel="noopener" href="https://github.com/coredns/deployment/tree/master/kubernetes">https://github.com/coredns/deployment/tree/master/kubernetes</a> 配置文件主要是deploy.sh和coredns.yam.sed，由于不是从kube-dns转到coredns，所以要注释掉kubectl相关操作，修改REVERSE_CIDRS、DNS_DOMAIN、CLUSTER_DNS_IP等变量为实际值，具体命令.&#x2F;deploy.sh -s -r 10.254.0.0&#x2F;16 -i 10.254.0.10 -d clouster.local &gt; coredns.yaml11</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 coredns]# ./deploy.sh -h</span><br><span class="line">usage: ./deploy.sh [ -r REVERSE-CIDR ] [ -i DNS-IP ] [ -d CLUSTER-DOMAIN ] [ -t YAML-TEMPLATE ]</span><br><span class="line">    -r : Define a reverse zone for the given CIDR. You may specifcy this option more</span><br><span class="line">         than once to add multiple reverse zones. If no reverse CIDRs are defined,</span><br><span class="line">         then the default is to handle all reverse zones (i.e. in-addr.arpa and ip6.arpa)</span><br><span class="line">    -i : Specify the cluster DNS IP address. If not specificed, the IP address of</span><br><span class="line">         the existing &quot;kube-dns&quot; service is used, if present.</span><br><span class="line">    -s : Skips the translation of kube-dns configmap to the corresponding CoreDNS Corefile configuration.</span><br><span class="line">[root@elasticsearch01 coredns]#  ./deploy.sh -s -r 10.254.0.0/16 -i 10.254.0.10 -d cluster.local &gt; coredns.yaml</span><br><span class="line">[root@elasticsearch01 coredns]# ls</span><br><span class="line">coredns.yaml    coredns.yaml.sed  deploy.sh</span><br></pre></td></tr></table></figure>

<p>修改前后对比</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 coredns]# diff coredns.yaml coredns.yaml.sed </span><br><span class="line">58c58</span><br><span class="line">&lt;         kubernetes cluster.local  10.254.0.0/16 &#123;</span><br><span class="line">---</span><br><span class="line">&gt;         kubernetes CLUSTER_DOMAIN REVERSE_CIDRS &#123;</span><br><span class="line">62c62</span><br><span class="line">&lt;         &#125;</span><br><span class="line">---</span><br><span class="line">&gt;         &#125;FEDERATIONS</span><br><span class="line">64c64</span><br><span class="line">&lt;         proxy . /etc/resolv.conf</span><br><span class="line">---</span><br><span class="line">&gt;         proxy . UPSTREAMNAMESERVER</span><br><span class="line">69c69</span><br><span class="line">&lt;     &#125;</span><br><span class="line">---</span><br><span class="line">&gt;     &#125;STUBDOMAINS</span><br><span class="line">165c165</span><br><span class="line">&lt;   clusterIP: 10.254.0.10</span><br><span class="line">---</span><br><span class="line">&gt;   clusterIP: CLUSTER_DNS_IP</span><br></pre></td></tr></table></figure>

<h3 id="二、部署coredns"><a href="#二、部署coredns" class="headerlink" title="二、部署coredns"></a><strong>二、部署coredns</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 coredns]# kubectl create -f coredns.yaml</span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.extensions/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>

<h3 id="三、修改kubelet-dns服务参数并重启kubelet服务"><a href="#三、修改kubelet-dns服务参数并重启kubelet服务" class="headerlink" title="三、修改kubelet dns服务参数并重启kubelet服务"></a><strong>三、修改kubelet dns服务参数并重启kubelet服务</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch02 ~]# tail /k8s/kubernetes/cfg/kubelet</span><br><span class="line">--v=4 \</span><br><span class="line">--hostname-override=10.2.8.65 \</span><br><span class="line">--kubeconfig=/k8s/kubernetes/cfg/kubelet.kubeconfig \</span><br><span class="line">--bootstrap-kubeconfig=/k8s/kubernetes/cfg/bootstrap.kubeconfig \</span><br><span class="line">--config=/k8s/kubernetes/cfg/kubelet.config \</span><br><span class="line">--cert-dir=/k8s/kubernetes/ssl \</span><br><span class="line">--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0 \</span><br><span class="line">--cluster-dns=10.254.0.10 \</span><br><span class="line">--cluster-domain=cluster.local. \</span><br><span class="line">--resolv-conf=/etc/resolv.conf &quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch02 ~]# systemctl restart kubelet.service </span><br><span class="line">[root@elasticsearch02 ~]# systemctl status kubelet.service </span><br><span class="line">● kubelet.service - Kubernetes Kubelet</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/kubelet.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Thu 2019-01-03 16:00:20 CST; 6s ago</span><br><span class="line"> Main PID: 31924 (kubelet)</span><br><span class="line">   Memory: 80.2M</span><br><span class="line">   CGroup: /system.slice/kubelet.service</span><br><span class="line">           └─31924 /k8s/kubernetes/bin/kubelet --logtostderr=true --v=4 --hostname-override=10.2.8.65 --kubeconfig=/k8s/kubernetes...</span><br></pre></td></tr></table></figure>

<h3 id="四、使用dnstools测试效果"><a href="#四、使用dnstools测试效果" class="headerlink" title="四、使用dnstools测试效果"></a><strong>四、使用dnstools测试效果</strong></h3><p>注意：拿SVC服务来测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@elasticsearch01 coredns]# kubectl run -it --rm --restart=Never --image=infoblox/dnstools:latest dnstools</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">dnstools# nslookup kubernetes</span><br><span class="line">Server:     10.254.0.10</span><br><span class="line">Address:    10.254.0.10#53</span><br><span class="line"></span><br><span class="line">Name:   kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.254.0.1</span><br><span class="line"></span><br><span class="line">dnstools# nslookup nginx</span><br><span class="line">Server:     10.254.0.10</span><br><span class="line">Address:    10.254.0.10#53</span><br><span class="line"></span><br><span class="line">Name:   nginx.default.svc.cluster.local</span><br><span class="line">Address: 10.254.224.237</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/19/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><span class="page-number current">20</span><a class="page-number" href="/page/21/">21</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/21/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jerry Min</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">260</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jerry Min</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
